{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **ML Model - Predict Remaining Useful Life (RUL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Answer [Business Requirement 1](https://github.com/roeszler/filter-maintenance-predictor/blob/main/README.md#business-requirements) :\n",
    "*   Fit and evaluate a **regression model** to predict the Remaining Useful Life of a replaceable part\n",
    "*   Fit and evaluate a **classification model** to predict the Remaining Useful Life of a replaceable part should the regressor not perform well.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Data cleaning and feature engineering from their respective notebooks:\n",
    "* inputs/datasets/cleaned/df_train.csv\n",
    "* inputs/datasets/cleaned/df_test.csv\n",
    "* inputs/datasets/cleaned/df_validate.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Validation set (features and target)\n",
    "* ML pipeline to predict RUL\n",
    "* A map of the labels\n",
    "* Feature Importance Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The major steps in a Regressor Pipeline\n",
    "\n",
    "1. **ML Pipeline: Regressor**\n",
    "    * Create Regressor Pipeline\n",
    "    * Split the train set\n",
    "    * Grid Search CV SKLearn\n",
    "        * Use standard hyperparameters to find most suitable algorithm\n",
    "        * Extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "    * Assess Feature Performance\n",
    "    * Evaluate Regressor\n",
    "    * Create Train, Test, Validation Sets\n",
    "\n",
    "2. **ML Pipeline: Regressor + Principal Component Analysis (PCA)**\n",
    "    * Prepare the Data for the Pipeline\n",
    "    * Create Regressor + PCA Pipeline\n",
    "    * Split the train and validation sets\n",
    "    * Grid Search CV SKLearn\n",
    "        * Use standard hyperparameters to find most suitable algorithm\n",
    "        * Do an extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "    * Assess Feature Performance\n",
    "    * Evaluate Regressor\n",
    "    * Create Train, Test, Validation Sets\n",
    "\n",
    "_Optionally_\n",
    "\n",
    "3. **Convert Regression to Classification**\n",
    "    * Convert numerical target to bins, and check if it is balanced\n",
    "    * Rewrite Pipeline for ML Modelling\n",
    "    * Load Algorithms For Classification\n",
    "    * Split the Train Test sets:\n",
    "    * Grid Search CV SKLearn:\n",
    "        * Use standard hyper parameters to find most suitable model\n",
    "        * Grid Search CV\n",
    "        * Check Result\n",
    "    * Do an extensive search on the most suitable model to find the best hyperparameter configuration.\n",
    "        * Define Model Parameters\n",
    "        * Extensive Grid Search CV                             \n",
    "        * Check Results\n",
    "        * Check Best Model\n",
    "        * Parameters for best model\n",
    "        * Define the best clf_pipeline\n",
    "    * Assess Feature Importance\n",
    "    * Evaluate Classifier on Train and Test Sets\n",
    "        * Custom Function\n",
    "        * List that relates the classes and tenure interval\n",
    "\n",
    "4. **Decide which pipeline to use**\n",
    "\n",
    "5. **Refit with the best features**\n",
    "    * Rewrite Pipeline\n",
    "    * Split Train Test Set with only best features\n",
    "    * Subset best features\n",
    "    * Grid Search CV SKLearn\n",
    "    * Best Parameters\n",
    "        * Manually\n",
    "    * Grid Search CV\n",
    "    * Check Results\n",
    "    * Check Best Model\n",
    "    * Define the best pipeline\n",
    "\n",
    "6. **Assess Feature Importance**\n",
    "\n",
    "7. **Push Files to Repo**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Modelling:\n",
    "The hypothesis part of the process where you will find out whether you can answer the question.\n",
    "* Identify what techniques to use.\n",
    "* Split your data into train, validate and test sets.\n",
    "* Build and train the models with the train data set.\n",
    "* Validate Models and hyper-parameter : Trial different machine learning methods and models with the validation data set.\n",
    "* Poor Results - return to data preparation for feature engineering\n",
    "* Successful hypothesis - where the inputs from the data set are mapped to the output target / label appropriately to evaluate.\n",
    "\n",
    "5. Evaluation:\n",
    "Where you test whether the model can predict unseen data.\n",
    "* Test Dataset\n",
    "* Choose the model that meets the business success criteria best.\n",
    "* Review and document the work that you have done.\n",
    "* If your project meets the success metrics you defined with your customer?\n",
    "- Ready to deploy. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12 (default, Dec  2 2022, 16:09:02) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
