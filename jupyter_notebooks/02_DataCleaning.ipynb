{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **Data Cleaning Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Confirm / Evaluate missing data\n",
    "*   Clean data in preparation for analysis\n",
    "\n",
    "### Inputs\n",
    "\n",
    "1. Test Dataset : `outputs/datasets/collection/PredictiveMaintenanceTest.csv`\n",
    "\n",
    "2. Train Dataset : `outputs/datasets/collection/PredictiveMaintenanceTrain.csv`\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* Generate cleaned Train and Test sets, both saved under `outputs/datasets/cleaned`\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "  * Data Cleaning Pipeline\n",
    "  * Drop Variables as Required\n",
    "  <!-- `['customerID', 'TotalCharges' ]` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"Current directory set to new location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Collection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTrain.csv')\n",
    "df_test = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm we don't have variables with missing data, and if we do; discover their distribution and shape.\n",
    "* Note: we are aware that the **df_train** dataset does not have values for `RUL`, so both sets are checked separately\n",
    "\n",
    "If we tried to combine the sets to check, it would indicate `RUL` has missing values like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train, df_test])\n",
    "vars_with_missing_data = df_total.columns[df_total.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check both datasets for missing data at the same time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a handy function to identify which dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_dataframe(data):\n",
    "    ''\" To identify which dataframe is being accessed \"\"\"\n",
    "    name =[n for n in globals() if globals()[n] is data][0]\n",
    "    print('Dataframe name: %s' % name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data & return error information if there is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "    if vars_with_missing_data:\n",
    "        profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "        profile.to_notebook_iframe()\n",
    "    else:\n",
    "        name_dataframe(df)\n",
    "        print('There are no variables with missing data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers in differential pressure observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each bin we notice that the change_DP measure, the size and direction of first few observations indicated they may be outliers. We have considered three main methods to deal with outliers:\n",
    "* Log transformation.\n",
    "* Winsorize method.\n",
    "* Dropping the outliers.\n",
    "\n",
    "These will be handled in the [feature engineering](https://github.com/roeszler/filter-maintenance-predictor/blob/main/jupyter_notebooks/03_FeatureEngineering.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df_train[df_train['Data_No'] == 46]\n",
    "df_bin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Bin 46 change in Differential Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bin = df_train[df_train['Data_No'] == 46]\n",
    "# sns.boxplot(x = df_bin['change_DP'])\n",
    "# sns.stripplot(x = df_bin['change_DP'])\n",
    "# sns.swarmplot(x = df_bin['change_DP'])\n",
    "sns.displot(x = df_bin['change_DP'])\n",
    "# sns.barplot(x = df_bin['change_DP'])\n",
    "# sns.relplot(x = df_bin['change_DP'], kind='line')\n",
    "# sns.scatterplot(x = df_bin['change_DP'])\n",
    "# sns.histplot(x = df_bin['change_DP'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Power Predictive Score Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install ppscore`\n",
    "* Following code derived from Code Institute [Exploratory Data Analysis Tools](https://learn.codeinstitute.net/courses/course-v1:CodeInstitute+DDA101+2021_T4/courseware/468437859a944f7d81a34234957d825b/c8ea2343476c48739676b7f03ba9b08e/) 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ppscore as pps\n",
    "\n",
    "def heatmap_corr(df, threshold, figsize=(10, 8), font_annot=8):\n",
    "    \"\"\"\n",
    "    Heatmap for pearson (linear) and spearman (monotonic) correlations to \n",
    "    visualize only those correlation levels greater than a given threshold.\n",
    "    \"\"\"\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        mask[abs(df) < threshold] = True\n",
    "\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                    mask=mask, cmap='viridis', annot_kws={'size': font_annot}, ax=axes,\n",
    "                    linewidth=0.01, linecolor='WhiteSmoke'\n",
    "                    )\n",
    "        axes.set_yticklabels(df.columns, rotation=0)\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def heatmap_pps(df, threshold, figsize=(10, 8), font_annot=8):\n",
    "    \"\"\"\n",
    "    Heatmap for power predictive score\n",
    "    PPS == 0 means that there is no predictive power\n",
    "    PPS < 0.2 often means that there is some relevant predictive power but it is weak\n",
    "    PPS > 0.2 often means that there is strong predictive power\n",
    "    PPS > 0.8 often means that there is a deterministic relationship in the data,\n",
    "    \"\"\"\n",
    "    if len(df.columns) > 1:\n",
    "        mask = np.zeros_like(df, dtype=bool)\n",
    "        mask[abs(df) < threshold] = True\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
    "                         mask=mask, cmap='rocket_r', annot_kws={'size': font_annot},\n",
    "                         linewidth=0.01, linecolor='WhiteSmoke')\n",
    "        plt.ylim(len(df.columns), 0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def calculate_corr_and_pps(df):\n",
    "    \"\"\"\n",
    "    Calculate the correlations and ppscore of a given dataframe\n",
    "    \"\"\"\n",
    "    df_corr_spearman = df.corr(method='spearman')\n",
    "    df_corr_pearson = df.corr(method='pearson')\n",
    "\n",
    "    pps_matrix_raw = pps.matrix(df)\n",
    "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    pps_score_stats = pps_matrix_raw.query('ppscore < 1').filter(['ppscore']).describe().T\n",
    "    print('PPS threshold - check PPS score IQR to decide threshold for heatmap \\n')\n",
    "    print(pps_score_stats.round(4))\n",
    "\n",
    "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
    "\n",
    "\n",
    "def display_corr_and_pps(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
    "                      figsize=(10, 8), font_annot=8):\n",
    "    \"\"\"\n",
    "    Render the correlations and ppscore heatmaps for a given dataframe\n",
    "    \"\"\"\n",
    "    # print('\\n')\n",
    "    print('To analyze: \\n** Colinearity: how the target variable is correlated with the other features (variables)')\n",
    "    print('** Multi-colinearity: how each feature correlates among themselves (multi-colinearity)')\n",
    "\n",
    "    print('\\n')\n",
    "    print('*** Heatmap: Pearson Correlation ***')\n",
    "    print(f'It evaluates the linear relationship between two continuous variables \\n'\n",
    "          f'* A +ve correlation indicates that as one variable increases the other variable tends to increase.\\n'\n",
    "          f'A correlation near zero indicates that as one variable increases, there is no tendency in the other variable to either increase or decrease.\\n'\n",
    "          f'A -ve correlation indicates that as one variable increases the other variable tends to decrease.')\n",
    "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'*** Heatmap: Spearman Correlation ***')\n",
    "    print(f'It evaluates monotonic relationship \\n'\n",
    "          f'Spearman correlation coefficients range from -1 to +1.\\n'\n",
    "          f'The sign of the coefficient indicates whether it is a positive or negative monotonic relationship.\\n'\n",
    "          f'* A positive correlation means that as one variable increases, the other variable also tends to increase.')\n",
    "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
    "\n",
    "    print('\\n')\n",
    "    print('*** Heatmap: Power Predictive Score (PPS) ***')\n",
    "    print(f'PPS detects linear or non-linear relationships between two columns.\\n'\n",
    "          f'The variable on the x-axis is used to predict the corresponding variable on the y-axis.\\n'\n",
    "          f'The score ranges from 0 (no predictive power) to 1 (perfect predictive power)\\n\\n'\n",
    "          f'* PPS == 0 means that there is no predictive power\\n'\n",
    "          f'* PPS < 0.2 often means that there is some relevant predictive power but it is weak\\n'\n",
    "          f'* PPS > 0.2 often means that there is strong predictive power\\n'\n",
    "          f'* PPS > 0.8 often means that there is a deterministic relationship in the data\\n')\n",
    "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Calculated Variables, Calculate Correlations and Power Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_total.drop(['Data_No', 'change_DP', 'mass_g', 'cumulative_mass_g', 'Tt', 'filter_balance'], axis=1)\n",
    "# df_corr_pearson, df_corr_spearman, pps_matrix = calculate_corr_and_pps(df_total)\n",
    "df_corr_pearson, df_corr_spearman, pps_matrix = calculate_corr_and_pps(df_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairplot** to quickly visualize the relationships among the provided variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmaps for **df_total** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_corr_and_pps(df_corr_pearson = df_corr_pearson, df_corr_spearman = df_corr_spearman,\n",
    "                    pps_matrix = pps_matrix, CorrThreshold = 0, PPS_Threshold =0,\n",
    "                    figsize=(12,10), font_annot=10\n",
    "                    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "#### Heatmap: **Pearson Correlation**\n",
    "* A linear relationship is one when a change in one variable is associated with a proportional change in the other variable \n",
    "* Positive relationships can be observed between \n",
    "    * **Differential Pressure** and **Time** plus **Flow Rate** with a negative \n",
    "    * **Flow Rate** and **RUL** plus **Time** \n",
    "* Strongly negative between **Differential Pressure** and **RUL** \n",
    "\n",
    "#### Heatmap: **Spearman Correlation**\n",
    "* A monotonic relationship is one where one variable is associated with a **change in the specific direction** of another variable. \n",
    "    * e.g. Does a positive change in value/direction X result in a positive change in the value/direction of Y?\n",
    "    * We consider Spearman’s correlation when \n",
    "        * we have pairs of continuous variables and the relationships between them don’t follow a straight line (curvilinear), and/or \n",
    "        * we have pairs of ordinal data (like time)\n",
    "\n",
    "* **Spearman's rho Values and Direction**\n",
    "    * **Differential Pressure** is strongly positively correlated to **Time**, less so **Flow Rate** and negatively correlated to **RUL**\n",
    "    * **Dust Feed** is negatively correlated to **RUL** whereas **Dust Type** is positively correlated to **RUL**\n",
    "    * **Flow Rate** is positively correlated to **Time** and **Differential Pressure** as noted above.\n",
    "\n",
    "#### Heatmap: **Power Predictive Score (PPS)**\n",
    "* Detects linear or non-linear relationships between two columns.\n",
    "* We see strong predictive power between **Dust_feed** and **RUL**, less so however still significant with **Dust_feed** and **Flow_rate**\n",
    "    * RUL as a calculation of **time** remaining, is logically affected by the volume of dust per second. The lower the flow or feed, the higher the RUL. This is however dictated by the simple fact that the filter needs to filter dust. Reducing either of the rates naturally negates the purpose of the filtering process, so we will treat it as a **confounding** relationship and as such, cannot be described in terms of correlations or associations.\n",
    "* When considering the absolute levels of the scores in the dataset, we see a weak yet strong predictive relationship between **Differential Pressure** and **RUL**\n",
    "    * Differential pressure has predictive power of RUL, whereas RUL has no predictive power on differential pressure\n",
    "    * Naturally we also see a week two way relationship between  **Differential Pressure** and **Time**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the files to /cleaned folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "df_train.to_csv(f'outputs/datasets/cleaned/dfCleanTrain.csv',index=False)\n",
    "df_test.to_csv(f'outputs/datasets/cleaned/dfCleanTest.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions: \n",
    "* \n",
    "\n",
    "#### Next Steps:\n",
    "* Correlation Study\n",
    "* Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
