{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **Data Cleaning Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Confirm / Evaluate missing data\n",
    "*   Clean data in preparation for analysis\n",
    "\n",
    "### Inputs\n",
    "\n",
    "1. Test Dataset : `outputs/datasets/collection/PredictiveMaintenanceTest.csv`\n",
    "\n",
    "2. Train Dataset : `outputs/datasets/collection/PredictiveMaintenanceTrain.csv`\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* Generate cleaned Train and Test sets, both saved under `outputs/datasets/cleaned`\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "  * Data Cleaning Pipeline\n",
    "  * Drop Variables as Required\n",
    "  <!-- `['customerID', 'TotalCharges' ]` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"Current directory set to new location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Collection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTrain.csv')\n",
    "df_test = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm we don't have variables with missing data, and if we do; discover their distribution and shape.\n",
    "* Note: we are aware that the **df_train** dataset does not have values for `RUL`, so both sets are checked separately\n",
    "\n",
    "If we tried to combine the sets to check, it would indicate `RUL` has missing values like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train, df_test])\n",
    "vars_with_missing_data = df_total.columns[df_total.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check both datasets for missing data at the same time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a handy function to identify which dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_dataframe(data):\n",
    "    \"\"\" To identify which dataframe is being accessed \"\"\"\n",
    "    name =[n for n in globals() if globals()[n] is data][0]\n",
    "    print('Dataframe name: %s' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "    if vars_with_missing_data:\n",
    "        profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "        profile.to_notebook_iframe()\n",
    "    else:\n",
    "        name_dataframe(df)\n",
    "        print('There are no variables with missing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evenly distribute dataset by `Dust` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the train and test sets supplied have data distributed unevenly between 50 test bins. To account for this we wish to assess the measures of central tendency for each Dust class, with tha aim of reducing the data size to a more evenly proportioned one between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider % `censored` calculation to all observations in both datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train** Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considerations**\n",
    "\n",
    "* The proportion of data that **has reached filter failure**. These may be worth keeping and will make part of our heuristic decision process.\n",
    "* The **mean** is the most frequently used measure of central tendency because it uses all values in the data set to give you an average.\n",
    "* For data from skewed distributions (like `differential_pressure`), the **median** is better than the mean because it isnâ€™t influenced by extremely large values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the top five `Data_No` bins where `differential_pressure` observations that have made it to the **600 Pa** (the point of filter failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row_train = df_train[df_train.Data_No != df_train.Data_No.shift(-1)]\n",
    "# last_row_descending = last_row_train.sort_values(by='Dust', ascending=True)\n",
    "last_row_descending = last_row_train.sort_values(by='Differential_pressure', ascending=False)\n",
    "last_row_descending.head(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `Dust` variable in this dataset shows a disproportionate mix between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "category_totals = df_train.groupby('Dust')['Differential_pressure'].count().sort_values()\n",
    "category_totals.plot(kind=\"barh\", title='Proportion of Dust Classes in df_train\\n', xlabel='\\nObservations', ylabel='Dust Class')\n",
    "category_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# top_5.plot(x='Dust', y='Differential_pressure', kind='bar', rot=5, fontsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# category_totals = last_row_descending.groupby('Dust')['Differential_pressure'].count().sort_values()\n",
    "# category_totals.plot(kind=\"barh\")\n",
    "# category_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "category_totals = df_train.groupby('Dust')['Differential_pressure'].count().sort_values()\n",
    "category_totals.plot(kind=\"barh\")\n",
    "category_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df_train, df_test):\n",
    "    df.to_numpy()\n",
    "    name_dataframe(df)\n",
    "    print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the last values of each data bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.Data_No != df_train.Data_No.shift(-1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract each class and compare distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test.Data_No != df_test.Data_No.shift(-1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Power Predictive Score Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the files to /cleaned folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "df_train.to_csv(f'outputs/datasets/cleaned/dfCleanTrain.csv',index=False)\n",
    "df_test.to_csv(f'outputs/datasets/cleaned/dfCleanTest.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions: \n",
    "* \n",
    "\n",
    "#### Next Steps:\n",
    "* Correlation Study\n",
    "* Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
