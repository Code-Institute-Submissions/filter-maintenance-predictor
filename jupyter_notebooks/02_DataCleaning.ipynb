{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **Data Cleaning Notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Confirm / Evaluate missing data\n",
    "*   Clean data in preparation for analysis\n",
    "\n",
    "### Inputs\n",
    "\n",
    "1. Test Dataset : `outputs/datasets/collection/PredictiveMaintenanceTest.csv`\n",
    "\n",
    "2. Train Dataset : `outputs/datasets/collection/PredictiveMaintenanceTrain.csv`\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* Generate cleaned Train and Test sets, both saved under `outputs/datasets/cleaned`\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "  * Data Cleaning Pipeline\n",
    "  * Drop Variables as Required\n",
    "  <!-- `['customerID', 'TotalCharges' ]` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"Current directory set to new location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Collection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTrain.csv')\n",
    "df_test = pd.read_csv(f'outputs/datasets/collection/PredictiveMaintenanceTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm we don't have variables with missing data, and if we do; discover their distribution and shape.\n",
    "* Note: we are aware that the **df_train** dataset does not have values for `RUL`, so both sets are checked separately\n",
    "\n",
    "If we tried to combine the sets to check, it would indicate `RUL` has missing values like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train, df_test])\n",
    "vars_with_missing_data = df_total.columns[df_total.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check both datasets for missing data at the same time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a handy function to identify which dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_dataframe(data):\n",
    "    \"\"\" To identify which dataframe is being accessed \"\"\"\n",
    "    name =[n for n in globals() if globals()[n] is data][0]\n",
    "    print('Dataframe name: %s' % name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data & return error information if there is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "    if vars_with_missing_data:\n",
    "        profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "        profile.to_notebook_iframe()\n",
    "    else:\n",
    "        name_dataframe(df)\n",
    "        print('There are no variables with missing data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers of change in differential pressure measures `change_DP`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each bin we notice that the change_DP measure, the size and direction of first few observations indicated they may be outliers. We have considered three main methods to deal with outliers:\n",
    "* Dropping the outliers.\n",
    "* Winsorize method.\n",
    "* Log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# df_train['change_DP'].plot(kind=\"boxplot\", title='Proportion of Dust Classes in df_train\\n', xlabel='\\nObservations', ylabel='Dust Class')\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x = df_train['change_DP'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evenly distribute dataset by `Dust` type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the train and test sets supplied have data distributed unevenly between 50 test bins. To account for this we wish to assess the measures of central tendency for each Dust class, with the aim of reducing the data size to a more evenly proportioned one between classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train** Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considerations**\n",
    "\n",
    "* The proportion of data that **has reached filter failure** is represented by how close `filter_balance` is to zero or less. \n",
    "    * Data with filter_balance values approaching zero may be worth keeping and will make part of our heuristic decision process.\n",
    "* Notwithstanding that the **mean** is the most frequently used measure of central tendency because it uses all values in the data set to give you an average\n",
    "    * For data from skewed distributions (like `differential_pressure`), the **median** is better than the mean because it isnâ€™t influenced by extremely large values.\n",
    "\n",
    "In the following calculation, we see a summary of the top ten `Data_No` bins where `differential_pressure` observations that have made it to the **600 Pa** (the point of filter failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row_train = df_train[df_train.Data_No != df_train.Data_No.shift(-1)]\n",
    "# last_row_descending = last_row_train.sort_values(by='Dust', ascending=True)\n",
    "last_row_descending = last_row_train.sort_values(by='Differential_pressure', ascending=False)\n",
    "last_row_descending.head(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the diagram below showing proportions of `Dust` variable in the **df_train** dataset.\n",
    "* It shows a disproportionate mix between classes. This will be the first dataset we tidy up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "category_totals = df_train.groupby('Dust')['Differential_pressure'].count().sort_values()\n",
    "category_totals.plot(kind=\"barh\", title='Proportion of Dust Classes in df_train\\n', xlabel='\\nObservations', ylabel='Dust Class')\n",
    "category_totals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent Central Tendency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next aim is to \n",
    "* Fill these bins with data that best represents a central tendency.\n",
    "* Make the size of each bin around **9400** observations (similar to the A4 Coarse Dust class bin) \n",
    "\n",
    "#### Procedure\n",
    "* Include a comparison to how far each `differential_pressure` measure **deviates** or how far it is from the **.median()** value of the bin.\n",
    "* Ordered by `filter_balance` showing sets with data closest to 600 Pa `differential_pressure`.\n",
    "* Include comparison to median\n",
    "* Add a cumulative measure of Data_No's to use as a ranking\n",
    "* Create a dataframe of the A3 Medium Dust : **1.025**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a calculation of Standard Deviation to **df_train** test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_group = df_train.groupby('Data_No').std()\n",
    "std_group.index.name = None\n",
    "std_group['Data_No'] = std_group.index\n",
    "map_std = df_train['Data_No'].map(std_group.set_index('Data_No')['Differential_pressure'])\n",
    "df_train['std_DP'] = map_std\n",
    "# df_test.loc[363:368]\n",
    "df_train.loc[446:451]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a calculation of Coefficient of Variation (variance) to **df_train** test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cv = lambda data: np.std(data, ddof=1) / np.mean(data, axis=0) * 100 \n",
    "var_group = df_train.groupby('Data_No').apply(cv)\n",
    "var_group.index.name = None\n",
    "var_group['Data_No'] = var_group.index\n",
    "map_var = df_train['Data_No'].map(var_group.set_index('Data_No')['Differential_pressure'])\n",
    "df_train['cv_DP'] = map_var\n",
    "# df_test.loc[363:368]\n",
    "df_train.loc[446:451]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of variation is an indication of how far the standard deviation is away from the mean. As we can see it does not add value to our understanding of the data, primarily due the the skewed nature of the `differential_pressure` continuous variable. \n",
    "* This re-enforces the understanding that descriptive statistics using the mean may not be preferred measure of central tendency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Coefficient of Variation and Add Median to df_train**\n",
    "* Median is the preferred measure of central tendency to observe in a skewed dataset such as this as it is not as affected by larger values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['cv_DP']\n",
    "median_group = df_train.groupby('Data_No').median()\n",
    "median_group.index.name = None\n",
    "median_group['Data_No'] = median_group.index\n",
    "map_median = df_train['Data_No'].map(median_group.set_index('Data_No')['Differential_pressure'])\n",
    "df_train['median_DP'] = map_median\n",
    "df_train.loc[446:452]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the dataframe with just **A3 Dust** in it, ordered by `filter_balance` as a measure of time to filter failure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the size of each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sum = df_train.groupby('Data_No')['Data_No'].count().reset_index(name='bin_Tot')\n",
    "map_bin = df_train['Data_No'].map(bin_sum.set_index('Data_No')['bin_Tot'])\n",
    "df_train['bin_Size'] = map_bin\n",
    "# df_train.loc[38817:38827]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include a cumulative sum of each **bin size**. This will help us decide on the data bin that reaches **9400** or more total values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_A3 = df_train[df_train['Dust'] == 1.025]\n",
    "filter_A3 = dust_A3[dust_A3.Data_No != dust_A3.Data_No.shift(-1)]\n",
    "df_train_A3 = filter_A3.sort_values(by='Filter_Balance', ascending=True)\n",
    "df_train_A3['c_Sum'] = df_train_A3['bin_Size'].cumsum()\n",
    "df_train_A3.head(13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the current dataframe containing only A3 Medium Dust observations, that is ordered by those tests with closest to a completed test to failure:\n",
    "* **The top 12 data bins (seen at bin 21) would extract a A3 Medium dust training dataset with 9,764 observations**\n",
    "* We will now perform a further PDA to evaluate the suitability of these further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank by Standard Deviations, ordered by `std_DP`\n",
    "The standard deviation is used to measure the spread of values in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dust_A3 = df_train[df_train['Dust'] == 1.025]\n",
    "# filter_A3 = dust_A3[dust_A3.Data_No != dust_A3.Data_No.shift(-1)]\n",
    "df_train_A3_std = filter_A3.sort_values(by='std_DP', ascending=True)\n",
    "df_train_A3_std['c_Sum'] = df_train_A3_std['bin_Size'].cumsum()\n",
    "df_train_A3_std.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank by central tenancy of the Median value, ordered by `median_DP`\n",
    "* the value of the number in the middle of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dust_A3 = df_train[df_train['Dust'] == 1.025]\n",
    "# filter_A3 = dust_A3[dust_A3.Data_No != dust_A3.Data_No.shift(-1)]\n",
    "df_train_A3_median = filter_A3.sort_values(by='median_DP', ascending=True)\n",
    "df_train_A3_median['c_Sum'] = df_train_A3_median['bin_Size'].cumsum()\n",
    "df_train_A3_median.head(14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations\n",
    "* T..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract these bins from the df_train dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a separate frame indicating the bin numbers we wish to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_no = df_train_A3['Data_No'].head(12)\n",
    "bin_no.to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these references to create a dataframe `df_train_cleaned_A3` that is ready for inclusion in our final dataframe `df_train_clean`.\n",
    "* Note we disregard the cumulative sum measure as it doesn't add value to further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train\n",
    "df_train_cleaned_A3 = df_train_copy[df_train_copy['Data_No'].isin(bin_no)]\n",
    "df_train_cleaned_A3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Quick Review: \n",
    "* The Shape we started with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_A3.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape we have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned_A3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "category_totals = df_train.groupby('Dust')['Differential_pressure'].count().sort_values()\n",
    "category_totals.plot(kind=\"barh\", title='Proportion of Dust Classes in df_train\\n', xlabel='\\nObservations', ylabel='Dust Class')\n",
    "category_totals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the cleaning with the next largest set of bins: **A2 Fine Dust**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_A3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_A3.median()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through each data bin in this dust class and calculate the .median() values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.std()\n",
    "df_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = df_train[df_train['Data_No'] == '12']\n",
    "# df_bin.median().round(decimals=2)\n",
    "df_bin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How far the measure is from the median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract each class and compare distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row_test = df_test[df_test.Data_No != df_test.Data_No.shift(-1)]\n",
    "last_row_descending = last_row_test.sort_values(by='Differential_pressure', ascending=False)\n",
    "last_row_descending.head(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataframe distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df_train, df_test):\n",
    "    df_numpy = df\n",
    "    df_numpy.to_numpy()\n",
    "    name_dataframe(df_numpy)\n",
    "    print(df_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Power Predictive Score Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the files to /cleaned folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/cleaned')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "df_train.to_csv(f'outputs/datasets/cleaned/dfCleanTrain.csv',index=False)\n",
    "df_test.to_csv(f'outputs/datasets/cleaned/dfCleanTest.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions: \n",
    "* \n",
    "\n",
    "#### Next Steps:\n",
    "* Correlation Study\n",
    "* Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Dec  2 2022, 16:09:02) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
