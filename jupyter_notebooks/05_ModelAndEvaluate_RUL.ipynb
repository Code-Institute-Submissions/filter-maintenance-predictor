{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **ML Model - Predict Remaining Useful Life (RUL)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Answer [Business Requirement 1](https://github.com/roeszler/filter-maintenance-predictor/blob/main/README.md#business-requirements) :\n",
    "*   Fit and evaluate a **regression model** to predict the Remaining Useful Life of a replaceable part\n",
    "*   Fit and evaluate a **classification model** to predict the Remaining Useful Life of a replaceable part should the regressor not perform well.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Data cleaning:\n",
    "* outputs/datasets/cleaned/dfCleanTotal.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Validation set (features and target)\n",
    "* ML pipeline to predict RUL\n",
    "* A map of the labels\n",
    "* Feature Importance Plot\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/filter-maintenance-predictor/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory set to new location\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"Current directory set to new location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/filter-maintenance-predictor'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The major steps in this Regressor Pipeline\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>1. ML Pipeline: Regressor</strong> (Dropdown List)</summary>\n",
    "\n",
    "* Create Regressor Pipeline\n",
    "* Split the train set\n",
    "* Grid Search CV SKLearn\n",
    "    * Use standard hyperparameters to find most suitable algorithm\n",
    "    * Extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "* Assess Feature Performance\n",
    "* Evaluate Regressor\n",
    "* Create Train, Test, Validation Sets\n",
    "</details></br>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>2. ML Pipeline: Regressor + Principal Component Analysis</strong> (PCA)</summary>\n",
    "\n",
    "* Prepare the Data for the Pipeline\n",
    "* Create Regressor + PCA Pipeline\n",
    "* Split the train and validation sets\n",
    "* Grid Search CV SKLearn\n",
    "    * Use standard hyperparameters to find most suitable algorithm\n",
    "    * Do an extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "* Assess Feature Performance\n",
    "* Evaluate Regressor\n",
    "* Create Train, Test, Validation Sets\n",
    "</details></br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>3. Convert Regression to Classification</strong> (Optionally)</summary>\n",
    "\n",
    "* Convert numerical target to bins, and check if it is balanced\n",
    "* Rewrite Pipeline for ML Modelling\n",
    "* Load Algorithms For Classification\n",
    "* Split the Train Test sets:\n",
    "* Grid Search CV SKLearn:\n",
    "    * Use standard hyper parameters to find most suitable model\n",
    "    * Grid Search CV\n",
    "    * Check Result\n",
    "* Do an extensive search on the most suitable model to find the best hyperparameter configuration.\n",
    "    * Define Model Parameters\n",
    "    * Extensive Grid Search CV                             \n",
    "    * Check Results\n",
    "    * Check Best Model\n",
    "    * Parameters for best model\n",
    "    * Define the best clf_pipeline\n",
    "* Assess Feature Importance\n",
    "* Evaluate Classifier on Train and Test Sets\n",
    "    * Custom Function\n",
    "    * List that relates the classes and tenure interval\n",
    "</details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>4. Decide which pipeline to use</strong></summary></details></br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>5. Refit with the best features</strong></summary>\n",
    "\n",
    "* Rewrite Pipeline\n",
    "* Split Train Test Set with only best features\n",
    "* Subset best features\n",
    "* Grid Search CV SKLearn\n",
    "* Best Parameters\n",
    "    * Manually\n",
    "* Grid Search CV\n",
    "* Check Results\n",
    "* Check Best Model\n",
    "* Define the best pipeline\n",
    "</details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>6. Assess Feature Importance</strong></summary></details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>7. Push Files to Repo</strong></summary></details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Modelling:\n",
    "The hypothesis part of the process where you will find out whether you can answer the question.\n",
    "* Identify what techniques to use.\n",
    "* Split your data into train, validate and test sets.\n",
    "* Build and train the models with the train data set.\n",
    "* Validate Models and hyper-parameter : Trial different machine learning methods and models with the validation data set.\n",
    "* Poor Results - return to data preparation for feature engineering\n",
    "* Successful hypothesis - where the inputs from the data set are mapped to the output target / label appropriately to evaluate.\n",
    "\n",
    "5. Evaluation:\n",
    "Where you test whether the model can predict unseen data.\n",
    "* Test Dataset\n",
    "* Choose the model that meets the business success criteria best.\n",
    "* Review and document the work that you have done.\n",
    "* If your project meets the success metrics you defined with your customer?\n",
    "- Ready to deploy. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data\n",
    "Target variable for regressor, remove from classifier and drop other variables not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69686, 15) = df_total\n",
      "(69686, 12) = df_total_model\n",
      "(20931, 12) = df_train_even_dist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>4point_EWM</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>change_DP</th>\n",
       "      <th>change_EWM</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.046296</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327257</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.242651</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196354</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.360463</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117813</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>2.154530</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.808449</td>\n",
       "      <td>0.794067</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>3.390519</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.898871</td>\n",
       "      <td>1.235989</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>457.888170</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.329500</td>\n",
       "      <td>5.071087</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>460.424462</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-1.265900</td>\n",
       "      <td>2.536292</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>462.669597</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.808400</td>\n",
       "      <td>2.245135</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>466.512358</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.239200</td>\n",
       "      <td>3.842761</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>469.577575</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.898900</td>\n",
       "      <td>3.065217</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure  4point_EWM   log_EWM  Flow_rate  Time  \\\n",
       "0            1               1.537182    1.046296  0.045257  54.143527   5.5   \n",
       "1            1               1.537182    1.242651  0.217247  54.518255   5.6   \n",
       "2            1               1.537182    1.360463  0.307825  54.658781   5.7   \n",
       "3            1               3.345631    2.154530  0.767573  54.780562   5.8   \n",
       "4            1               5.244502    3.390519  1.220983  54.574466   5.9   \n",
       "...        ...                    ...         ...       ...        ...   ...   \n",
       "69681      100             465.494800  457.888170  6.126625  82.675521  52.0   \n",
       "69682      100             464.228900  460.424462  6.132149  82.421873  52.1   \n",
       "69683      100             466.037300  462.669597  6.137013  82.743156  52.2   \n",
       "69684      100             472.276500  466.512358  6.145285  82.785427  52.3   \n",
       "69685      100             474.175400  469.577575  6.151834  83.013710  52.4   \n",
       "\n",
       "        Dust_feed   Dust  RUL  change_DP  change_EWM    mass_g  \\\n",
       "0      236.428943  1.025  NaN   0.000000    0.327257  0.242340   \n",
       "1      236.428943  1.025  NaN   0.000000    0.196354  0.242340   \n",
       "2      236.428943  1.025  NaN   0.000000    0.117813  0.242340   \n",
       "3      236.428943  1.025  NaN   1.808449    0.794067  0.242340   \n",
       "4      236.428943  1.025  NaN   1.898871    1.235989  0.242340   \n",
       "...           ...    ...  ...        ...         ...       ...   \n",
       "69681  316.985065  1.200  8.2   6.329500    5.071087  0.380382   \n",
       "69682  316.985065  1.200  8.1  -1.265900    2.536292  0.380382   \n",
       "69683  316.985065  1.200  8.0   1.808400    2.245135  0.380382   \n",
       "69684  316.985065  1.200  7.9   6.239200    3.842761  0.380382   \n",
       "69685  316.985065  1.200  7.8   1.898900    3.065217  0.380382   \n",
       "\n",
       "       cumulative_mass_g    Tt  filter_balance  \n",
       "0              13.328682  44.9           99.74  \n",
       "1              13.571021  44.9           99.74  \n",
       "2              13.813361  44.9           99.74  \n",
       "3              14.055701  44.9           99.44  \n",
       "4              14.298040  44.9           99.13  \n",
       "...                  ...   ...             ...  \n",
       "69681         197.798681  52.4           22.42  \n",
       "69682         198.179063  52.4           22.63  \n",
       "69683         198.559445  52.4           22.33  \n",
       "69684         198.939827  52.4           21.29  \n",
       "69685         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_total = pd.read_csv(f'outputs/datasets/transformed/dfTransformedTotal.csv') # data with all negative log_EWM values removed\n",
    "df_total_model = (pd.read_csv('outputs/datasets/transformed/dfTransformedTotal.csv')\n",
    "        .drop(labels=['4point_EWM', 'change_DP', 'change_EWM'], axis=1)\n",
    "    )\n",
    "df_train_even_dist = (pd.read_csv(f'outputs/datasets/transformed/dfTransformedTrain.csv')\n",
    "        .drop(labels=['4point_EWM', 'change_DP', 'change_EWM', 'std_DP', 'median_DP', 'bin_size'], axis=1)\n",
    "    )\n",
    "print(df_total.shape, '= df_total')\n",
    "print(df_total_model.shape, '= df_total_model')\n",
    "print(df_train_even_dist.shape, '= df_train_even_dist')\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline : Regressor\n",
    "## Create Regressor Pipeline\n",
    "### Set the Transformations\n",
    "* Smart correlation\n",
    "* feat_scaling\n",
    "* feat_selection\n",
    "* Modelling\n",
    "* Model as variable\n",
    "\n",
    "Note: Numerical Transformation not required as data supplied as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train, Test, Validate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is discrete however in bins, so:\n",
    "#### Define Cleaned **Train** & **Test** Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4.159433</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6.691262</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9.856047</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12.749570</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14.738860</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>359.971800</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>360.785600</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>361.509000</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>362.051500</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>366.482200</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            8               4.159433  0.509088  79.771690   0.6   59.107236   \n",
       "1            8               6.691262  1.301490  80.820436   0.7   59.107236   \n",
       "2            8               9.856047  1.816010  80.605533   0.8   59.107236   \n",
       "3            8              12.749570  2.173409  80.639911   0.9   59.107236   \n",
       "4            8              14.738860  2.413094  80.786058   1.0   59.107236   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "20926       50             359.971800  5.878279  58.721877  59.4  177.321707   \n",
       "20927       50             360.785600  5.882293  58.699919  59.5  177.321707   \n",
       "20928       50             361.509000  5.885498  58.743820  59.6  177.321707   \n",
       "20929       50             362.051500  5.888018  58.601152  59.7  177.321707   \n",
       "20930       50             366.482200  5.894421  58.612131  59.8  177.321707   \n",
       "\n",
       "       Dust  RUL    mass_g  cumulative_mass_g     Tt  filter_balance  \n",
       "0       0.9  NaN  0.053197           0.319179  179.4           99.31  \n",
       "1       0.9  NaN  0.053197           0.372376  179.4           98.88  \n",
       "2       0.9  NaN  0.053197           0.425572  179.4           98.36  \n",
       "3       0.9  NaN  0.053197           0.478769  179.4           97.88  \n",
       "4       0.9  NaN  0.053197           0.531965  179.4           97.54  \n",
       "...     ...  ...       ...                ...    ...             ...  \n",
       "20926   1.2  NaN  0.212786         126.394913   59.8           40.00  \n",
       "20927   1.2  NaN  0.212786         126.607699   59.8           39.87  \n",
       "20928   1.2  NaN  0.212786         126.820485   59.8           39.75  \n",
       "20929   1.2  NaN  0.212786         127.033271   59.8           39.66  \n",
       "20930   1.2  NaN  0.212786         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df_total_model['Data_No'].iloc[0:len(df_total)]\n",
    "# df_train = df_total_model[n < 51].reset_index(drop=True)\n",
    "df_test = df_total_model[n > 50].reset_index(drop=True)\n",
    "df_train = df_train_even_dist\n",
    "# df_train = df_train_even_dist.fillna(0)\n",
    "df_train_model = df_train_even_dist\n",
    "# df_train_model = df_train_even_dist.fillna(0)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2.622251</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>55.524146</td>\n",
       "      <td>0.4</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>3.888165</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>55.852018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.211698</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.150273</td>\n",
       "      <td>56.130203</td>\n",
       "      <td>0.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.454038</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.309382</td>\n",
       "      <td>56.150070</td>\n",
       "      <td>0.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.696378</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.393959</td>\n",
       "      <td>56.090457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.938717</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36358</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36359</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36360</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36361</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0           51               2.622251  0.148056  55.524146   0.4  236.428943   \n",
       "1           51               3.888165  0.811380  55.852018   0.5  236.428943   \n",
       "2           51               4.521122  1.150273  56.130203   0.6  236.428943   \n",
       "3           51               4.521122  1.309382  56.150070   0.7  236.428943   \n",
       "4           51               4.521122  1.393959  56.090457   0.8  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "36357      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "36358      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "36359      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "36360      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "36361      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust   RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  58.6  0.242340           0.969359  36.6           99.56  \n",
       "1      1.025  58.5  0.242340           1.211698  36.6           99.35  \n",
       "2      1.025  58.4  0.242340           1.454038  36.6           99.25  \n",
       "3      1.025  58.3  0.242340           1.696378  36.6           99.25  \n",
       "4      1.025  58.2  0.242340           1.938717  36.6           99.25  \n",
       "...      ...   ...       ...                ...   ...             ...  \n",
       "36357  1.200   8.2  0.380382         197.798681  52.4           22.42  \n",
       "36358  1.200   8.1  0.380382         198.179063  52.4           22.63  \n",
       "36359  1.200   8.0  0.380382         198.559445  52.4           22.33  \n",
       "36360  1.200   7.9  0.380382         198.939827  52.4           21.29  \n",
       "36361  1.200   7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[36362 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine **Target** and **Independent** Variables and Extract **Validation** Dataset\n",
    "\n",
    "As discussed in the readme, this data has been supplied pre-split into **train** and **test** within unique **data bins**. \n",
    "We extract random observations from the **test** dataset to create a **validation** set, in a 70:30 split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2.622251</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>55.524146</td>\n",
       "      <td>0.4</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>3.888165</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>55.852018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.211698</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.150273</td>\n",
       "      <td>56.130203</td>\n",
       "      <td>0.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.454038</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.309382</td>\n",
       "      <td>56.150070</td>\n",
       "      <td>0.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.696378</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.393959</td>\n",
       "      <td>56.090457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.938717</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36358</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36359</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36360</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36361</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0           51               2.622251  0.148056  55.524146   0.4  236.428943   \n",
       "1           51               3.888165  0.811380  55.852018   0.5  236.428943   \n",
       "2           51               4.521122  1.150273  56.130203   0.6  236.428943   \n",
       "3           51               4.521122  1.309382  56.150070   0.7  236.428943   \n",
       "4           51               4.521122  1.393959  56.090457   0.8  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "36357      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "36358      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "36359      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "36360      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "36361      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust   RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  58.6  0.242340           0.969359  36.6           99.56  \n",
       "1      1.025  58.5  0.242340           1.211698  36.6           99.35  \n",
       "2      1.025  58.4  0.242340           1.454038  36.6           99.25  \n",
       "3      1.025  58.3  0.242340           1.696378  36.6           99.25  \n",
       "4      1.025  58.2  0.242340           1.938717  36.6           99.25  \n",
       "...      ...   ...       ...                ...   ...             ...  \n",
       "36357  1.200   8.2  0.380382         197.798681  52.4           22.42  \n",
       "36358  1.200   8.1  0.380382         198.179063  52.4           22.63  \n",
       "36359  1.200   8.0  0.380382         198.559445  52.4           22.33  \n",
       "36360  1.200   7.9  0.380382         198.939827  52.4           21.29  \n",
       "36361  1.200   7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[36362 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review correlations, Drop Features and Split into **70% test** and **30% validate**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25453, 7) X_test\n",
      "(10909, 7) X_validate\n",
      "(25453,) y_test\n",
      "(10909,) y_validate\n",
      "\n",
      "Features Suggested to Drop :\n",
      " ['Differential_pressure', 'Time', 'mass_g', 'cumulative_mass_g', 'filter_balance']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
    "df_engineering = df_test.copy()\n",
    "corr_sel.fit_transform(df_engineering)\n",
    "\n",
    "# log_EWM = df_test['log_EWM']\n",
    "features_to_drop_test = corr_sel.features_to_drop_\n",
    "# features_to_drop_test = [e for e in features_to_drop_test if e not in ('log_EWM', 'Dust_feed', 'RUL')] # prevent these requirements from being removed in V1\n",
    "features_to_drop_test = [e for e in features_to_drop_test if e not in ('Dust_feed', 'RUL')] # prevent these requirements from being removed in V1\n",
    "features_to_drop_test.insert(0, 'Differential_pressure') # include differential pressure to be removed\n",
    "X = df_test.drop(features_to_drop_test,axis=1)\n",
    "# y = df_test['Differential_pressure'] # define the target variable\n",
    "y = df_test['log_EWM'] # define the target variable\n",
    "\n",
    "# X.loc[:, 'log_EWM'] = log_EWM\n",
    "# sma_calc = df_bin['Differential_pressure'].rolling(4).mean()\n",
    "# X.insert(loc=2, column='log_EWM', value=log_EWM)\n",
    "\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X,y,test_size=0.30, random_state=0)\n",
    "\n",
    "print(X_test.shape, 'X_test')\n",
    "print(X_validate.shape, 'X_validate')\n",
    "print(y_test.shape, 'y_test')\n",
    "print(y_validate.shape, 'y_validate')\n",
    "print('\\nFeatures Suggested to Drop :\\n', features_to_drop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>Tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>56</td>\n",
       "      <td>1.574637</td>\n",
       "      <td>57.383039</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>95.8</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>77</td>\n",
       "      <td>4.110545</td>\n",
       "      <td>57.690319</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>1.025</td>\n",
       "      <td>40.6</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32959</th>\n",
       "      <td>94</td>\n",
       "      <td>2.701905</td>\n",
       "      <td>60.006667</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>0.900</td>\n",
       "      <td>22.7</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>79</td>\n",
       "      <td>5.329106</td>\n",
       "      <td>81.686305</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>122.2</td>\n",
       "      <td>258.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34580</th>\n",
       "      <td>99</td>\n",
       "      <td>3.762976</td>\n",
       "      <td>80.313263</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>168.4</td>\n",
       "      <td>248.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>78</td>\n",
       "      <td>2.108220</td>\n",
       "      <td>83.445949</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>261.7</td>\n",
       "      <td>243.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>91</td>\n",
       "      <td>2.025411</td>\n",
       "      <td>80.846225</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>0.900</td>\n",
       "      <td>38.8</td>\n",
       "      <td>49.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>85</td>\n",
       "      <td>4.211845</td>\n",
       "      <td>80.485188</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.200</td>\n",
       "      <td>48.5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>78</td>\n",
       "      <td>3.385567</td>\n",
       "      <td>82.624780</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>213.1</td>\n",
       "      <td>243.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>56</td>\n",
       "      <td>4.934737</td>\n",
       "      <td>58.228042</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>39.4</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25453 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No   log_EWM  Flow_rate   Dust_feed   Dust    RUL     Tt\n",
       "2168        56  1.574637  57.383039  158.492533  1.025   95.8   71.3\n",
       "20305       77  4.110545  57.690319  237.738799  1.025   40.6   60.2\n",
       "32959       94  2.701905  60.006667  316.985065  0.900   22.7   24.1\n",
       "24724       79  5.329106  81.686305   59.107236  1.200  122.2  258.1\n",
       "34580       99  3.762976  80.313263   59.107236  1.200  168.4  248.2\n",
       "...        ...       ...        ...         ...    ...    ...    ...\n",
       "20757       78  2.108220  83.445949   59.107236  1.200  261.7  243.8\n",
       "32103       91  2.025411  80.846225  237.738799  0.900   38.8   49.9\n",
       "30403       85  4.211845  80.485188  177.321707  1.200   48.5   66.0\n",
       "21243       78  3.385567  82.624780   59.107236  1.200  213.1  243.8\n",
       "2732        56  4.934737  58.228042  158.492533  1.025   39.4   71.3\n",
       "\n",
       "[25453 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define **X_train**, **y_train** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4.159433</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6.691262</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9.856047</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12.749570</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14.738860</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>359.971800</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>360.785600</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>361.509000</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>362.051500</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>366.482200</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            8               4.159433  0.509088  79.771690   0.6   59.107236   \n",
       "1            8               6.691262  1.301490  80.820436   0.7   59.107236   \n",
       "2            8               9.856047  1.816010  80.605533   0.8   59.107236   \n",
       "3            8              12.749570  2.173409  80.639911   0.9   59.107236   \n",
       "4            8              14.738860  2.413094  80.786058   1.0   59.107236   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "20926       50             359.971800  5.878279  58.721877  59.4  177.321707   \n",
       "20927       50             360.785600  5.882293  58.699919  59.5  177.321707   \n",
       "20928       50             361.509000  5.885498  58.743820  59.6  177.321707   \n",
       "20929       50             362.051500  5.888018  58.601152  59.7  177.321707   \n",
       "20930       50             366.482200  5.894421  58.612131  59.8  177.321707   \n",
       "\n",
       "       Dust  RUL    mass_g  cumulative_mass_g     Tt  filter_balance  \n",
       "0       0.9  NaN  0.053197           0.319179  179.4           99.31  \n",
       "1       0.9  NaN  0.053197           0.372376  179.4           98.88  \n",
       "2       0.9  NaN  0.053197           0.425572  179.4           98.36  \n",
       "3       0.9  NaN  0.053197           0.478769  179.4           97.88  \n",
       "4       0.9  NaN  0.053197           0.531965  179.4           97.54  \n",
       "...     ...  ...       ...                ...    ...             ...  \n",
       "20926   1.2  NaN  0.212786         126.394913   59.8           40.00  \n",
       "20927   1.2  NaN  0.212786         126.607699   59.8           39.87  \n",
       "20928   1.2  NaN  0.212786         126.820485   59.8           39.75  \n",
       "20929   1.2  NaN  0.212786         127.033271   59.8           39.66  \n",
       "20930   1.2  NaN  0.212786         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **train** dataset with the same variables dropped as the **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20931, 6) X_train\n",
      "(20931,) y_train\n",
      "\n",
      "Features Dropped :\n",
      " ['RUL', 'Differential_pressure', 'Time', 'mass_g', 'cumulative_mass_g', 'filter_balance']\n"
     ]
    }
   ],
   "source": [
    "features_to_drop_test.insert(0, 'RUL')\n",
    "\n",
    "X_train = df_train.drop(features_to_drop_test,axis=1)\n",
    "y_train = df_train['Differential_pressure']\n",
    "\n",
    "print(X_train.shape, 'X_train')\n",
    "print(y_train.shape, 'y_train')\n",
    "print('\\nFeatures Dropped :\\n', features_to_drop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No   log_EWM  Flow_rate   Dust_feed  Dust     Tt\n",
       "0            8  0.509088  79.771690   59.107236   0.9  179.4\n",
       "1            8  1.301490  80.820436   59.107236   0.9  179.4\n",
       "2            8  1.816010  80.605533   59.107236   0.9  179.4\n",
       "3            8  2.173409  80.639911   59.107236   0.9  179.4\n",
       "4            8  2.413094  80.786058   59.107236   0.9  179.4\n",
       "...        ...       ...        ...         ...   ...    ...\n",
       "20926       50  5.878279  58.721877  177.321707   1.2   59.8\n",
       "20927       50  5.882293  58.699919  177.321707   1.2   59.8\n",
       "20928       50  5.885498  58.743820  177.321707   1.2   59.8\n",
       "20929       50  5.888018  58.601152  177.321707   1.2   59.8\n",
       "20930       50  5.894421  58.612131  177.321707   1.2   59.8\n",
       "\n",
       "[20931 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4.159433\n",
       "1          6.691262\n",
       "2          9.856047\n",
       "3         12.749570\n",
       "4         14.738860\n",
       "            ...    \n",
       "20926    359.971800\n",
       "20927    360.785600\n",
       "20928    361.509000\n",
       "20929    362.051500\n",
       "20930    366.482200\n",
       "Name: Differential_pressure, Length: 20931, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Target Imbalance\n",
    "### No need to handle target imbalance in this **regression model**.\n",
    "* Typically we only need to create a single pipeline for Classification or Regression task. \n",
    "* The exception occurs when we need to handle a **classification target imbalance**, which requires more than one model to process "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Pipeline for **Fitting Models** (regression)\n",
    "Import features & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Management\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML regression algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        # (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "        #                                              variables=['Differential_pressure', 'Flow_rate',\n",
    "        #                                                         # 'log_EWM', 'Time', 'mass_g', 'Tt', 'filter_balance',\n",
    "        #                                                         'Dust_feed', 'Dust', 'cumulative_mass_g'])),\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipeline_base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Custom Class** to fit a set of algorithms, each with its own set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key]) # the model\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score (R²)'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score (R²)': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score (R²)', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use standard hyperparameters to find most suitable algorithm for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=0),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(random_state=0),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(random_state=0),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=0),\n",
    "    'XGBRegressor': XGBRegressor(random_state=0),\n",
    "    'SGDRegressor': SGDRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    'DecisionTreeRegressor': {},\n",
    "    'RandomForestRegressor': {},\n",
    "    'ExtraTreesRegressor': {},\n",
    "    'AdaBoostRegressor': {},\n",
    "    'GradientBoostingRegressor': {},\n",
    "    'XGBRegressor': {},\n",
    "    'SGDRegressor': {},\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the pipelines, using the above models with **default hyperparameters** to find the most suitable model\n",
    "* Parsed the train set\n",
    "* Set the performance metric as an R2 score (Regression: described in our ML business case)\n",
    "* Cross validation as 5 (rule of thumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for SGDRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.99965</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.999264</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.99972</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.951972</td>\n",
       "      <td>0.986593</td>\n",
       "      <td>0.998113</td>\n",
       "      <td>0.017436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-0.537714</td>\n",
       "      <td>0.448415</td>\n",
       "      <td>0.753499</td>\n",
       "      <td>0.49414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>-0.559711</td>\n",
       "      <td>0.443811</td>\n",
       "      <td>0.755234</td>\n",
       "      <td>0.502959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score (R²) max_score std_score\n",
       "6               XGBRegressor  0.999442         0.99969  0.999785  0.000129\n",
       "5  GradientBoostingRegressor  0.999336         0.99965  0.999763  0.000163\n",
       "2      RandomForestRegressor  0.999264        0.999616  0.999752  0.000184\n",
       "3        ExtraTreesRegressor  0.999132        0.999556   0.99972  0.000222\n",
       "1      DecisionTreeRegressor  0.998984        0.999471  0.999669  0.000256\n",
       "4          AdaBoostRegressor  0.951972        0.986593  0.998113  0.017436\n",
       "0           LinearRegression -0.537714        0.448415  0.753499   0.49414\n",
       "7               SGDRegressor -0.559711        0.443811  0.755234  0.502959"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_quick, grid_search_pipelines_quick = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No   log_EWM  Flow_rate   Dust_feed  Dust     Tt\n",
       "0            8  0.509088  79.771690   59.107236   0.9  179.4\n",
       "1            8  1.301490  80.820436   59.107236   0.9  179.4\n",
       "2            8  1.816010  80.605533   59.107236   0.9  179.4\n",
       "3            8  2.173409  80.639911   59.107236   0.9  179.4\n",
       "4            8  2.413094  80.786058   59.107236   0.9  179.4\n",
       "...        ...       ...        ...         ...   ...    ...\n",
       "20926       50  5.878279  58.721877  177.321707   1.2   59.8\n",
       "20927       50  5.882293  58.699919  177.321707   1.2   59.8\n",
       "20928       50  5.885498  58.743820  177.321707   1.2   59.8\n",
       "20929       50  5.888018  58.601152  177.321707   1.2   59.8\n",
       "20930       50  5.894421  58.612131  177.321707   1.2   59.8\n",
       "\n",
       "[20931 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>Tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>56</td>\n",
       "      <td>1.574637</td>\n",
       "      <td>57.383039</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>95.8</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>77</td>\n",
       "      <td>4.110545</td>\n",
       "      <td>57.690319</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>1.025</td>\n",
       "      <td>40.6</td>\n",
       "      <td>60.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32959</th>\n",
       "      <td>94</td>\n",
       "      <td>2.701905</td>\n",
       "      <td>60.006667</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>0.900</td>\n",
       "      <td>22.7</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>79</td>\n",
       "      <td>5.329106</td>\n",
       "      <td>81.686305</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>122.2</td>\n",
       "      <td>258.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34580</th>\n",
       "      <td>99</td>\n",
       "      <td>3.762976</td>\n",
       "      <td>80.313263</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>168.4</td>\n",
       "      <td>248.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>78</td>\n",
       "      <td>2.108220</td>\n",
       "      <td>83.445949</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>261.7</td>\n",
       "      <td>243.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>91</td>\n",
       "      <td>2.025411</td>\n",
       "      <td>80.846225</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>0.900</td>\n",
       "      <td>38.8</td>\n",
       "      <td>49.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>85</td>\n",
       "      <td>4.211845</td>\n",
       "      <td>80.485188</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.200</td>\n",
       "      <td>48.5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>78</td>\n",
       "      <td>3.385567</td>\n",
       "      <td>82.624780</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>213.1</td>\n",
       "      <td>243.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>56</td>\n",
       "      <td>4.934737</td>\n",
       "      <td>58.228042</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>39.4</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25453 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No   log_EWM  Flow_rate   Dust_feed   Dust    RUL     Tt\n",
       "2168        56  1.574637  57.383039  158.492533  1.025   95.8   71.3\n",
       "20305       77  4.110545  57.690319  237.738799  1.025   40.6   60.2\n",
       "32959       94  2.701905  60.006667  316.985065  0.900   22.7   24.1\n",
       "24724       79  5.329106  81.686305   59.107236  1.200  122.2  258.1\n",
       "34580       99  3.762976  80.313263   59.107236  1.200  168.4  248.2\n",
       "...        ...       ...        ...         ...    ...    ...    ...\n",
       "20757       78  2.108220  83.445949   59.107236  1.200  261.7  243.8\n",
       "32103       91  2.025411  80.846225  237.738799  0.900   38.8   49.9\n",
       "30403       85  4.211845  80.485188  177.321707  1.200   48.5   66.0\n",
       "21243       78  3.385567  82.624780   59.107236  1.200  213.1  243.8\n",
       "2732        56  4.934737  58.228042  158.492533  1.025   39.4   71.3\n",
       "\n",
       "[25453 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "* The average **R² score** (mean_score) indicates how well a model of the data fits the actual data. It ranges from **0.98 to 0.99**, which is exceptional.\n",
    "    * A value of R² score = 1 represents a perfect fit.\n",
    "\n",
    "* The R² score is much higher than the **0.7** tolerance we decided in the business case.\n",
    "* We can have our choice of most of the regressors. The best result is the **ExtremeGradientBoosting Regressor** however any of **GradientBoosting Regressor**, **RandomForest**, **ExtraTree**, **DecisionTree** or **AdaptiveBoost** regressors perform above our business requirements.\n",
    "* The Linear and Stochastic Gradient Descent regressors under perform and will not be included for consideration in this business case.\n",
    "<!-- * We will perform an extensive search to hopefully improve performance. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary_quick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do an extensive search on the most suitable model to find the best hyperparameter configuration.\n",
    "Define model and parameters for each extensive search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "models_search = {\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'XGBRegressor':{\n",
    "        'model__max_depth': [2, 4, 6],\n",
    "        'model__n_estimators': [50, 100, 200, 400, 600, 20931],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>0.999642</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.998508</td>\n",
       "      <td>0.999203</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.996947</td>\n",
       "      <td>0.998324</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      estimator min_score mean_score (R²) max_score std_score  \\\n",
       "5  XGBRegressor  0.999445        0.999692  0.999788  0.000128   \n",
       "6  XGBRegressor  0.999439         0.99969  0.999789  0.000131   \n",
       "7  XGBRegressor  0.999442         0.99969  0.999785  0.000129   \n",
       "8  XGBRegressor   0.99944        0.999684  0.999779  0.000126   \n",
       "4  XGBRegressor  0.999421        0.999681  0.999781  0.000137   \n",
       "3  XGBRegressor  0.999358        0.999642   0.99976  0.000153   \n",
       "2  XGBRegressor  0.999162        0.999557  0.999712  0.000208   \n",
       "1  XGBRegressor  0.998508        0.999203  0.999529  0.000375   \n",
       "0  XGBRegressor  0.996947        0.998324  0.999166  0.000795   \n",
       "\n",
       "  model__max_depth model__n_estimators  \n",
       "5                4                 200  \n",
       "6                6                  50  \n",
       "7                6                 100  \n",
       "8                6                 200  \n",
       "4                4                 100  \n",
       "3                4                  50  \n",
       "2                2                 200  \n",
       "1                2                 100  \n",
       "0                2                  50  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_XGBR, grid_search_pipelines_XGBR = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_XGBR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor Model (21min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "\n",
    "models_search = {\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'GradientBoostingRegressor':{\n",
    "        'model__loss': ['squared_error', 'huber', 'absolute_error', 'quantile'],\n",
    "        'model__learning_rate': [1e-1,1e-2,1e-3],\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__criterion': ['friedman_mse', 'squared_error'],\n",
    "        'model__max_features': [1.0, 'sqrt', 'log2'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20.262663</td>\n",
       "      <td>-5.828653</td>\n",
       "      <td>-0.343382</td>\n",
       "      <td>7.401115</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.001</td>\n",
       "      <td>quantile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20.262663</td>\n",
       "      <td>-5.828653</td>\n",
       "      <td>-0.343382</td>\n",
       "      <td>7.401115</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.001</td>\n",
       "      <td>quantile</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20.614698</td>\n",
       "      <td>-5.902852</td>\n",
       "      <td>-0.343382</td>\n",
       "      <td>7.535802</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.001</td>\n",
       "      <td>quantile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20.614698</td>\n",
       "      <td>-5.902852</td>\n",
       "      <td>-0.343382</td>\n",
       "      <td>7.535802</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.001</td>\n",
       "      <td>quantile</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-20.614698</td>\n",
       "      <td>-5.902852</td>\n",
       "      <td>-0.343382</td>\n",
       "      <td>7.535802</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>0.001</td>\n",
       "      <td>quantile</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator  min_score mean_score (R²) max_score std_score  \\\n",
       "2    GradientBoostingRegressor   0.999407        0.999681  0.999778  0.000142   \n",
       "5    GradientBoostingRegressor   0.999407        0.999681  0.999778  0.000142   \n",
       "110  GradientBoostingRegressor   0.999407        0.999681  0.999778  0.000142   \n",
       "113  GradientBoostingRegressor   0.999407        0.999681  0.999778  0.000142   \n",
       "8    GradientBoostingRegressor   0.999407        0.999681  0.999778  0.000142   \n",
       "..                         ...        ...             ...       ...       ...   \n",
       "99   GradientBoostingRegressor -20.262663       -5.828653 -0.343382  7.401115   \n",
       "102  GradientBoostingRegressor -20.262663       -5.828653 -0.343382  7.401115   \n",
       "207  GradientBoostingRegressor -20.614698       -5.902852 -0.343382  7.535802   \n",
       "210  GradientBoostingRegressor -20.614698       -5.902852 -0.343382  7.535802   \n",
       "213  GradientBoostingRegressor -20.614698       -5.902852 -0.343382  7.535802   \n",
       "\n",
       "    model__criterion model__learning_rate    model__loss model__max_features  \\\n",
       "2       friedman_mse                  0.1  squared_error                 1.0   \n",
       "5       friedman_mse                  0.1  squared_error                sqrt   \n",
       "110    squared_error                  0.1  squared_error                 1.0   \n",
       "113    squared_error                  0.1  squared_error                sqrt   \n",
       "8       friedman_mse                  0.1  squared_error                log2   \n",
       "..               ...                  ...            ...                 ...   \n",
       "99      friedman_mse                0.001       quantile                 1.0   \n",
       "102     friedman_mse                0.001       quantile                sqrt   \n",
       "207    squared_error                0.001       quantile                 1.0   \n",
       "210    squared_error                0.001       quantile                sqrt   \n",
       "213    squared_error                0.001       quantile                log2   \n",
       "\n",
       "    model__n_estimators  \n",
       "2                   300  \n",
       "5                   300  \n",
       "110                 300  \n",
       "113                 300  \n",
       "8                   300  \n",
       "..                  ...  \n",
       "99                  100  \n",
       "102                 100  \n",
       "207                 100  \n",
       "210                 100  \n",
       "213                 100  \n",
       "\n",
       "[216 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_GBR, grid_search_pipelines_GBR = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_GBR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary_XGBR, grid_search_summary_GBR], ignore_index=True)\n",
    "grid_search_pipelines = dict(grid_search_pipelines_XGBR); grid_search_pipelines.update(grid_search_pipelines_GBR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor (8min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "models_search = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'RandomForestRegressor':{\n",
    "        'model__n_estimators': [100,200,300],\n",
    "        'model__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "        'model__max_depth': [None],\n",
    "        'model__max_features': [1.0, 'sqrt', 'log2'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.993617</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987585</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.99963</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987576</td>\n",
       "      <td>0.993598</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987575</td>\n",
       "      <td>0.993597</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987564</td>\n",
       "      <td>0.993597</td>\n",
       "      <td>0.99963</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987569</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987568</td>\n",
       "      <td>0.993592</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987562</td>\n",
       "      <td>0.993591</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987564</td>\n",
       "      <td>0.993591</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.98756</td>\n",
       "      <td>0.99359</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.00603</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987564</td>\n",
       "      <td>0.99359</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987549</td>\n",
       "      <td>0.99359</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987548</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987559</td>\n",
       "      <td>0.993588</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987543</td>\n",
       "      <td>0.993587</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987546</td>\n",
       "      <td>0.993583</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987545</td>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987544</td>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.98754</td>\n",
       "      <td>0.993579</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.98754</td>\n",
       "      <td>0.993579</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987537</td>\n",
       "      <td>0.993579</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987537</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.99962</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987536</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.993576</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987531</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987517</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987521</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987531</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987517</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987528</td>\n",
       "      <td>0.993573</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987527</td>\n",
       "      <td>0.993573</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987513</td>\n",
       "      <td>0.993566</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987511</td>\n",
       "      <td>0.993564</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987506</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987494</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>0.99963</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator min_score mean_score (R²) max_score std_score  \\\n",
       "31  RandomForestRegressor  0.987616        0.993617  0.999618  0.006001   \n",
       "4   RandomForestRegressor  0.987585        0.993602  0.999619  0.006017   \n",
       "12  RandomForestRegressor  0.987573        0.993602   0.99963  0.006029   \n",
       "1   RandomForestRegressor  0.987576        0.993598   0.99962  0.006022   \n",
       "6   RandomForestRegressor  0.987575        0.993597  0.999619  0.006022   \n",
       "10  RandomForestRegressor  0.987564        0.993597   0.99963  0.006033   \n",
       "26  RandomForestRegressor  0.987569        0.993593  0.999618  0.006025   \n",
       "24  RandomForestRegressor  0.987568        0.993592  0.999616  0.006024   \n",
       "20  RandomForestRegressor  0.987562        0.993591   0.99962  0.006029   \n",
       "32  RandomForestRegressor  0.987564        0.993591  0.999617  0.006026   \n",
       "27  RandomForestRegressor   0.98756         0.99359   0.99962   0.00603   \n",
       "21  RandomForestRegressor  0.987564         0.99359  0.999617  0.006026   \n",
       "16  RandomForestRegressor  0.987549         0.99359  0.999631  0.006041   \n",
       "9   RandomForestRegressor  0.987548        0.993589  0.999631  0.006041   \n",
       "0   RandomForestRegressor  0.987559        0.993588  0.999617  0.006029   \n",
       "11  RandomForestRegressor  0.987543        0.993587  0.999631  0.006044   \n",
       "7   RandomForestRegressor  0.987546        0.993583  0.999619  0.006037   \n",
       "2   RandomForestRegressor  0.987545        0.993582  0.999619  0.006037   \n",
       "25  RandomForestRegressor  0.987544        0.993582   0.99962  0.006038   \n",
       "8   RandomForestRegressor   0.98754        0.993579  0.999618  0.006039   \n",
       "33  RandomForestRegressor   0.98754        0.993579  0.999618  0.006039   \n",
       "22  RandomForestRegressor  0.987537        0.993579   0.99962  0.006041   \n",
       "19  RandomForestRegressor  0.987537        0.993578   0.99962  0.006041   \n",
       "18  RandomForestRegressor  0.987536        0.993578  0.999621  0.006042   \n",
       "28  RandomForestRegressor  0.987533        0.993576  0.999619  0.006043   \n",
       "5   RandomForestRegressor  0.987531        0.993574  0.999618  0.006044   \n",
       "14  RandomForestRegressor  0.987517        0.993574  0.999631  0.006057   \n",
       "15  RandomForestRegressor  0.987521        0.993574  0.999628  0.006054   \n",
       "30  RandomForestRegressor  0.987531        0.993574  0.999617  0.006043   \n",
       "17  RandomForestRegressor  0.987517        0.993574  0.999631  0.006057   \n",
       "23  RandomForestRegressor  0.987528        0.993573  0.999618  0.006045   \n",
       "34  RandomForestRegressor  0.987527        0.993573  0.999619  0.006046   \n",
       "29  RandomForestRegressor  0.987513        0.993566  0.999618  0.006052   \n",
       "35  RandomForestRegressor  0.987511        0.993564  0.999618  0.006054   \n",
       "3   RandomForestRegressor  0.987506        0.993562  0.999618  0.006056   \n",
       "13  RandomForestRegressor  0.987494        0.993562   0.99963  0.006068   \n",
       "\n",
       "   model__criterion model__max_depth model__max_features model__n_estimators  \n",
       "31          poisson             None                sqrt                 200  \n",
       "4     squared_error             None                sqrt                 200  \n",
       "12   absolute_error             None                sqrt                 100  \n",
       "1     squared_error             None                 1.0                 200  \n",
       "6     squared_error             None                log2                 100  \n",
       "10   absolute_error             None                 1.0                 200  \n",
       "26     friedman_mse             None                log2                 300  \n",
       "24     friedman_mse             None                log2                 100  \n",
       "20     friedman_mse             None                 1.0                 300  \n",
       "32          poisson             None                sqrt                 300  \n",
       "27          poisson             None                 1.0                 100  \n",
       "21     friedman_mse             None                sqrt                 100  \n",
       "16   absolute_error             None                log2                 200  \n",
       "9    absolute_error             None                 1.0                 100  \n",
       "0     squared_error             None                 1.0                 100  \n",
       "11   absolute_error             None                 1.0                 300  \n",
       "7     squared_error             None                log2                 200  \n",
       "2     squared_error             None                 1.0                 300  \n",
       "25     friedman_mse             None                log2                 200  \n",
       "8     squared_error             None                log2                 300  \n",
       "33          poisson             None                log2                 100  \n",
       "22     friedman_mse             None                sqrt                 200  \n",
       "19     friedman_mse             None                 1.0                 200  \n",
       "18     friedman_mse             None                 1.0                 100  \n",
       "28          poisson             None                 1.0                 200  \n",
       "5     squared_error             None                sqrt                 300  \n",
       "14   absolute_error             None                sqrt                 300  \n",
       "15   absolute_error             None                log2                 100  \n",
       "30          poisson             None                sqrt                 100  \n",
       "17   absolute_error             None                log2                 300  \n",
       "23     friedman_mse             None                sqrt                 300  \n",
       "34          poisson             None                log2                 200  \n",
       "29          poisson             None                 1.0                 300  \n",
       "35          poisson             None                log2                 300  \n",
       "3     squared_error             None                sqrt                 100  \n",
       "13   absolute_error             None                sqrt                 200  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_RForest, grid_search_pipelines_RForest = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_RForest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_RForest], ignore_index = True)\n",
    "data = dict(grid_search_pipelines); data.update(grid_search_pipelines_RForest)\n",
    "grid_search_pipelines = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesRegressor (48min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\n",
    "\n",
    "models_search = {\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'ExtraTreesRegressor':{\n",
    "        'model__n_estimators': [100,200,300],\n",
    "        'model__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "        'model__max_depth': [None],\n",
    "        'model__min_samples_split': [2,4,6],\n",
    "        'model__max_features': [1.0, 'sqrt', 'log2'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 2 folds for each of 108 candidates, totalling 216 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__min_samples_split</th>\n",
       "      <th>model__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987693</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987679</td>\n",
       "      <td>0.993677</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.993674</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.993673</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.993673</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987549</td>\n",
       "      <td>0.993549</td>\n",
       "      <td>0.999549</td>\n",
       "      <td>0.006</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987549</td>\n",
       "      <td>0.993549</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.006</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.98755</td>\n",
       "      <td>0.993549</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987549</td>\n",
       "      <td>0.993549</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.006</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987549</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.999547</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              estimator min_score mean_score (R²) max_score std_score  \\\n",
       "39  ExtraTreesRegressor  0.987693        0.993684  0.999675  0.005991   \n",
       "41  ExtraTreesRegressor  0.987679        0.993677  0.999675  0.005998   \n",
       "48  ExtraTreesRegressor  0.987672        0.993674  0.999675  0.006001   \n",
       "49  ExtraTreesRegressor  0.987672        0.993673  0.999675  0.006002   \n",
       "31  ExtraTreesRegressor  0.987672        0.993673  0.999675  0.006001   \n",
       "..                  ...       ...             ...       ...       ...   \n",
       "54  ExtraTreesRegressor  0.987549        0.993549  0.999549     0.006   \n",
       "37  ExtraTreesRegressor  0.987549        0.993549  0.999548     0.006   \n",
       "45  ExtraTreesRegressor   0.98755        0.993549  0.999548  0.005999   \n",
       "28  ExtraTreesRegressor  0.987549        0.993549  0.999548     0.006   \n",
       "90  ExtraTreesRegressor  0.987549        0.993548  0.999547  0.005999   \n",
       "\n",
       "   model__criterion model__max_depth model__max_features  \\\n",
       "39   absolute_error             None                sqrt   \n",
       "41   absolute_error             None                sqrt   \n",
       "48   absolute_error             None                log2   \n",
       "49   absolute_error             None                log2   \n",
       "31   absolute_error             None                 1.0   \n",
       "..              ...              ...                 ...   \n",
       "54     friedman_mse             None                 1.0   \n",
       "37   absolute_error             None                sqrt   \n",
       "45   absolute_error             None                log2   \n",
       "28   absolute_error             None                 1.0   \n",
       "90          poisson             None                sqrt   \n",
       "\n",
       "   model__min_samples_split model__n_estimators  \n",
       "39                        4                 100  \n",
       "41                        4                 300  \n",
       "48                        4                 100  \n",
       "49                        4                 200  \n",
       "31                        4                 200  \n",
       "..                      ...                 ...  \n",
       "54                        2                 100  \n",
       "37                        2                 200  \n",
       "45                        2                 100  \n",
       "28                        2                 200  \n",
       "90                        2                 100  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_ExtraTrees, grid_search_pipelines_ExtraTrees = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_ExtraTrees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_ExtraTrees], ignore_index = True)\n",
    "data = dict(grid_search_pipelines); data.update(grid_search_pipelines_ExtraTrees)\n",
    "grid_search_pipelines = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "\n",
    "models_search = {\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'DecisionTreeRegressor':{\n",
    "        'model__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "        'model__splitter': ['best', 'random'],\n",
    "        'model__max_depth': [None],\n",
    "        'model__min_samples_split': [2,4,6],\n",
    "        'model__max_features': [1.0, 'sqrt', 'log2', 0.3, None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__min_samples_split</th>\n",
       "      <th>model__splitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999642</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999671</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998954</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.99946</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.99946</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998955</td>\n",
       "      <td>0.999459</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 estimator min_score mean_score (R²) max_score std_score  \\\n",
       "83   DecisionTreeRegressor  0.999317        0.999644  0.999766  0.000169   \n",
       "41   DecisionTreeRegressor  0.999327        0.999643  0.999757  0.000165   \n",
       "59   DecisionTreeRegressor  0.999325        0.999643  0.999769  0.000166   \n",
       "5    DecisionTreeRegressor  0.999327        0.999642  0.999762  0.000165   \n",
       "35   DecisionTreeRegressor  0.999318        0.999641  0.999755  0.000167   \n",
       "..                     ...       ...             ...       ...       ...   \n",
       "109  DecisionTreeRegressor  0.998976        0.999465  0.999671  0.000259   \n",
       "97   DecisionTreeRegressor  0.998954        0.999461  0.999664  0.000266   \n",
       "25   DecisionTreeRegressor  0.998939         0.99946  0.999667  0.000273   \n",
       "19   DecisionTreeRegressor  0.998944         0.99946  0.999659  0.000269   \n",
       "91   DecisionTreeRegressor  0.998955        0.999459  0.999669  0.000265   \n",
       "\n",
       "    model__criterion model__max_depth model__max_features  \\\n",
       "83      friedman_mse             None                 0.3   \n",
       "41    absolute_error             None                sqrt   \n",
       "59    absolute_error             None                None   \n",
       "5      squared_error             None                 1.0   \n",
       "35    absolute_error             None                 1.0   \n",
       "..               ...              ...                 ...   \n",
       "109          poisson             None                 0.3   \n",
       "97           poisson             None                sqrt   \n",
       "25     squared_error             None                None   \n",
       "19     squared_error             None                 0.3   \n",
       "91           poisson             None                 1.0   \n",
       "\n",
       "    model__min_samples_split model__splitter  \n",
       "83                         6          random  \n",
       "41                         6          random  \n",
       "59                         6          random  \n",
       "5                          6          random  \n",
       "35                         6          random  \n",
       "..                       ...             ...  \n",
       "109                        2          random  \n",
       "97                         2          random  \n",
       "25                         2          random  \n",
       "19                         2          random  \n",
       "91                         2          random  \n",
       "\n",
       "[120 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_DTree, grid_search_pipelines_DTree = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_DTree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_DTree], ignore_index=True)\n",
    "data = dict(grid_search_pipelines); data.update(grid_search_pipelines_DTree)\n",
    "grid_search_pipelines = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "\n",
    "models_search = {\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'AdaBoostRegressor':{\n",
    "        'model__n_estimators': [50, 100, 200, 300],\n",
    "        'model__learning_rate': [1, 1e-1,1e-2,1e-3],\n",
    "        'model__loss': ['linear', 'square', 'exponential'],\n",
    "        'model__random_state': [None],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.986319</td>\n",
       "      <td>0.995621</td>\n",
       "      <td>0.999069</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>1</td>\n",
       "      <td>square</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.984801</td>\n",
       "      <td>0.995339</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>1</td>\n",
       "      <td>square</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.98031</td>\n",
       "      <td>0.994266</td>\n",
       "      <td>0.999076</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>1</td>\n",
       "      <td>square</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.973377</td>\n",
       "      <td>0.992062</td>\n",
       "      <td>0.99883</td>\n",
       "      <td>0.00946</td>\n",
       "      <td>1</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.963659</td>\n",
       "      <td>0.989079</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.961054</td>\n",
       "      <td>0.988582</td>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.1</td>\n",
       "      <td>square</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.960551</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>0.99814</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.95792</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.998072</td>\n",
       "      <td>0.015194</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.987928</td>\n",
       "      <td>0.998367</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>0.987433</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>0.015578</td>\n",
       "      <td>1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            estimator min_score mean_score (R²) max_score std_score  \\\n",
       "7   AdaBoostRegressor  0.986319        0.995621  0.999069  0.004733   \n",
       "6   AdaBoostRegressor  0.984801        0.995339  0.999011  0.005327   \n",
       "5   AdaBoostRegressor   0.98031        0.994266  0.999076  0.007046   \n",
       "4   AdaBoostRegressor  0.973377        0.992062   0.99883   0.00946   \n",
       "2   AdaBoostRegressor  0.963659        0.989079  0.998373  0.012893   \n",
       "19  AdaBoostRegressor  0.961054        0.988582  0.998104  0.013904   \n",
       "0   AdaBoostRegressor  0.960551        0.988303   0.99814  0.014041   \n",
       "1   AdaBoostRegressor   0.95792          0.9881  0.998072  0.015194   \n",
       "3   AdaBoostRegressor  0.957821        0.987928  0.998367  0.015197   \n",
       "8   AdaBoostRegressor  0.956538        0.987433  0.998017  0.015578   \n",
       "\n",
       "   model__learning_rate  model__loss model__n_estimators model__random_state  \n",
       "7                     1       square                 300                None  \n",
       "6                     1       square                 200                None  \n",
       "5                     1       square                 100                None  \n",
       "4                     1       square                  50                None  \n",
       "2                     1       linear                 200                None  \n",
       "19                  0.1       square                 300                None  \n",
       "0                     1       linear                  50                None  \n",
       "1                     1       linear                 100                None  \n",
       "3                     1       linear                 300                None  \n",
       "8                     1  exponential                  50                None  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_ABR, grid_search_pipelines_ABR = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_ABR.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_ABR], ignore_index = True)\n",
    "data = dict(grid_search_pipelines); data.update(grid_search_pipelines_ABR)\n",
    "grid_search_pipelines = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "### Best model from quick search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.99965</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.999264</td>\n",
       "      <td>0.999616</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.99972</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.951972</td>\n",
       "      <td>0.986593</td>\n",
       "      <td>0.998113</td>\n",
       "      <td>0.017436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-0.537714</td>\n",
       "      <td>0.448415</td>\n",
       "      <td>0.753499</td>\n",
       "      <td>0.49414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>-0.559711</td>\n",
       "      <td>0.443811</td>\n",
       "      <td>0.755234</td>\n",
       "      <td>0.502959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score (R²) max_score std_score\n",
       "6               XGBRegressor  0.999442         0.99969  0.999785  0.000129\n",
       "5  GradientBoostingRegressor  0.999336         0.99965  0.999763  0.000163\n",
       "2      RandomForestRegressor  0.999264        0.999616  0.999752  0.000184\n",
       "3        ExtraTreesRegressor  0.999132        0.999556   0.99972  0.000222\n",
       "1      DecisionTreeRegressor  0.998984        0.999471  0.999669  0.000256\n",
       "4          AdaBoostRegressor  0.951972        0.986593  0.998113  0.017436\n",
       "0           LinearRegression -0.537714        0.448415  0.753499   0.49414\n",
       "7               SGDRegressor -0.559711        0.443811  0.755234  0.502959"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBRegressor'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search_summary_quick.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__min_samples_split</th>\n",
       "      <th>model__splitter</th>\n",
       "      <th>model__random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.99969</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.99944</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.974391</td>\n",
       "      <td>0.986765</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>0.974347</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>exponential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.948822</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.986171</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>exponential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.948744</td>\n",
       "      <td>0.974227</td>\n",
       "      <td>0.985913</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>square</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.948708</td>\n",
       "      <td>0.974019</td>\n",
       "      <td>0.985204</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             estimator min_score mean_score (R²) max_score std_score  \\\n",
       "0         XGBRegressor  0.999445        0.999692  0.999788  0.000128   \n",
       "1         XGBRegressor  0.999439         0.99969  0.999789  0.000131   \n",
       "2         XGBRegressor  0.999442         0.99969  0.999785  0.000129   \n",
       "3         XGBRegressor   0.99944        0.999684  0.999779  0.000126   \n",
       "4         XGBRegressor  0.999421        0.999681  0.999781  0.000137   \n",
       "..                 ...       ...             ...       ...       ...   \n",
       "532  AdaBoostRegressor  0.948901        0.974391  0.986765  0.013523   \n",
       "533  AdaBoostRegressor  0.948667        0.974347  0.986567  0.013591   \n",
       "534  AdaBoostRegressor  0.948822          0.9743  0.986171  0.013469   \n",
       "535  AdaBoostRegressor  0.948744        0.974227  0.985913  0.013466   \n",
       "536  AdaBoostRegressor  0.948708        0.974019  0.985204  0.013314   \n",
       "\n",
       "    model__max_depth model__n_estimators model__criterion  \\\n",
       "0                  4                 200              NaN   \n",
       "1                  6                  50              NaN   \n",
       "2                  6                 100              NaN   \n",
       "3                  6                 200              NaN   \n",
       "4                  4                 100              NaN   \n",
       "..               ...                 ...              ...   \n",
       "532              NaN                 100              NaN   \n",
       "533              NaN                  50              NaN   \n",
       "534              NaN                 100              NaN   \n",
       "535              NaN                  50              NaN   \n",
       "536              NaN                  50              NaN   \n",
       "\n",
       "    model__learning_rate  model__loss model__max_features  \\\n",
       "0                    NaN          NaN                 NaN   \n",
       "1                    NaN          NaN                 NaN   \n",
       "2                    NaN          NaN                 NaN   \n",
       "3                    NaN          NaN                 NaN   \n",
       "4                    NaN          NaN                 NaN   \n",
       "..                   ...          ...                 ...   \n",
       "532                0.001       linear                 NaN   \n",
       "533                0.001  exponential                 NaN   \n",
       "534                0.001  exponential                 NaN   \n",
       "535                0.001       square                 NaN   \n",
       "536                0.001       linear                 NaN   \n",
       "\n",
       "    model__min_samples_split model__splitter model__random_state  \n",
       "0                        NaN             NaN                 NaN  \n",
       "1                        NaN             NaN                 NaN  \n",
       "2                        NaN             NaN                 NaN  \n",
       "3                        NaN             NaN                 NaN  \n",
       "4                        NaN             NaN                 NaN  \n",
       "..                       ...             ...                 ...  \n",
       "532                      NaN             NaN                None  \n",
       "533                      NaN             NaN                None  \n",
       "534                      NaN             NaN                None  \n",
       "535                      NaN             NaN                None  \n",
       "536                      NaN             NaN                None  \n",
       "\n",
       "[537 rows x 14 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__criterion</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__max_features</th>\n",
       "      <th>model__min_samples_split</th>\n",
       "      <th>model__splitter</th>\n",
       "      <th>model__random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.993617</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>poisson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.987693</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score (R²) max_score std_score  \\\n",
       "0                 XGBRegressor  0.999445        0.999692  0.999788  0.000128   \n",
       "9    GradientBoostingRegressor  0.999407        0.999681  0.999778  0.000142   \n",
       "225      RandomForestRegressor  0.987616        0.993617  0.999618  0.006001   \n",
       "261        ExtraTreesRegressor  0.987693        0.993684  0.999675  0.005991   \n",
       "369      DecisionTreeRegressor  0.999317        0.999644  0.999766  0.000169   \n",
       "\n",
       "    model__max_depth model__n_estimators model__criterion  \\\n",
       "0                  4                 200              NaN   \n",
       "9                NaN                 300     friedman_mse   \n",
       "225             None                 200          poisson   \n",
       "261             None                 100   absolute_error   \n",
       "369             None                 NaN     friedman_mse   \n",
       "\n",
       "    model__learning_rate    model__loss model__max_features  \\\n",
       "0                    NaN            NaN                 NaN   \n",
       "9                    0.1  squared_error                 1.0   \n",
       "225                  NaN            NaN                sqrt   \n",
       "261                  NaN            NaN                sqrt   \n",
       "369                  NaN            NaN                 0.3   \n",
       "\n",
       "    model__min_samples_split model__splitter model__random_state  \n",
       "0                        NaN             NaN                 NaN  \n",
       "9                        NaN             NaN                 NaN  \n",
       "225                      NaN             NaN                 NaN  \n",
       "261                        4             NaN                 NaN  \n",
       "369                        6          random                 NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_search_summary = grid_search_summary.drop(labels=['model__copy_X', 'model__fit_intercept', 'model__positive',\n",
    "#                                                     'model__alpha', 'model__average', 'model__learning_rate', 'model__loss',\n",
    "#                                                     'model__penalty', 'model__criterion', 'model__max_depth', 'model__max_features',\n",
    "#                                                     'model__min_samples_split', 'model__splitter', 'model__n_estimators',\n",
    "#                                                     'model__random_state', 'model__early_stopping'], axis=1)\n",
    "                                                    \n",
    "grid_search_summary[grid_search_summary.estimator != grid_search_summary.estimator.shift(1)].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of each pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['XGBRegressor', 'GradientBoostingRegressor', 'RandomForestRegressor', 'ExtraTreesRegressor', 'DecisionTreeRegressor', 'AdaBoostRegressor'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipelines.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 4, 'model__n_estimators': 200}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_parameters = grid_search_pipelines_linear[best_model].best_params_\n",
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No   log_EWM  Flow_rate   Dust_feed  Dust     Tt\n",
       "0            8  0.509088  79.771690   59.107236   0.9  179.4\n",
       "1            8  1.301490  80.820436   59.107236   0.9  179.4\n",
       "2            8  1.816010  80.605533   59.107236   0.9  179.4\n",
       "3            8  2.173409  80.639911   59.107236   0.9  179.4\n",
       "4            8  2.413094  80.786058   59.107236   0.9  179.4\n",
       "...        ...       ...        ...         ...   ...    ...\n",
       "20926       50  5.878279  58.721877  177.321707   1.2   59.8\n",
       "20927       50  5.882293  58.699919  177.321707   1.2   59.8\n",
       "20928       50  5.885498  58.743820  177.321707   1.2   59.8\n",
       "20929       50  5.888018  58.601152  177.321707   1.2   59.8\n",
       "20930       50  5.894421  58.612131  177.321707   1.2   59.8\n",
       "\n",
       "[20931 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4.159433\n",
       "1          6.691262\n",
       "2          9.856047\n",
       "3         12.749570\n",
       "4         14.738860\n",
       "            ...    \n",
       "20926    359.971800\n",
       "20927    360.785600\n",
       "20928    361.509000\n",
       "20929    362.051500\n",
       "20930    366.482200\n",
       "Name: Differential_pressure, Length: 20931, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Regressor based on search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                              interaction_constraints=&#x27;&#x27;,\n",
       "                              learning_rate=0.300000012, max_bin=256,\n",
       "                              max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                              max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "                              min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n",
       "                              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                              random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                              interaction_constraints=&#x27;&#x27;,\n",
       "                              learning_rate=0.300000012, max_bin=256,\n",
       "                              max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                              max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "                              min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints=&#x27;()&#x27;, n_estimators=200,\n",
       "                              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                              random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
       "                         threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                       callbacks=None, colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None,\n",
       "                                       early_stopping_rounds=None,\n",
       "                                       enable_categorical=False,\n",
       "                                       eval_metric=None, feature_types=None,\n",
       "                                       gamma=None, gpu_id=None,\n",
       "                                       grow_policy=None, importance_type=None,\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=None, max_bin=None,\n",
       "                                       max_cat_threshold=None,\n",
       "                                       max_cat_to_onehot=None,\n",
       "                                       max_delta_step=None, max_depth=None,\n",
       "                                       max_leaves=None, min_child_weight=None,\n",
       "                                       missing=nan, monotone_constraints=None,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       num_parallel_tree=None, predictor=None,\n",
       "                                       random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=4, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('SmartCorrelatedSelection',\n",
       "                 SmartCorrelatedSelection(method='spearman',\n",
       "                                          selection_method='variance',\n",
       "                                          threshold=0.6)),\n",
       "                ('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=0, gpu_id=-1,\n",
       "                              grow_policy='depthwise', importance_type=None,\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_bin=256,\n",
       "                              max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                              max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "                              min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=200,\n",
       "                              n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "                              random_state=0, ...))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "# best_regressor_pipeline.keys()\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Feature Performance\n",
    "To find the most important features in this pipeline. Since the best model is linear regression, we cannot access these features using **.features_importances**.......???\n",
    "\n",
    "<!-- * The \"best features\" information is found in the pipeline's \"feature selection\" step as a boolean list.\n",
    "* We can use this list to subset the train set columns.\n",
    "* We create a DataFrame that contains these features' importance and plot it as a bar plot. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Regressor, Train and Test Set Performance\n",
    "Compute a performance metric on the data held out for testing, **df_test**\n",
    "* [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) (MSE)\n",
    "* [Mean Absolute Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (MAE)\n",
    "* [Median Absolute Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html) (MdAE)\n",
    "* [R² score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) (also called Coefficient of Determination)\n",
    "* Adjusted R2 Score \n",
    "    * _((1 - R²) * (sample_size - 1)) * -1 / (sample_size - no_independent_features - 1))_\n",
    "\n",
    "We could also include:\n",
    "* Almost Correct Predictions Error Rate (ACPER)\n",
    "* Mean Absolute Percentage Error (MAPE) and \n",
    "* Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    # sample_size = len(X)\n",
    "    # no_indep_features = y.shape[1]\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    # print('Adjusted R2 Score:', -(1 - R2)*(sample_size - 1)/(sample_size - no_indep_features - 1))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Median Absolute Error:', median_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_test['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation \n",
      "\n",
      "* Train Set\n",
      "R2 Score: 1.0\n",
      "Mean Absolute Error: 1.0\n",
      "Median Absolute Error: 0.661\n",
      "Mean Squared Error: 2.26\n",
      "Root Mean Squared Error: 1.503\n",
      "\n",
      "\n",
      "* Test Set\n",
      "R2 Score: 1.0\n",
      "Mean Absolute Error: 1.151\n",
      "Median Absolute Error: 0.769\n",
      "Mean Squared Error: 3.077\n",
      "Root Mean Squared Error: 1.754\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The **R2 score** (pipeline performance) is perfect 1.0 on the **df_train** and **df_test** sets respectively\n",
    "* As the business requirement requests an R2 score of 0.7 or above, this is an exceptional result.\n",
    "\n",
    "We also note that\n",
    "* The predictions follow the actual values extremely well, (the blue dots follow along the red diagonal almost perfectly).\n",
    "● We could have added more hyperparameters in the extensive search or considered more algorithms.\n",
    "● The reason we selected fewer hyperparameter combinations in the notebook was to train all possible\n",
    "models more quickly.\n",
    "In your project you may want to consider more hyperparameters.\n",
    "● If your hyperparameter combination almost reaches your performance criteria,\n",
    "○ then you may want to add a few more hyperparameters with the expectation that it would reach the performance we stated in the business case.\n",
    "● However, in this example, as our performance is very low, we'll explore other strategies. ○ We fitted a regressor pipeline using all available data.\n",
    " \n",
    "■ However, it didn't meet our performance requirements\n",
    "● What should we do?\n",
    "● Does this mean the data doesn't have patterns to predict tenure properly for a prospect that will likely\n",
    "churn?\n",
    "● Is there any other strategy we could take, like before delivering this pipeline as our solution?\n",
    "One strategy is to replace the feature selection step for a PCA (Principal Component Analysis) step. Next to refit our ML Pipeline with a PCA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Multiple regression and classification models under consideration \n",
    "\n",
    "* sklearn.linear_model.**LinearRegression**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "* sklearn.linear_model.**LogisticRegression**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "    * *.predict_proba(X)*\n",
    "* sklearn.linear_model.**SGDRegressor**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "    * *.SGDClassifier()*\n",
    "\n",
    "List full of available and under consideration can be seen at scikitlearn [linear models](https://scikit-learn.org/stable/modules/linear_model.html#)\n",
    "\n",
    "* No one optimal model. the most appropriate seems .LogisticRegression()\n",
    "<!-- \n",
    "**.LinearRegression()** - Ordinary Least Squares\n",
    "**.SGDClassifier()** and **.SGDRegressor()** - Stochastic Gradient Descent - SGD\n",
    ".Ridge() \n",
    ".Lasso()\n",
    ".MultiTaskLasso()\n",
    ".ElasticNet()\n",
    ".MultiTaskElasticNet()\n",
    ".Lars() - Least Angle Regression\n",
    ".LassoLars()\n",
    ".OrthogonalMatchingPursuit() and orthogonal_mp()\n",
    ".BayesianRidge() - Bayesian Regression\n",
    ".ARDRegression() - Automatic Relevance Determination\n",
    "Generalized Linear Models\n",
    "**.LogisticRegression()** + **.predict_proba(X)**\n",
    ".TweedieRegressor()\n",
    ".Perceptron()\n",
    ".PassiveAggressiveClassifier() and .PassiveAggressiveRegressor()\n",
    "Robustness regression: outliers and modeling errors\n",
    ".RANSACRegressor()\n",
    ".TheilSenRegressor() and \n",
    ".HuberRegressor()\n",
    ".QuantileRegressor()\n",
    "Polynomial regression: extending linear models with basis functions\n",
    ".PolynomialFeatures() transformer -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models with **R² score** = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept : -155.70499088778337\n",
      "Coefficients :\n",
      " [ 5.63605506e-01  8.08585054e+01  1.60358969e-01 -5.01446042e-03\n",
      " -8.07811592e+01  1.46301505e-02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "print('Intercept :', linreg.intercept_)\n",
    "print('Coefficients :\\n', linreg.coef_)\n",
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept : [-8.95161221e+09]\n",
      "Coefficients :\n",
      " [ 1.28410179e+10 -1.08856142e+10 -1.91961051e+10  1.95842713e+10\n",
      " -3.03098491e+09  8.63240338e+09]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "SGDreg = SGDRegressor()\n",
    "SGDreg.fit(X_train,y_train)\n",
    "print('Intercept :', SGDreg.intercept_)\n",
    "print('Coefficients :\\n', SGDreg.coef_)\n",
    "SGDreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "XTRreg = ExtraTreesRegressor()\n",
    "XTRreg.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFreg = RandomForestRegressor()\n",
    "RFreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DTreg = DecisionTreeRegressor()\n",
    "DTreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "             interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "             grow_policy='depthwise', importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
       "             max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "             max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGBreg = XGBRegressor()\n",
    "XGBreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBreg = GradientBoostingRegressor()\n",
    "GBreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ABreg = AdaBoostRegressor()\n",
    "ABreg.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Model Evaluation\n",
    "* A good metric for this is the **coefficient of determination** also called **r2-score**.\n",
    "* A good metric for this is the **median_absolute_error**.\n",
    "* Consider Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_linreg : 0.6362123748806392\n",
      "prediction_SGDreg : -724844344329774301184\n",
      "prediction_XTRreg : 0.9990402066880703\n",
      "prediction_RFreg : 0.9996902946305902\n",
      "prediction_DTreg : 0.9993839802055697\n",
      "prediction_XGBreg : 0.9996577720346448\n",
      "prediction_GBreg : 0.9996469111184378\n",
      "prediction_ABreg : 0.9926989722157485\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "prediction_linear = linreg.predict(X_test)\n",
    "prediction_SGDreg = SGDreg.predict(X_test)\n",
    "prediction_XTRreg = XTRreg.predict(X_test)\n",
    "prediction_RFreg = RFreg.predict(X_test)\n",
    "prediction_DTreg = DTreg.predict(X_test)\n",
    "prediction_XGBreg = XGBreg.predict(X_test)\n",
    "prediction_GBreg = GBreg.predict(X_test)\n",
    "prediction_ABreg = ABreg.predict(X_test)\n",
    "\n",
    "print('prediction_linreg :', r2_score(y_test,prediction_linear))\n",
    "print('prediction_SGDreg :', round(r2_score(y_test,prediction_SGDreg)))\n",
    "print('prediction_XTRreg :', r2_score(y_test,prediction_XTRreg))\n",
    "print('prediction_RFreg :', r2_score(y_test,prediction_RFreg))\n",
    "print('prediction_DTreg :', r2_score(y_test,prediction_DTreg))\n",
    "print('prediction_XGBreg :', r2_score(y_test,prediction_XGBreg))\n",
    "print('prediction_GBreg :', r2_score(y_test,prediction_GBreg))\n",
    "print('prediction_ABreg :', r2_score(y_test,prediction_ABreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# prediction = linreg.predict(X_test)\n",
    "# print(classification_report(y_test,prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets \n",
    "Save the files to **/models** folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/models/RULRegressor')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "grid_search_summary.to_csv(f'outputs/datasets/models/RULRegressor/GS_summary.csv',index=False)\n",
    "grid_search_pipelines.to_csv(f'outputs/datasets/models/RULRegressor/GS_pipelines.csv',index=False)\n",
    "# linreg.to_csv(f'outputs/datasets/models/RULRegressor/RUL_linreg.csv',index=False)\n",
    "# ABreg.to_csv(f'outputs/datasets/models/RULRegressor/RUL_ABreg.csv',index=False)\n",
    "\n",
    "df_total.to_csv(f'outputs/datasets/models/df_total.csv',index=False)\n",
    "df_total_model.to_csv(f'outputs/datasets/models/df_total_model.csv',index=False)\n",
    "df_train.to_csv(f'outputs/datasets/models/df_train.csv',index=False)\n",
    "df_train_even_dist.to_csv(f'outputs/datasets/models/df_train_even_dist.csv',index=False)\n",
    "df_test.to_csv(f'outputs/datasets/models/df_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
