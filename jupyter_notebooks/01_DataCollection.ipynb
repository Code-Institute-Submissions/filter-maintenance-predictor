{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
        "## **Data Collection Notebook**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* Fetch data from Kaggle and save it as raw data.\n",
        "* Inspect the data and save it under outputs/datasets/collection\n",
        "\n",
        "### Inputs\n",
        "\n",
        "*   Kaggle JSON file - the authentication token.\n",
        "\n",
        "### Outputs\n",
        "\n",
        "* Generates Two Datasets: \n",
        "    1. outputs/datasets/collection/**PredictiveMaintenanceTest**.csv\n",
        "    2. outputs/datasets/collection/**PredictiveMaintenanceTrain**.csv\n",
        "\n",
        "### Additional Comments\n",
        "* The data is from a publicly accessible Kaggle repo found [here](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance) and comes pre-divided into distinctly different Testing and Training data.\n",
        "* For the purposes of the learning context of this project, we are hosting the data in a publicly accessible repo at [GitHub](https://github.com/roeszler/filter-maintenance-predictor).\n",
        "* In the workplace, we would never push data to a public repository due to security exposure it represents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The notebooks are stored in a subfolder. When running the notebook in the editor, we change the working directory from its current folder to its parent folder.\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "To make the parent of the current directory the new current directory\n",
        "* `os.path.dirname()` = gets the parent directory\n",
        "* `os.chir()` = defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"Current directory set to new location\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install an instance of Kaggle to work within the editor\n",
        "\n",
        "`pip install kaggle==1.5.12`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- We have pre-installed Kaggle package to fetch data using : \n",
        "\n",
        "`pip install kaggle==1.5.12` -->\n",
        "\n",
        "This can be pre included in the requirements.txt documentation to load on initialization using : \n",
        "\n",
        "`pip3 freeze --local > requirements.txt`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Download a .JSON file (authentication token) from Kaggle and include it in the root directory\n",
        "* kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Recognize the token in the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Define the Kaggle dataset, and destination folder and download it.\n",
        "\n",
        "Kaggle url: [/prognosticshse/preventive-to-predicitve-maintenance](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance) .\n",
        "* **Note** the misspelling of 'predictive'\n",
        "\n",
        "The following function: \n",
        "* Retrieves and defines the Kaggle dataset\n",
        "* Creates a destination folder folder for the data to be placed\n",
        "* Downloads it to the destination folder\n",
        "* Unzips the downloaded file\n",
        "* Deletes the **.zip** file and unused data\n",
        "* Removes any **kaggle.json** files used to access the dataset on Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = 'prognosticshse/preventive-to-predicitve-maintenance'\n",
        "DestinationFolder = 'inputs/datasets/raw'   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n",
        "\n",
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm {DestinationFolder}/*.pdf \\\n",
        "  && rm {DestinationFolder}/*.mat \\\n",
        "#   && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Load and Inspect Kaggle data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data to Inspect\n",
        "We could combine both datasets, however as they have been included as two sets with slightly different content, we will inspect them each separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(f'inputs/datasets/raw/Test_Data_CSV.csv')\n",
        "df_train = pd.read_csv(f'inputs/datasets/raw/Train_Data_CSV.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DataFrame Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre installed `pandas_profiling` and `ipywidgets` with: \n",
        "\n",
        "* `pip install pandas-profiling`\n",
        "\n",
        "* `pip install ipywidgets`\n",
        "\n",
        "Not forgetting to update the requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the following frameworks to visualize and review the data with:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To explore the **Test** dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report_test = ProfileReport(df=df_test, minimal=True)\n",
        "pandas_report_test.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main observations of the **Test** Dataset :\n",
        "\n",
        "* There are no missing cells.\n",
        "\n",
        "* Differential Pressure has zero's and has a **reverse exponential** shaped distribution \n",
        "    * This correlates to what we understand. The beginning of each test set will have a period where the filter is clean and the difference in pressure is negligible.\n",
        "    * Subsequently, the measures of distribution (Mean, Median, Mode, Skewness, Kurtosis) correlate to the reverse exponential shape\n",
        "\n",
        "* Most of the **Dust_Feed** was run at 60mm<sup>3</sup>/s\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "* There is more than three times the amount of A3 Medium Dust observations (47.9%) as there is A2 Fine dust (14.8%), with A4 Course tests (37.3%)\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "    \n",
        "* The RUL target distribution is right or **positively skewed** at 0.71.\n",
        "    * Confirmed by the **Mean** of **111.48** > **Median** of **93.5**\n",
        "    * An ideal normal distribution has mean, median and mode similar in value and a skewness measure approaching zero\n",
        "    * A measure of the distributions tails; Kurtosis at -0.34 is relatively low in value and negative, indicating few outliers.\n",
        "    * Similar to **differential pressure** This shape is what we expect for a variable that progresses to zero.\n",
        "\n",
        "### Early Conclusions\n",
        "* Further box plot visualization to further investigate this skewness.\n",
        "* We will consider manipulating data at the feature engineering stage to reduce the affect of skewness, like:\n",
        "    * Random Forest Selection (Bagging)\n",
        "    * Logarithmic transformation\n",
        "    * Manipulate the data range to that of test sets more evenly distributed\n",
        "    * Feature Scaling\n",
        "\n",
        "#### Note: \n",
        "This dataset has deliberately had the tails of its observations removed at random points (right censored). This needs to be considered when looking at engineering the distributions. In light of this, depending on our Principal Component Analysis (PCA) a Random Forest Selection (Bagging) may present itself as the preferred method to engineer this set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To explore the **Train** dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_report_train = ProfileReport(df=df_train, minimal=True)\n",
        "pandas_report_train.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What group do the zeros appear in mostly?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main observations of the **Train** Dataset :\n",
        "\n",
        "* There are also no missing cells.\n",
        "\n",
        "* Differential Pressure has zero's and has the same **reverse exponential** shaped distribution as df_test.\n",
        "    * This correlates to what we understand. The beginning of each test set will have a period where the filter is clean and the difference in pressure is negligible.\n",
        "    * Subsequently, the measures of distribution (Mean, Median, Mode, Skewness, Kurtosis) correlate to the same reverse exponential shape\n",
        "\n",
        "* Most of the **Dust_Feed** was ab bit more evenly spread through the data, a 27% from 158.5mm<sup>3</sup>/s to around 20% in feeds between 60mm<sup>3</sup>/s to 118mm<sup>3</sup>/s.\n",
        "    * In a live project, we would check the stakeholders as to possible reasons for this and confirm that it represents typical data seen in practice\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "* The dust observations maintain A3 Medium Dust as the highest proportion (47.9%), however the portions of A2 Fine dust (28.2%) to A4 Course Dust (23.7%) are approximately the same.\n",
        "    * We would also check this with the stakeholders in a live workplace project\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "#### Reminder Note: \n",
        "This dataset has deliberately had the tails of its observations removed at random points (right censored). This needs to be considered when looking at engineering the distributions of this dataset. In light of this and further Principal Component Analysis (PCA) a Random Forest Selection (Bagging) may present itself as the preferred method to engineer this set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Considerations & Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We note that the dataset has **no missing data**. \n",
        "* This is outside of what we already know to be true for **df_test** (with RUL) and **df_train** (without RUL)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extend and convert `Data_No` of **df_test** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A comparison between sets reveals that the **Data_No** variable:\n",
        "* Is a categorical variable presented as an integer\n",
        "* Restarts at the beginning of each dataset\n",
        "\n",
        "This has the potential to confound subsequent analysis between the sets, where the analysis erroneously considers *Data_No* a discrete value &/or a duplicate entry. To help avoid confusion we alter the values in the **df_test dataset** to be a continuation from the bins seen in the **df_train dataset**.\n",
        "\n",
        "This is as simple as adding the total number of unique test bins in the df_test set to each one seen in the df_train set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quick reminder of the tables we are working with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the total number of test sets in **df_train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df_train.pivot_table(index = ['Data_No'], aggfunc ='size')\n",
        "df_train_total_sets = duplicates.count()\n",
        "df_train_total_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Continue the numbering in the next set : **df_test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_data_no = df_test['Data_No'] + df_train_total_sets\n",
        "new_data_no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace new data references into **df_test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Data_No'] = new_data_no\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert `Data_No` to a categorical variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the **test** set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_no_test = df_test['Data_No'].map(str)\n",
        "df_test['Data_No'] = data_no_test\n",
        "df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the **train** set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_no_train = df_train['Data_No'].map(str)\n",
        "df_train['Data_No'] = data_no_train\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert `Dust` to floating number\n",
        "Derived from the business requirements, we know that the **Dust** categorical variable has a floating number equivalent:\n",
        "* ISO 12103-1, A2 Fine Test Dust = 0.900 g/m<sup>3</sup>\n",
        "* ISO 12103-1, A3 Medium Test Dust = 1.025 g/m<sup>3</sup>\n",
        "* ISO 12103-1, A4 Coarse Test Dust = 1.200 g/m<sup>3</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dust_density_train = [0.900 if n == 'ISO 12103-1, A2 Fine Test Dust' else (1.025 if n == 'ISO 12103-1, A3 Medium Test Dust' else 1.200) for n in df_train['Dust']]\n",
        "df_train['Dust'] = dust_density_train\n",
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the `Dust` data type has changed in **df_train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['Dust'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the Test set using a concatenated function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dust_density_test = [0.900 if n == 'ISO 12103-1, A2 Fine Test Dust' else (1.025 if n == 'ISO 12103-1, A3 Medium Test Dust' else 1.200) for n in df_test['Dust']]\n",
        "df_test['Dust'] = dust_density_test\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For **df_test** dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change in Differential Pressure\n",
        "Include change in Differential Pressure calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['change_DP'] = df_test['Differential_pressure'].diff().fillna(0)\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace first instance of `change_DP` with zero value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['change_DP'][df_test.Data_No != df_test.Data_No.shift(1)] = 0\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the change in first and not the last values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(-1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['test'] = df_test['Data_No'].shift() != df_test['Data_No']\n",
        "# df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['test'].loc[366]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# type(df_test['test'].loc[366])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change = []\n",
        "# if ((df_test['test'] == True).any()):\n",
        "#     change = df_test[df_test['test'] == True]\n",
        "# # change.head()\n",
        "# index_value = change.index\n",
        "# index_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if change.index == df_test.index:\n",
        "#     df_test['change_DP'] = 0\n",
        "# df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change = df_test[df_test.Data_No != df_test.Data_No.shift(1)].head()\n",
        "# change.change_DP = 0\n",
        "# change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['change_DP'][df_test.Data_No != df_test.Data_No.shift(1)] = 0\n",
        "# df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test[df_test.Data_No != df_test.Data_No.shift(1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bool_val = list(map(int, df_test['Data_No'].shift() != df_test['Data_No']))\n",
        "# df_test['test'] = bool_val\n",
        "# df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# type(df_test['test'].loc[366])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['change_DP'] = df_test['Differential_pressure'].diff().fillna(0)\n",
        "# df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if df_test['test'] == True:\n",
        "#     df_test['change_DP'] = 0\n",
        "# else:\n",
        "#     df_test['change_DP'] == df_test['Differential_pressure'].diff().fillna(0)\n",
        "# df_test[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # if df_test['Data_No'].shift() != df_test['Data_No']:\n",
        "# if df_test[(df_test.test == 'True')].item():\n",
        "#     df_test['test'] = 0\n",
        "# else:\n",
        "#     df_test['test'] = df_test['Differential_pressure'].diff().fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Add Mass Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mass per observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_test['Mass_g'] = (df_test.Dust_feed/1000)*df_test.Dust\n",
        "df_test.loc[:,('Mass_g')] = (df_test.Dust_feed/1000)*df_test.Dust\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cumulative Mass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "df_test['Cumulative_Mass_g'] = df_test['Mass_g'].groupby(data).cumsum()\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Represent the total time of the test set at each row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve the total time for each test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total = df_test['Time'].groupby(data).max().to_frame()\n",
        "time_total.index.name = None\n",
        "time_total['Data_No'] = time_total.index\n",
        "time_total.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Map the total time to each observation and place it in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_test_time = df_test['Data_No'].map(time_total.set_index('Data_No')['Time'])\n",
        "df_test['Tt'] = total_test_time\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter Balance %\n",
        "Calculation to represent the balance to 600Pa `differential_pressure`. At the last value of the dataset, it indicates the amount of **right censoring** has ocurred to each data bin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = df_test['Differential_pressure']\n",
        "df_censor_test = (((600 - test_data)/600)*100).round(decimals = 2)\n",
        "df_censor_test.loc[363:368]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['Filter_Balance'] = df_censor_test\n",
        "df_test.loc[363:368]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Review the last values of each data bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(-1)].head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract information on a particular data bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bin = df_test[df_test['Data_No'] == '52']\n",
        "df_bin.describe().round(decimals=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Repeat calculations for **df_train** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.loc[446:451]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change in Differential Pressure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['change_DP'] = df_train['Differential_pressure'].diff().fillna(0)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mass per observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_train['Mass_g'] = (df_train.Dust_feed/1000)*df_train.Dust\n",
        "df_train.loc[:,('Mass_g')] = (df_train.Dust_feed/1000)*df_train.Dust\n",
        "df_train.loc[446:451]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cumulative Mass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_train.Data_No\n",
        "df_train['Cumulative_Mass_g'] = df_train['Mass_g'].groupby(data).cumsum()\n",
        "df_train.loc[446:451]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Total time of the test at each row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve the total time for each test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_total_train = df_train['Time'].groupby(data).max().to_frame()\n",
        "time_total_train.index.name = None\n",
        "time_total_train['Data_No'] = time_total_train.index\n",
        "time_total_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Map the total time to each observation and place it in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_test_time = df_train['Data_No'].map(time_total_train.set_index('Data_No')['Time'])\n",
        "df_train['Tt'] = total_test_time\n",
        "df_train.loc[446:451]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = df_train['Differential_pressure']\n",
        "df_censor_train = (((600 - train_data)/600)*100).round(decimals = 2)\n",
        "df_train['Filter_Balance'] = df_censor_train\n",
        "df_train.loc[446:451]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Review the last values of each data bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test[df_test.Data_No != df_test.Data_No.shift(-1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.describe().round(decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the description of cental tendency of the data with a `Data_No` value of `1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bin = df_train[df_train['Data_No'] == '1']\n",
        "df_bin.describe().round(decimals=2)\n",
        "# df_bin"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`pip install matplotlib`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# df_bin.plot(column=['Differential_pressure'], by='Data_No', figsize=(8, 6))\n",
        "df_bin.plot(kind='line', x='Data_No', y='Differential_pressure', ylim=(0,600), figsize=(8,6), title='Rate of Differential Pressure change in Data_No by Bin No.\\n', xlabel='Data_No', ylabel='Differential_pressure\\n')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RUL Calculation\n",
        "As discussed at the [splitting datasets](https://github.com/roeszler/filter-maintenance-predictor/blob/main/README.md#test-train-validation-data) section of the readme document: \n",
        "* The Remaining Useful Life variable has been supplied with live data in the **df_test** dataset and not recorded for the training dataset. \n",
        "* Notwithstanding, **RUL is a calculated measure** and may prove useful as an additional observation in the final validation stages. \n",
        "* Calculating the RUL also aids to highlight the correlation to the `Differential Pressure` and `Time` variables, where:\n",
        "\n",
        "<p style=\"text-align: center; font-size: 1rem;\">Remaining Useful Life (RUL) = Total time (cycles) to failure for each life test (T) - current time (t)</p>\n",
        "\n",
        "To test the function, here we will compare the **actual RUL** values supplied to the **calculated RUL** values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.loc[1209:1214]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve the last RUL value of each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df_test.Data_No\n",
        "RUL_end = df_test['RUL'].groupby(data).min().to_frame()\n",
        "RUL_end.index.name = None\n",
        "RUL_end['Data_No'] = RUL_end.index\n",
        "RUL_end.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rearrange and Drop unnecessary columns into a new dataset for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUL_drop = df_test.drop(['Differential_pressure', 'Flow_rate', 'Dust', 'Dust_feed', 'Mass_g', 'Cumulative_Mass_g', 'Filter_Balance'], axis=1)\n",
        "RUL_compared = RUL_drop[['Data_No',\t'Time',\t'Tt', 'RUL']]\n",
        "RUL_compared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate `RUL_Test` and its difference to `RUL` (Actual) to confirm the calculation is accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUL_Start = RUL_compared['Data_No'].map(RUL_end.set_index('Data_No')['RUL'])\n",
        "# RUL_compared['RUL_Test'] = (RUL_compared['Tt'] - RUL_compared['Time']) + RUL_Start\n",
        "# RUL_compared['RUL_Diff'] = round(RUL_compared['RUL'] - RUL_compared['RUL_Test'])\n",
        "RUL_compared.loc[:,('RUL_Test')] = (RUL_compared.loc[:,('Tt')] - RUL_compared.loc[:,('Time')]) + RUL_Start\n",
        "RUL_compared.loc[:,('RUL_Diff')] = round(RUL_compared.loc[:,('RUL')] - RUL_compared.loc[:,('RUL_Test')])\n",
        "RUL_compared.loc[1210:1220]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The RUL calculation is working as we predicted and can be confident to use this in our calculations. \n",
        "\n",
        "**An important note**:  \n",
        "* This calculation **is not predicting the RUL**, merely representing it with the data provided via the observation `Time` and Total Test Time `Tt`. \n",
        "* Both time observations are dependant on `Differential_pressure` reaching 600 Pa (i.e. point of filter failure). \n",
        "* This condition is not met in this data, so RUL cannot be calculated **until** we have an accurate prediction of when `Differential_pressure` will reach **600 Pa**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Combine datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combined_list = [df_test, df_train, df_validate]\n",
        "# df = pd.concat(combined_list)\n",
        "# df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the files to an outputs/../collection folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df_train.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceTrain.csv',index=False)\n",
        "df_test.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceTest.csv',index=False)\n",
        "# df_validate.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceValidate.csv',index=False)\n",
        "# df.to_csv(f'outputs/datasets/collection/FilterMaintenancePredictorDataset.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now push the changes to your GitHub Repo, using the Git commands (git add, git commit, git push)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conclusions: \n",
        "* Data supplied without missing observations\n",
        "* The Data_No references were repeated and corrected\n",
        "\n",
        "#### Next Steps:\n",
        "* Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
