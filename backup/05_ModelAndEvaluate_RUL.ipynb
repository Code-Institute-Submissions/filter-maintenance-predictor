{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
    "## **ML Model - Predict Remaining Useful Life (RUL)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Answer [Business Requirement 1](https://github.com/roeszler/filter-maintenance-predictor/blob/main/README.md#business-requirements) :\n",
    "*   Fit and evaluate a **regression model** to predict the Remaining Useful Life of a replaceable part\n",
    "*   Fit and evaluate a **classification model** to predict the Remaining Useful Life of a replaceable part should the regressor not perform well.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Data cleaning:\n",
    "* outputs/datasets/cleaned/dfCleanTotal.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set (features and target)\n",
    "* Test set (features and target)\n",
    "* Validation set (features and target)\n",
    "* ML pipeline to predict RUL\n",
    "* A map of the labels\n",
    "* Feature Importance Plot\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/filter-maintenance-predictor/backup'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory set to new location\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"Current directory set to new location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/filter-maintenance-predictor'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The major steps in this Regressor Pipeline\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>1. ML Pipeline: Regressor</strong> (Dropdown List)</summary>\n",
    "\n",
    "* Create Regressor Pipeline\n",
    "* Split the train set\n",
    "* Grid Search CV SKLearn\n",
    "    * Use standard hyperparameters to find most suitable algorithm\n",
    "    * Extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "* Assess Feature Performance\n",
    "* Evaluate Regressor\n",
    "* Create Train, Test, Validation Sets\n",
    "</details></br>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>2. ML Pipeline: Regressor + Principal Component Analysis</strong> (PCA)</summary>\n",
    "\n",
    "* Prepare the Data for the Pipeline\n",
    "* Create Regressor + PCA Pipeline\n",
    "* Split the train and validation sets\n",
    "* Grid Search CV SKLearn\n",
    "    * Use standard hyperparameters to find most suitable algorithm\n",
    "    * Do an extensive search on most suitable algorithm to find the best hyperparameter configuration\n",
    "* Assess Feature Performance\n",
    "* Evaluate Regressor\n",
    "* Create Train, Test, Validation Sets\n",
    "</details></br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>3. Convert Regression to Classification</strong> (Optionally)</summary>\n",
    "\n",
    "* Convert numerical target to bins, and check if it is balanced\n",
    "* Rewrite Pipeline for ML Modelling\n",
    "* Load Algorithms For Classification\n",
    "* Split the Train Test sets:\n",
    "* Grid Search CV SKLearn:\n",
    "    * Use standard hyper parameters to find most suitable model\n",
    "    * Grid Search CV\n",
    "    * Check Result\n",
    "* Do an extensive search on the most suitable model to find the best hyperparameter configuration.\n",
    "    * Define Model Parameters\n",
    "    * Extensive Grid Search CV                             \n",
    "    * Check Results\n",
    "    * Check Best Model\n",
    "    * Parameters for best model\n",
    "    * Define the best clf_pipeline\n",
    "* Assess Feature Importance\n",
    "* Evaluate Classifier on Train and Test Sets\n",
    "    * Custom Function\n",
    "    * List that relates the classes and tenure interval\n",
    "</details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>4. Decide which pipeline to use</strong></summary></details></br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"font-size: 0.9rem;\"><strong>5. Refit with the best features</strong></summary>\n",
    "\n",
    "* Rewrite Pipeline\n",
    "* Split Train Test Set with only best features\n",
    "* Subset best features\n",
    "* Grid Search CV SKLearn\n",
    "* Best Parameters\n",
    "    * Manually\n",
    "* Grid Search CV\n",
    "* Check Results\n",
    "* Check Best Model\n",
    "* Define the best pipeline\n",
    "</details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>6. Assess Feature Importance</strong></summary></details></br>\n",
    "\n",
    "<details><summary style=\"font-size: 0.9rem;\"><strong>7. Push Files to Repo</strong></summary></details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Modelling:\n",
    "The hypothesis part of the process where you will find out whether you can answer the question.\n",
    "* Identify what techniques to use.\n",
    "* Split your data into train, validate and test sets.\n",
    "* Build and train the models with the train data set.\n",
    "* Validate Models and hyper-parameter : Trial different machine learning methods and models with the validation data set.\n",
    "* Poor Results - return to data preparation for feature engineering\n",
    "* Successful hypothesis - where the inputs from the data set are mapped to the output target / label appropriately to evaluate.\n",
    "\n",
    "5. Evaluation:\n",
    "Where you test whether the model can predict unseen data.\n",
    "* Test Dataset\n",
    "* Choose the model that meets the business success criteria best.\n",
    "* Review and document the work that you have done.\n",
    "* If your project meets the success metrics you defined with your customer?\n",
    "- Ready to deploy. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cleaned Data\n",
    "Target variable for regressor, remove from classifier and drop other variables not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69686, 15) = df_total\n",
      "(69686, 12) = df_total_model\n",
      "(20931, 12) = df_train_even_dist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>4point_EWM</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>change_DP</th>\n",
       "      <th>change_EWM</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.046296</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327257</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.242651</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196354</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.360463</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117813</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>2.154530</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.808449</td>\n",
       "      <td>0.794067</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>3.390519</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.898871</td>\n",
       "      <td>1.235989</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>457.888170</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.329500</td>\n",
       "      <td>5.071087</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>460.424462</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-1.265900</td>\n",
       "      <td>2.536292</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>462.669597</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.808400</td>\n",
       "      <td>2.245135</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>466.512358</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.239200</td>\n",
       "      <td>3.842761</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>469.577575</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.898900</td>\n",
       "      <td>3.065217</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure  4point_EWM   log_EWM  Flow_rate  Time  \\\n",
       "0            1               1.537182    1.046296  0.045257  54.143527   5.5   \n",
       "1            1               1.537182    1.242651  0.217247  54.518255   5.6   \n",
       "2            1               1.537182    1.360463  0.307825  54.658781   5.7   \n",
       "3            1               3.345631    2.154530  0.767573  54.780562   5.8   \n",
       "4            1               5.244502    3.390519  1.220983  54.574466   5.9   \n",
       "...        ...                    ...         ...       ...        ...   ...   \n",
       "69681      100             465.494800  457.888170  6.126625  82.675521  52.0   \n",
       "69682      100             464.228900  460.424462  6.132149  82.421873  52.1   \n",
       "69683      100             466.037300  462.669597  6.137013  82.743156  52.2   \n",
       "69684      100             472.276500  466.512358  6.145285  82.785427  52.3   \n",
       "69685      100             474.175400  469.577575  6.151834  83.013710  52.4   \n",
       "\n",
       "        Dust_feed   Dust  RUL  change_DP  change_EWM    mass_g  \\\n",
       "0      236.428943  1.025  NaN   0.000000    0.327257  0.242340   \n",
       "1      236.428943  1.025  NaN   0.000000    0.196354  0.242340   \n",
       "2      236.428943  1.025  NaN   0.000000    0.117813  0.242340   \n",
       "3      236.428943  1.025  NaN   1.808449    0.794067  0.242340   \n",
       "4      236.428943  1.025  NaN   1.898871    1.235989  0.242340   \n",
       "...           ...    ...  ...        ...         ...       ...   \n",
       "69681  316.985065  1.200  8.2   6.329500    5.071087  0.380382   \n",
       "69682  316.985065  1.200  8.1  -1.265900    2.536292  0.380382   \n",
       "69683  316.985065  1.200  8.0   1.808400    2.245135  0.380382   \n",
       "69684  316.985065  1.200  7.9   6.239200    3.842761  0.380382   \n",
       "69685  316.985065  1.200  7.8   1.898900    3.065217  0.380382   \n",
       "\n",
       "       cumulative_mass_g    Tt  filter_balance  \n",
       "0              13.328682  44.9           99.74  \n",
       "1              13.571021  44.9           99.74  \n",
       "2              13.813361  44.9           99.74  \n",
       "3              14.055701  44.9           99.44  \n",
       "4              14.298040  44.9           99.13  \n",
       "...                  ...   ...             ...  \n",
       "69681         197.798681  52.4           22.42  \n",
       "69682         198.179063  52.4           22.63  \n",
       "69683         198.559445  52.4           22.33  \n",
       "69684         198.939827  52.4           21.29  \n",
       "69685         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "df_total = pd.read_csv(f'outputs/datasets/transformed/dfTransformedTotal.csv') # data with all negative log_EWM values removed\n",
    "df_total_model = (pd.read_csv('outputs/datasets/transformed/dfTransformedTotal.csv')\n",
    "        .drop(labels=['4point_EWM', 'change_DP', 'change_EWM'], axis=1)\n",
    "    )\n",
    "df_train_even_dist = (pd.read_csv(f'outputs/datasets/transformed/dfTransformedTrain.csv')\n",
    "        .drop(labels=['4point_EWM', 'change_DP', 'change_EWM', 'std_DP', 'median_DP', 'bin_size'], axis=1)\n",
    "    )\n",
    "print(df_total.shape, '= df_total')\n",
    "print(df_total_model.shape, '= df_total_model')\n",
    "print(df_train_even_dist.shape, '= df_train_even_dist')\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline : Regressor\n",
    "## Create Regressor Pipeline\n",
    "### Set the Transformations\n",
    "* Smart correlation\n",
    "* feat_scaling\n",
    "* feat_selection\n",
    "* Modelling\n",
    "* Model as variable\n",
    "\n",
    "Note: Numerical Transformation not required as data supplied as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train, Test, Validate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is discrete however in bins, so:\n",
    "#### Define Cleaned **Train** & **Test** Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4.159433</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6.691262</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9.856047</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12.749570</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14.738860</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>359.971800</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>360.785600</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>361.509000</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>362.051500</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>366.482200</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            8               4.159433  0.509088  79.771690   0.6   59.107236   \n",
       "1            8               6.691262  1.301490  80.820436   0.7   59.107236   \n",
       "2            8               9.856047  1.816010  80.605533   0.8   59.107236   \n",
       "3            8              12.749570  2.173409  80.639911   0.9   59.107236   \n",
       "4            8              14.738860  2.413094  80.786058   1.0   59.107236   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "20926       50             359.971800  5.878279  58.721877  59.4  177.321707   \n",
       "20927       50             360.785600  5.882293  58.699919  59.5  177.321707   \n",
       "20928       50             361.509000  5.885498  58.743820  59.6  177.321707   \n",
       "20929       50             362.051500  5.888018  58.601152  59.7  177.321707   \n",
       "20930       50             366.482200  5.894421  58.612131  59.8  177.321707   \n",
       "\n",
       "       Dust  RUL    mass_g  cumulative_mass_g     Tt  filter_balance  \n",
       "0       0.9  NaN  0.053197           0.319179  179.4           99.31  \n",
       "1       0.9  NaN  0.053197           0.372376  179.4           98.88  \n",
       "2       0.9  NaN  0.053197           0.425572  179.4           98.36  \n",
       "3       0.9  NaN  0.053197           0.478769  179.4           97.88  \n",
       "4       0.9  NaN  0.053197           0.531965  179.4           97.54  \n",
       "...     ...  ...       ...                ...    ...             ...  \n",
       "20926   1.2  NaN  0.212786         126.394913   59.8           40.00  \n",
       "20927   1.2  NaN  0.212786         126.607699   59.8           39.87  \n",
       "20928   1.2  NaN  0.212786         126.820485   59.8           39.75  \n",
       "20929   1.2  NaN  0.212786         127.033271   59.8           39.66  \n",
       "20930   1.2  NaN  0.212786         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df_total_model['Data_No'].iloc[0:len(df_total)]\n",
    "df_test = df_total_model[n > 50].reset_index(drop=True)\n",
    "df_train = df_train_even_dist # smaller dataset\n",
    "# df_train = df_total_model[n < 51].reset_index(drop=True) # larger dataset\n",
    "# df_train = df_train_even_dist.fillna(0)\n",
    "\n",
    "df_train_model = df_train_even_dist\n",
    "# df_train_model = df_train_even_dist.fillna(0)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2.622251</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>55.524146</td>\n",
       "      <td>0.4</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>3.888165</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>55.852018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.211698</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.150273</td>\n",
       "      <td>56.130203</td>\n",
       "      <td>0.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.454038</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.309382</td>\n",
       "      <td>56.150070</td>\n",
       "      <td>0.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.696378</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.393959</td>\n",
       "      <td>56.090457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.938717</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36358</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36359</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36360</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36361</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0           51               2.622251  0.148056  55.524146   0.4  236.428943   \n",
       "1           51               3.888165  0.811380  55.852018   0.5  236.428943   \n",
       "2           51               4.521122  1.150273  56.130203   0.6  236.428943   \n",
       "3           51               4.521122  1.309382  56.150070   0.7  236.428943   \n",
       "4           51               4.521122  1.393959  56.090457   0.8  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "36357      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "36358      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "36359      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "36360      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "36361      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust   RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  58.6  0.242340           0.969359  36.6           99.56  \n",
       "1      1.025  58.5  0.242340           1.211698  36.6           99.35  \n",
       "2      1.025  58.4  0.242340           1.454038  36.6           99.25  \n",
       "3      1.025  58.3  0.242340           1.696378  36.6           99.25  \n",
       "4      1.025  58.2  0.242340           1.938717  36.6           99.25  \n",
       "...      ...   ...       ...                ...   ...             ...  \n",
       "36357  1.200   8.2  0.380382         197.798681  52.4           22.42  \n",
       "36358  1.200   8.1  0.380382         198.179063  52.4           22.63  \n",
       "36359  1.200   8.0  0.380382         198.559445  52.4           22.33  \n",
       "36360  1.200   7.9  0.380382         198.939827  52.4           21.29  \n",
       "36361  1.200   7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[36362 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine **Target** and **Independent** Variables and Extract **Validation** Dataset\n",
    "\n",
    "As discussed in the readme, this data has been supplied pre-split into **train** and **test** within unique **data bins**. \n",
    "We extract random observations from the **test** dataset to create a **validation** set, in a 70:30 split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>2.622251</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>55.524146</td>\n",
       "      <td>0.4</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>3.888165</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>55.852018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.211698</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.150273</td>\n",
       "      <td>56.130203</td>\n",
       "      <td>0.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.454038</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.309382</td>\n",
       "      <td>56.150070</td>\n",
       "      <td>0.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.696378</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>4.521122</td>\n",
       "      <td>1.393959</td>\n",
       "      <td>56.090457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>1.938717</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36358</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36359</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36360</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36361</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36362 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0           51               2.622251  0.148056  55.524146   0.4  236.428943   \n",
       "1           51               3.888165  0.811380  55.852018   0.5  236.428943   \n",
       "2           51               4.521122  1.150273  56.130203   0.6  236.428943   \n",
       "3           51               4.521122  1.309382  56.150070   0.7  236.428943   \n",
       "4           51               4.521122  1.393959  56.090457   0.8  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "36357      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "36358      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "36359      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "36360      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "36361      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust   RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  58.6  0.242340           0.969359  36.6           99.56  \n",
       "1      1.025  58.5  0.242340           1.211698  36.6           99.35  \n",
       "2      1.025  58.4  0.242340           1.454038  36.6           99.25  \n",
       "3      1.025  58.3  0.242340           1.696378  36.6           99.25  \n",
       "4      1.025  58.2  0.242340           1.938717  36.6           99.25  \n",
       "...      ...   ...       ...                ...   ...             ...  \n",
       "36357  1.200   8.2  0.380382         197.798681  52.4           22.42  \n",
       "36358  1.200   8.1  0.380382         198.179063  52.4           22.63  \n",
       "36359  1.200   8.0  0.380382         198.559445  52.4           22.33  \n",
       "36360  1.200   7.9  0.380382         198.939827  52.4           21.29  \n",
       "36361  1.200   7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[36362 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review correlations, Drop Features and Split into **70% test** and **30% validate**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25453, 10) X_test\n",
      "(10909, 10) X_validate\n",
      "(25453,) y_test\n",
      "(10909,) y_validate\n",
      "\n",
      "Features Suggested to Drop :\n",
      " ['Differential_pressure', 'log_EWM']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
    "df_engineering = df_test.copy()\n",
    "corr_sel.fit_transform(df_engineering)\n",
    "\n",
    "# log_EWM = df_test['log_EWM']\n",
    "features_to_drop_test = corr_sel.features_to_drop_\n",
    "features_to_drop_test = [e for e in features_to_drop_test if e not in ('Dust_feed', 'Time', 'RUL', 'mass_g', 'cumulative_mass_g', 'filter_balance')] # prevent these requirements from being removed in V1\n",
    "# features_to_drop_test = [e for e in features_to_drop_test if e not in ('Dust_feed', 'RUL', 'mass_g', 'cumulative_mass_g', 'filter_balance')] # prevent these requirements from being removed in V1\n",
    "# features_to_drop_test = [e for e in features_to_drop_test if e not in ('Dust_feed', 'Time', 'RUL', 'mass_g', 'cumulative_mass_g')] # prevent these requirements from being removed in V1\n",
    "features_to_drop_test.insert(0, 'Differential_pressure') # include differential pressure to be removed\n",
    "# features_to_drop_test.insert(0, 'Tt') # include differential pressure to be removed\n",
    "X = df_test.drop(features_to_drop_test,axis=1)\n",
    "y = df_test['Differential_pressure'] # define the target variable\n",
    "# y = df_test['filter_balance'] # define the target variable\n",
    "# y = df_test['Tt'] # define the target variable\n",
    "# y = df_test['Time'] # define the target variable\n",
    "\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X,y,test_size=0.30, random_state=0)\n",
    "\n",
    "print(X_test.shape, 'X_test')\n",
    "print(X_validate.shape, 'X_validate')\n",
    "print(y_test.shape, 'y_test')\n",
    "print(y_validate.shape, 'y_validate')\n",
    "print('\\nFeatures Suggested to Drop :\\n', features_to_drop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>56</td>\n",
       "      <td>57.383039</td>\n",
       "      <td>10.6</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>95.8</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>17.220214</td>\n",
       "      <td>71.3</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>77</td>\n",
       "      <td>57.690319</td>\n",
       "      <td>37.6</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>1.025</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>91.624533</td>\n",
       "      <td>60.2</td>\n",
       "      <td>89.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32959</th>\n",
       "      <td>94</td>\n",
       "      <td>60.006667</td>\n",
       "      <td>15.5</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>0.900</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.285287</td>\n",
       "      <td>43.934130</td>\n",
       "      <td>24.1</td>\n",
       "      <td>97.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>79</td>\n",
       "      <td>81.686305</td>\n",
       "      <td>213.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>122.2</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>151.078095</td>\n",
       "      <td>258.1</td>\n",
       "      <td>65.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34580</th>\n",
       "      <td>99</td>\n",
       "      <td>80.313263</td>\n",
       "      <td>113.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>168.4</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>80.574984</td>\n",
       "      <td>248.2</td>\n",
       "      <td>93.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>78</td>\n",
       "      <td>83.445949</td>\n",
       "      <td>32.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>261.7</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>22.697179</td>\n",
       "      <td>243.8</td>\n",
       "      <td>98.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>91</td>\n",
       "      <td>80.846225</td>\n",
       "      <td>13.2</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>0.900</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0.213965</td>\n",
       "      <td>28.243369</td>\n",
       "      <td>49.9</td>\n",
       "      <td>98.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>85</td>\n",
       "      <td>80.485188</td>\n",
       "      <td>34.0</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.200</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>72.347257</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>78</td>\n",
       "      <td>82.624780</td>\n",
       "      <td>80.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>213.1</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>57.168518</td>\n",
       "      <td>243.8</td>\n",
       "      <td>94.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>56</td>\n",
       "      <td>58.228042</td>\n",
       "      <td>67.0</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>108.844747</td>\n",
       "      <td>71.3</td>\n",
       "      <td>76.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25453 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Flow_rate   Time   Dust_feed   Dust    RUL    mass_g  \\\n",
       "2168        56  57.383039   10.6  158.492533  1.025   95.8  0.162455   \n",
       "20305       77  57.690319   37.6  237.738799  1.025   40.6  0.243682   \n",
       "32959       94  60.006667   15.5  316.985065  0.900   22.7  0.285287   \n",
       "24724       79  81.686305  213.0   59.107236  1.200  122.2  0.070929   \n",
       "34580       99  80.313263  113.6   59.107236  1.200  168.4  0.070929   \n",
       "...        ...        ...    ...         ...    ...    ...       ...   \n",
       "20757       78  83.445949   32.0   59.107236  1.200  261.7  0.070929   \n",
       "32103       91  80.846225   13.2  237.738799  0.900   38.8  0.213965   \n",
       "30403       85  80.485188   34.0  177.321707  1.200   48.5  0.212786   \n",
       "21243       78  82.624780   80.6   59.107236  1.200  213.1  0.070929   \n",
       "2732        56  58.228042   67.0  158.492533  1.025   39.4  0.162455   \n",
       "\n",
       "       cumulative_mass_g     Tt  filter_balance  \n",
       "2168           17.220214   71.3           99.25  \n",
       "20305          91.624533   60.2           89.63  \n",
       "32959          43.934130   24.1           97.23  \n",
       "24724         151.078095  258.1           65.13  \n",
       "34580          80.574984  248.2           93.02  \n",
       "...                  ...    ...             ...  \n",
       "20757          22.697179  243.8           98.73  \n",
       "32103          28.243369   49.9           98.52  \n",
       "30403          72.347257   66.0           88.40  \n",
       "21243          57.168518  243.8           94.80  \n",
       "2732          108.844747   71.3           76.84  \n",
       "\n",
       "[25453 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define **X_train**, **y_train** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4.159433</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6.691262</td>\n",
       "      <td>1.301490</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9.856047</td>\n",
       "      <td>1.816010</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12.749570</td>\n",
       "      <td>2.173409</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14.738860</td>\n",
       "      <td>2.413094</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>359.971800</td>\n",
       "      <td>5.878279</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>360.785600</td>\n",
       "      <td>5.882293</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>361.509000</td>\n",
       "      <td>5.885498</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>362.051500</td>\n",
       "      <td>5.888018</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>366.482200</td>\n",
       "      <td>5.894421</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            8               4.159433  0.509088  79.771690   0.6   59.107236   \n",
       "1            8               6.691262  1.301490  80.820436   0.7   59.107236   \n",
       "2            8               9.856047  1.816010  80.605533   0.8   59.107236   \n",
       "3            8              12.749570  2.173409  80.639911   0.9   59.107236   \n",
       "4            8              14.738860  2.413094  80.786058   1.0   59.107236   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "20926       50             359.971800  5.878279  58.721877  59.4  177.321707   \n",
       "20927       50             360.785600  5.882293  58.699919  59.5  177.321707   \n",
       "20928       50             361.509000  5.885498  58.743820  59.6  177.321707   \n",
       "20929       50             362.051500  5.888018  58.601152  59.7  177.321707   \n",
       "20930       50             366.482200  5.894421  58.612131  59.8  177.321707   \n",
       "\n",
       "       Dust  RUL    mass_g  cumulative_mass_g     Tt  filter_balance  \n",
       "0       0.9  NaN  0.053197           0.319179  179.4           99.31  \n",
       "1       0.9  NaN  0.053197           0.372376  179.4           98.88  \n",
       "2       0.9  NaN  0.053197           0.425572  179.4           98.36  \n",
       "3       0.9  NaN  0.053197           0.478769  179.4           97.88  \n",
       "4       0.9  NaN  0.053197           0.531965  179.4           97.54  \n",
       "...     ...  ...       ...                ...    ...             ...  \n",
       "20926   1.2  NaN  0.212786         126.394913   59.8           40.00  \n",
       "20927   1.2  NaN  0.212786         126.607699   59.8           39.87  \n",
       "20928   1.2  NaN  0.212786         126.820485   59.8           39.75  \n",
       "20929   1.2  NaN  0.212786         127.033271   59.8           39.66  \n",
       "20930   1.2  NaN  0.212786         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **train** dataset with the same variables dropped as the **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20931, 9) X_train\n",
      "(20931,) y_train\n",
      "\n",
      "Features Dropped :\n",
      " ['RUL', 'Differential_pressure', 'log_EWM']\n"
     ]
    }
   ],
   "source": [
    "features_to_drop_test.insert(0, 'RUL')\n",
    "\n",
    "X_train = df_train.drop(features_to_drop_test,axis=1)\n",
    "y_train = df_train['Differential_pressure']\n",
    "# y_train = df_train['filter_balance']\n",
    "# y_train = df_train['Tt']\n",
    "# y_train = df_train['Time']\n",
    "\n",
    "print(X_train.shape, 'X_train')\n",
    "print(y_train.shape, 'y_train')\n",
    "print('\\nFeatures Dropped :\\n', features_to_drop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Flow_rate  Time   Dust_feed  Dust    mass_g  \\\n",
       "0            8  79.771690   0.6   59.107236   0.9  0.053197   \n",
       "1            8  80.820436   0.7   59.107236   0.9  0.053197   \n",
       "2            8  80.605533   0.8   59.107236   0.9  0.053197   \n",
       "3            8  80.639911   0.9   59.107236   0.9  0.053197   \n",
       "4            8  80.786058   1.0   59.107236   0.9  0.053197   \n",
       "...        ...        ...   ...         ...   ...       ...   \n",
       "20926       50  58.721877  59.4  177.321707   1.2  0.212786   \n",
       "20927       50  58.699919  59.5  177.321707   1.2  0.212786   \n",
       "20928       50  58.743820  59.6  177.321707   1.2  0.212786   \n",
       "20929       50  58.601152  59.7  177.321707   1.2  0.212786   \n",
       "20930       50  58.612131  59.8  177.321707   1.2  0.212786   \n",
       "\n",
       "       cumulative_mass_g     Tt  filter_balance  \n",
       "0               0.319179  179.4           99.31  \n",
       "1               0.372376  179.4           98.88  \n",
       "2               0.425572  179.4           98.36  \n",
       "3               0.478769  179.4           97.88  \n",
       "4               0.531965  179.4           97.54  \n",
       "...                  ...    ...             ...  \n",
       "20926         126.394913   59.8           40.00  \n",
       "20927         126.607699   59.8           39.87  \n",
       "20928         126.820485   59.8           39.75  \n",
       "20929         127.033271   59.8           39.66  \n",
       "20930         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          4.159433\n",
       "1          6.691262\n",
       "2          9.856047\n",
       "3         12.749570\n",
       "4         14.738860\n",
       "            ...    \n",
       "20926    359.971800\n",
       "20927    360.785600\n",
       "20928    361.509000\n",
       "20929    362.051500\n",
       "20930    366.482200\n",
       "Name: Differential_pressure, Length: 20931, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Target Imbalance\n",
    "### No need to handle target imbalance in this **regression model**.\n",
    "* Typically we only need to create a single pipeline for Classification or Regression task. \n",
    "* The exception occurs when we need to handle a **classification target imbalance**, which requires more than one model to process "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline for **Fitting Models** (regression)\n",
    "Import features & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Management\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML regression algorithms\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>4point_EWM</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>change_DP</th>\n",
       "      <th>change_EWM</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.046296</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327257</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.242651</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196354</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>1.360463</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117813</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>2.154530</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.808449</td>\n",
       "      <td>0.794067</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>3.390519</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.898871</td>\n",
       "      <td>1.235989</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>457.888170</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.329500</td>\n",
       "      <td>5.071087</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>460.424462</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-1.265900</td>\n",
       "      <td>2.536292</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>462.669597</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.808400</td>\n",
       "      <td>2.245135</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>466.512358</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.239200</td>\n",
       "      <td>3.842761</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>469.577575</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.898900</td>\n",
       "      <td>3.065217</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure  4point_EWM   log_EWM  Flow_rate  Time  \\\n",
       "0            1               1.537182    1.046296  0.045257  54.143527   5.5   \n",
       "1            1               1.537182    1.242651  0.217247  54.518255   5.6   \n",
       "2            1               1.537182    1.360463  0.307825  54.658781   5.7   \n",
       "3            1               3.345631    2.154530  0.767573  54.780562   5.8   \n",
       "4            1               5.244502    3.390519  1.220983  54.574466   5.9   \n",
       "...        ...                    ...         ...       ...        ...   ...   \n",
       "69681      100             465.494800  457.888170  6.126625  82.675521  52.0   \n",
       "69682      100             464.228900  460.424462  6.132149  82.421873  52.1   \n",
       "69683      100             466.037300  462.669597  6.137013  82.743156  52.2   \n",
       "69684      100             472.276500  466.512358  6.145285  82.785427  52.3   \n",
       "69685      100             474.175400  469.577575  6.151834  83.013710  52.4   \n",
       "\n",
       "        Dust_feed   Dust  RUL  change_DP  change_EWM    mass_g  \\\n",
       "0      236.428943  1.025  NaN   0.000000    0.327257  0.242340   \n",
       "1      236.428943  1.025  NaN   0.000000    0.196354  0.242340   \n",
       "2      236.428943  1.025  NaN   0.000000    0.117813  0.242340   \n",
       "3      236.428943  1.025  NaN   1.808449    0.794067  0.242340   \n",
       "4      236.428943  1.025  NaN   1.898871    1.235989  0.242340   \n",
       "...           ...    ...  ...        ...         ...       ...   \n",
       "69681  316.985065  1.200  8.2   6.329500    5.071087  0.380382   \n",
       "69682  316.985065  1.200  8.1  -1.265900    2.536292  0.380382   \n",
       "69683  316.985065  1.200  8.0   1.808400    2.245135  0.380382   \n",
       "69684  316.985065  1.200  7.9   6.239200    3.842761  0.380382   \n",
       "69685  316.985065  1.200  7.8   1.898900    3.065217  0.380382   \n",
       "\n",
       "       cumulative_mass_g    Tt  filter_balance  \n",
       "0              13.328682  44.9           99.74  \n",
       "1              13.571021  44.9           99.74  \n",
       "2              13.813361  44.9           99.74  \n",
       "3              14.055701  44.9           99.44  \n",
       "4              14.298040  44.9           99.13  \n",
       "...                  ...   ...             ...  \n",
       "69681         197.798681  52.4           22.42  \n",
       "69682         198.179063  52.4           22.63  \n",
       "69683         198.559445  52.4           22.33  \n",
       "69684         198.939827  52.4           21.29  \n",
       "69685         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Differential_pressure</th>\n",
       "      <th>log_EWM</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.045257</td>\n",
       "      <td>54.143527</td>\n",
       "      <td>5.5</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.328682</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>54.518255</td>\n",
       "      <td>5.6</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.571021</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.537182</td>\n",
       "      <td>0.307825</td>\n",
       "      <td>54.658781</td>\n",
       "      <td>5.7</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>13.813361</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.345631</td>\n",
       "      <td>0.767573</td>\n",
       "      <td>54.780562</td>\n",
       "      <td>5.8</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.055701</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.244502</td>\n",
       "      <td>1.220983</td>\n",
       "      <td>54.574466</td>\n",
       "      <td>5.9</td>\n",
       "      <td>236.428943</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242340</td>\n",
       "      <td>14.298040</td>\n",
       "      <td>44.9</td>\n",
       "      <td>99.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>100</td>\n",
       "      <td>465.494800</td>\n",
       "      <td>6.126625</td>\n",
       "      <td>82.675521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>197.798681</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>100</td>\n",
       "      <td>464.228900</td>\n",
       "      <td>6.132149</td>\n",
       "      <td>82.421873</td>\n",
       "      <td>52.1</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.179063</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69683</th>\n",
       "      <td>100</td>\n",
       "      <td>466.037300</td>\n",
       "      <td>6.137013</td>\n",
       "      <td>82.743156</td>\n",
       "      <td>52.2</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.559445</td>\n",
       "      <td>52.4</td>\n",
       "      <td>22.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69684</th>\n",
       "      <td>100</td>\n",
       "      <td>472.276500</td>\n",
       "      <td>6.145285</td>\n",
       "      <td>82.785427</td>\n",
       "      <td>52.3</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>198.939827</td>\n",
       "      <td>52.4</td>\n",
       "      <td>21.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69685</th>\n",
       "      <td>100</td>\n",
       "      <td>474.175400</td>\n",
       "      <td>6.151834</td>\n",
       "      <td>83.013710</td>\n",
       "      <td>52.4</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>1.200</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.380382</td>\n",
       "      <td>199.320209</td>\n",
       "      <td>52.4</td>\n",
       "      <td>20.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69686 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Differential_pressure   log_EWM  Flow_rate  Time   Dust_feed  \\\n",
       "0            1               1.537182  0.045257  54.143527   5.5  236.428943   \n",
       "1            1               1.537182  0.217247  54.518255   5.6  236.428943   \n",
       "2            1               1.537182  0.307825  54.658781   5.7  236.428943   \n",
       "3            1               3.345631  0.767573  54.780562   5.8  236.428943   \n",
       "4            1               5.244502  1.220983  54.574466   5.9  236.428943   \n",
       "...        ...                    ...       ...        ...   ...         ...   \n",
       "69681      100             465.494800  6.126625  82.675521  52.0  316.985065   \n",
       "69682      100             464.228900  6.132149  82.421873  52.1  316.985065   \n",
       "69683      100             466.037300  6.137013  82.743156  52.2  316.985065   \n",
       "69684      100             472.276500  6.145285  82.785427  52.3  316.985065   \n",
       "69685      100             474.175400  6.151834  83.013710  52.4  316.985065   \n",
       "\n",
       "        Dust  RUL    mass_g  cumulative_mass_g    Tt  filter_balance  \n",
       "0      1.025  NaN  0.242340          13.328682  44.9           99.74  \n",
       "1      1.025  NaN  0.242340          13.571021  44.9           99.74  \n",
       "2      1.025  NaN  0.242340          13.813361  44.9           99.74  \n",
       "3      1.025  NaN  0.242340          14.055701  44.9           99.44  \n",
       "4      1.025  NaN  0.242340          14.298040  44.9           99.13  \n",
       "...      ...  ...       ...                ...   ...             ...  \n",
       "69681  1.200  8.2  0.380382         197.798681  52.4           22.42  \n",
       "69682  1.200  8.1  0.380382         198.179063  52.4           22.63  \n",
       "69683  1.200  8.0  0.380382         198.559445  52.4           22.33  \n",
       "69684  1.200  7.9  0.380382         198.939827  52.4           21.29  \n",
       "69685  1.200  7.8  0.380382         199.320209  52.4           20.97  \n",
       "\n",
       "[69686 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        # (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "        #                                              variables=['Differential_pressure', 'Flow_rate',\n",
    "        #                                                         # 'log_EWM', 'Time', 'mass_g', 'Tt', 'filter_balance',\n",
    "        #                                                         'Dust_feed', 'Dust', 'cumulative_mass_g'])),\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"feat_selection\",  SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    return pipeline_base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Custom Class** to fit a set of algorithms, each with its own set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key]) # the model\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score (R²)'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score (R²)': np.mean(scores),\n",
    "                'stdDev_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score (R²)', 'max_score', 'stdDev_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns], self.grid_searches\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use standard hyperparameters to find most suitable algorithm for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=0),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(random_state=0),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(random_state=0),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=0),\n",
    "    'XGBRegressor': XGBRegressor(random_state=0),\n",
    "    'SGDRegressor': SGDRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    'DecisionTreeRegressor': {},\n",
    "    'RandomForestRegressor': {},\n",
    "    'ExtraTreesRegressor': {},\n",
    "    'AdaBoostRegressor': {},\n",
    "    'GradientBoostingRegressor': {},\n",
    "    'XGBRegressor': {},\n",
    "    'SGDRegressor': {},\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the pipelines, using the above models with **default hyperparameters** to find the most suitable model\n",
    "* Parsed the train set\n",
    "* Set the performance metric as an R² score (Regression: described in our ML business case)\n",
    "* Cross validation as 5 (rule of thumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for DecisionTreeRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for RandomForestRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for ExtraTreesRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for AdaBoostRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for GradientBoostingRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Running GridSearchCV for SGDRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.344381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.817438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.08554</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-1.136743</td>\n",
       "      <td>0.572583</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.854663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.571999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>-1.148366</td>\n",
       "      <td>0.570326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-1.170942</td>\n",
       "      <td>0.55541</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>0.863293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score (R²) max_score stdDev_score\n",
       "6               XGBRegressor  0.139039        0.827801  0.999996     0.344381\n",
       "0           LinearRegression  0.087188        0.817438       1.0     0.365125\n",
       "7               SGDRegressor   0.08554        0.817108       1.0     0.365784\n",
       "5  GradientBoostingRegressor -1.136743        0.572583  0.999952     0.854663\n",
       "3        ExtraTreesRegressor -1.140001           0.572       1.0        0.856\n",
       "1      DecisionTreeRegressor -1.140001        0.571999       1.0        0.856\n",
       "2      RandomForestRegressor -1.148366        0.570326       1.0     0.859346\n",
       "4          AdaBoostRegressor -1.170942         0.55541  0.998017     0.863293"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_quick, grid_search_pipelines_quick = search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_quick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "* The average **R² score** (mean_score) indicates how well a model of the data fits the actual data.\n",
    "    * A value of R² score = 1 represents a perfect fit and R² score = 0 indicates the model is not any better than simply estimating an average.\n",
    "\n",
    "* Our R² score ranges from **0.55 to 0.83**, which includes model performances higher than the **0.7** tolerance we decided in the business case.\n",
    "* The best result is the **Extreme Gradient Boosting Regressor** at an R² score of **0.83** and standard deviation of **0.344381**. \n",
    "* The **Linear** and **Stochastic Gradient Descent** regressors also perform above our business requirements and would be good alternates for modelling should we need."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensive Grid Search \n",
    "Perform an extensive search on the most suitable model to find the best **hyperparameter configuration** with the aim to **improve performance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.344381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.817438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.08554</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-1.136743</td>\n",
       "      <td>0.572583</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.854663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.571999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>-1.148366</td>\n",
       "      <td>0.570326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-1.170942</td>\n",
       "      <td>0.55541</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>0.863293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score (R²) max_score stdDev_score\n",
       "6               XGBRegressor  0.139039        0.827801  0.999996     0.344381\n",
       "0           LinearRegression  0.087188        0.817438       1.0     0.365125\n",
       "7               SGDRegressor   0.08554        0.817108       1.0     0.365784\n",
       "5  GradientBoostingRegressor -1.136743        0.572583  0.999952     0.854663\n",
       "3        ExtraTreesRegressor -1.140001           0.572       1.0        0.856\n",
       "1      DecisionTreeRegressor -1.140001        0.571999       1.0        0.856\n",
       "2      RandomForestRegressor -1.148366        0.570326       1.0     0.859346\n",
       "4          AdaBoostRegressor -1.170942         0.55541  0.998017     0.863293"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_quick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "models_search = {\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    'XGBRegressor':{\n",
    "        'model__base_score': [0.5],\n",
    "        'model__booster': ['gbtree', 'gblinear'],\n",
    "        # 'model__booster': ['gbtree'],\n",
    "        # 'model__booster': ['gblinear'],\n",
    "        'model__eval_metric': ['rmse', 'mae', 'rmsle', 'map'],\n",
    "        # 'model__eval_metric': ['rmse'],\n",
    "        'model__learning_rate': [0.1, 0.3],\n",
    "        # 'model__learning_rate': [0.3],\n",
    "        'model__max_depth': [2, 4, 6],\n",
    "        'model__n_estimators': [10, 20, 30, 50, 100, 20931],\n",
    "        'model__objective': ['reg:squarederror'],\n",
    "        'model__verbosity': [0],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "XGB_search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "XGB_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "      <th>model__base_score</th>\n",
       "      <th>model__booster</th>\n",
       "      <th>model__eval_metric</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__objective</th>\n",
       "      <th>model__verbosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>20931</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>20931</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>20931</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192142</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimator min_score mean_score (R²) max_score stdDev_score  \\\n",
       "9   XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "10  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "16  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "15  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "11  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "17  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "5   XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "4   XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "3   XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "8   XGBRegressor  0.192142        0.838428       1.0     0.323143   \n",
       "\n",
       "   model__base_score model__booster model__eval_metric model__learning_rate  \\\n",
       "9                0.5       gblinear               rmse                  0.3   \n",
       "10               0.5       gblinear               rmse                  0.3   \n",
       "16               0.5       gblinear               rmse                  0.3   \n",
       "15               0.5       gblinear               rmse                  0.3   \n",
       "11               0.5       gblinear               rmse                  0.3   \n",
       "17               0.5       gblinear               rmse                  0.3   \n",
       "5                0.5       gblinear               rmse                  0.3   \n",
       "4                0.5       gblinear               rmse                  0.3   \n",
       "3                0.5       gblinear               rmse                  0.3   \n",
       "8                0.5       gblinear               rmse                  0.3   \n",
       "\n",
       "   model__max_depth model__n_estimators  model__objective model__verbosity  \n",
       "9                 4                  50  reg:squarederror                0  \n",
       "10                4                 100  reg:squarederror                0  \n",
       "16                6                 100  reg:squarederror                0  \n",
       "15                6                  50  reg:squarederror                0  \n",
       "11                4               20931  reg:squarederror                0  \n",
       "17                6               20931  reg:squarederror                0  \n",
       "5                 2               20931  reg:squarederror                0  \n",
       "4                 2                 100  reg:squarederror                0  \n",
       "3                 2                  50  reg:squarederror                0  \n",
       "8                 4                  30  reg:squarederror                0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_XGBR, grid_search_pipelines_XGBR = XGB_search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_XGBR.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "lin_model_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "}\n",
    "\n",
    "lin_params_search = {\n",
    "    'LinearRegression':{\n",
    "        'model__fit_intercept': [False, True],\n",
    "        'model__positive': [False, True],\n",
    "        'model__copy_X': [True],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for LinearRegression \n",
      "\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "lin_search = HyperparameterOptimizationSearch(models=lin_model_search, params=lin_params_search)\n",
    "lin_search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "      <th>model__copy_X</th>\n",
       "      <th>model__fit_intercept</th>\n",
       "      <th>model__positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.817438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365125</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-1.532701</td>\n",
       "      <td>-0.61643</td>\n",
       "      <td>-0.009994</td>\n",
       "      <td>0.66843</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-3.801675</td>\n",
       "      <td>-0.757901</td>\n",
       "      <td>0.606306</td>\n",
       "      <td>1.607661</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-1.196924</td>\n",
       "      <td>-1.04103</td>\n",
       "      <td>-0.908697</td>\n",
       "      <td>0.124761</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          estimator min_score mean_score (R²) max_score stdDev_score  \\\n",
       "2  LinearRegression  0.087188        0.817438       1.0     0.365125   \n",
       "3  LinearRegression -1.532701        -0.61643 -0.009994      0.66843   \n",
       "0  LinearRegression -3.801675       -0.757901  0.606306     1.607661   \n",
       "1  LinearRegression -1.196924        -1.04103 -0.908697     0.124761   \n",
       "\n",
       "  model__copy_X model__fit_intercept model__positive  \n",
       "2          True                 True           False  \n",
       "3          True                 True            True  \n",
       "0          True                False           False  \n",
       "1          True                False            True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_linear, grid_search_pipelines_linear = lin_search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3150/3917396185.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  grid_search_summary = pd.concat([grid_search_summary_XGBR, grid_search_summary_linear], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary_XGBR, grid_search_summary_linear], ignore_index=True)\n",
    "grid_search_pipelines = dict(grid_search_pipelines_XGBR); grid_search_pipelines.update(grid_search_pipelines_linear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "\n",
    "sgd_model_search = {\n",
    "    'SGDRegressor': SGDRegressor(),\n",
    "}\n",
    "\n",
    "sgd_params_search = {\n",
    "    'SGDRegressor':{\n",
    "        'model__loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "        'model__penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "        'model__alpha': [0.0001,0.0002,0.0003],\n",
    "        'model__learning_rate': [1e-1,1e-2,1e-3, 'optimal', 'adaptive'],\n",
    "        'model__fit_intercept': [False, True],\n",
    "        'model__early_stopping': [True],\n",
    "        'model__average': [True],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for SGDRegressor \n",
      "\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1440 fits failed out of a total of 2400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'adaptive', 'constant'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'optimal', 'constant', 'invscaling'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "89 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'constant', 'optimal', 'invscaling'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'optimal', 'adaptive'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'optimal', 'adaptive', 'invscaling'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "88 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'adaptive', 'optimal'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'adaptive', 'optimal', 'invscaling'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'adaptive', 'optimal', 'constant'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'constant', 'adaptive'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'constant', 'invscaling'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'invscaling', 'constant'}. Got 0.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'constant', 'optimal', 'invscaling'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'adaptive', 'optimal', 'invscaling'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'invscaling', 'constant'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'optimal', 'constant', 'invscaling'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'optimal', 'adaptive'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "89 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'adaptive', 'optimal'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'optimal', 'adaptive', 'invscaling'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'adaptive', 'constant'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'constant', 'adaptive'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "32 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'adaptive', 'optimal', 'constant'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'constant', 'invscaling'}. Got 0.01 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "87 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'adaptive', 'optimal'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'constant', 'optimal', 'adaptive'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'adaptive', 'constant'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'invscaling', 'constant'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'optimal', 'adaptive', 'constant', 'invscaling'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'adaptive', 'optimal', 'invscaling'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "85 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'constant', 'optimal', 'invscaling'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "32 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'constant', 'optimal', 'adaptive', 'invscaling'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'optimal', 'constant', 'adaptive'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'adaptive', 'optimal', 'constant', 'invscaling'}. Got 0.001 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1585, in fit\n",
      "    self._validate_params()\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of SGDRegressor must be a str among {'invscaling', 'adaptive', 'optimal', 'constant'}. Got 0.001 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [            nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -1.81737113e+15 -1.52138641e+15 -1.41487611e+15 -3.50949972e+14\n",
      " -9.41385115e-01 -9.47454128e-01 -9.31142201e-01 -7.80748759e-01\n",
      " -6.78902263e-01 -8.06497172e-01 -6.92724124e-01 -5.10721805e-01\n",
      " -1.23330692e+15 -4.22370524e+14 -1.41542702e+15 -1.46038691e+15\n",
      " -7.58324630e-01 -7.55141371e-01 -7.52949079e-01 -7.60505998e-01\n",
      " -9.55282134e-01 -9.56525723e-01 -9.56537360e-01 -9.54771172e-01\n",
      " -8.74420789e-01 -6.30651652e-01 -8.90558855e-01 -5.55594469e-01\n",
      " -7.54359902e-01 -7.56480722e-01 -7.56894077e-01 -7.53094624e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -7.12117515e+15 -8.52159556e+15 -1.67902009e+16 -3.71631922e+15\n",
      "  7.69586119e-01  7.58451573e-01  7.68062887e-01  7.59754685e-01\n",
      "  7.63234844e-01  7.62025013e-01  7.62739673e-01  7.60555643e-01\n",
      " -5.55396714e+15 -3.81204015e+15 -7.22069859e+15 -1.29085657e+15\n",
      "  8.17074181e-01  8.17554155e-01  8.17260969e-01  8.18280837e-01\n",
      "  7.20788598e-01  7.23856315e-01  7.22438794e-01  7.24190550e-01\n",
      "  7.61431377e-01  7.61000060e-01  7.61626079e-01  7.62401407e-01\n",
      "  8.16650810e-01  8.18479787e-01  8.17726711e-01  8.18621727e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -3.34187741e+14 -9.85156652e+13 -2.28395654e+15 -3.03713050e+14\n",
      " -9.47513406e-01 -9.21711726e-01 -9.43528448e-01 -8.90560093e-01\n",
      " -8.22232270e-01 -8.48308225e-01 -7.85921846e-01 -4.09141553e-01\n",
      " -1.04717050e+15 -1.41074369e+14 -5.81560497e+14 -1.38932338e+15\n",
      " -7.55549385e-01 -7.57023327e-01 -7.58819166e-01 -7.51058427e-01\n",
      " -9.48464807e-01 -9.55540630e-01 -9.58547956e-01 -9.57053479e-01\n",
      " -9.19215599e-01 -9.11912157e-01 -8.99887080e-01 -8.40598570e-01\n",
      " -7.61913477e-01 -7.57372811e-01 -7.54861312e-01 -7.56479006e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -2.03279214e+15 -1.10821309e+15 -6.79239243e+15 -1.22836001e+16\n",
      "  7.72097617e-01  7.57442745e-01  7.70254086e-01  7.61159090e-01\n",
      "  7.63540467e-01  7.59704999e-01  7.62107932e-01  7.61112706e-01\n",
      " -1.03871261e+16 -3.58556363e+15 -3.88331696e+15 -8.84861625e+14\n",
      "  8.16574162e-01  8.17333020e-01  8.17006418e-01  8.17784476e-01\n",
      "  6.88383976e-01  7.23393994e-01  7.01642440e-01  7.24856720e-01\n",
      "  7.61228353e-01  7.62478156e-01  7.60849821e-01  7.61184417e-01\n",
      "  8.18510234e-01  8.16441920e-01  8.16792370e-01  8.16537099e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -9.48121720e+14 -1.26087505e+14 -4.07386831e+15 -4.58889546e+14\n",
      " -9.42094387e-01 -8.63290191e-01 -9.47970554e-01 -9.24146692e-01\n",
      " -7.49815987e-01 -5.92374743e-01 -8.73521239e-01 -5.23943792e-01\n",
      " -8.80894434e+14 -4.50425823e+14 -8.21161964e+14 -3.62908628e+14\n",
      " -7.57671285e-01 -7.57602091e-01 -7.59070232e-01 -7.60228593e-01\n",
      " -9.57532526e-01 -9.56750760e-01 -9.56689791e-01 -9.60022209e-01\n",
      " -9.66403160e-01 -9.45323848e-01 -9.13993702e-01 -7.11433304e-01\n",
      " -7.56713536e-01 -7.59492443e-01 -7.53131417e-01 -7.56432213e-01\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      " -1.63250067e+16 -1.73605123e+15 -3.35096724e+15 -1.94160181e+15\n",
      "  7.68031297e-01  7.57881797e-01  7.67629334e-01  7.59981450e-01\n",
      "  7.64293790e-01  7.58015868e-01  7.61575488e-01  7.60415267e-01\n",
      " -2.20084310e+15 -8.98169276e+14 -3.26205673e+15 -1.53723081e+15\n",
      "  8.15084507e-01  8.18357674e-01  8.18334203e-01  8.16805919e-01\n",
      "  6.25584164e-01  7.21303724e-01  6.50863103e-01  7.24246466e-01\n",
      "  7.62360091e-01  7.62810966e-01  7.62303877e-01  7.61150470e-01\n",
      "  8.17878719e-01  8.17837845e-01  8.17119348e-01  8.18046071e-01]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SGD_search = HyperparameterOptimizationSearch(models=sgd_model_search, params=sgd_params_search)\n",
    "SGD_search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "      <th>model__alpha</th>\n",
       "      <th>model__average</th>\n",
       "      <th>model__early_stopping</th>\n",
       "      <th>model__fit_intercept</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>0.818622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362755</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.092555</td>\n",
       "      <td>0.81851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362978</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.81848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.36304</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.09179</td>\n",
       "      <td>0.818358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363284</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.091672</td>\n",
       "      <td>0.818334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363331</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        estimator min_score mean_score (R²) max_score stdDev_score  \\\n",
       "159  SGDRegressor  0.093112        0.818622       1.0     0.362755   \n",
       "316  SGDRegressor  0.092555         0.81851       1.0     0.362978   \n",
       "157  SGDRegressor    0.0924         0.81848       1.0      0.36304   \n",
       "465  SGDRegressor   0.09179        0.818358       1.0     0.363284   \n",
       "466  SGDRegressor  0.091672        0.818334       1.0     0.363331   \n",
       "..            ...       ...             ...       ...          ...   \n",
       "443  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "444  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "445  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "446  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "447  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "\n",
       "    model__alpha model__average model__early_stopping model__fit_intercept  \\\n",
       "159       0.0001           True                  True                 True   \n",
       "316       0.0002           True                  True                 True   \n",
       "157       0.0001           True                  True                 True   \n",
       "465       0.0003           True                  True                 True   \n",
       "466       0.0003           True                  True                 True   \n",
       "..           ...            ...                   ...                  ...   \n",
       "443       0.0003           True                  True                 True   \n",
       "444       0.0003           True                  True                 True   \n",
       "445       0.0003           True                  True                 True   \n",
       "446       0.0003           True                  True                 True   \n",
       "447       0.0003           True                  True                 True   \n",
       "\n",
       "    model__learning_rate                  model__loss model__penalty  \n",
       "159             adaptive  squared_epsilon_insensitive           None  \n",
       "316             adaptive  squared_epsilon_insensitive             l2  \n",
       "157             adaptive  squared_epsilon_insensitive             l1  \n",
       "465             adaptive                squared_error             l1  \n",
       "466             adaptive                squared_error     elasticnet  \n",
       "..                   ...                          ...            ...  \n",
       "443                0.001          epsilon_insensitive           None  \n",
       "444                0.001  squared_epsilon_insensitive             l2  \n",
       "445                0.001  squared_epsilon_insensitive             l1  \n",
       "446                0.001  squared_epsilon_insensitive     elasticnet  \n",
       "447                0.001  squared_epsilon_insensitive           None  \n",
       "\n",
       "[480 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_SGDR, grid_search_pipelines_SGDR = SGD_search.score_summary(sort_by='mean_score (R²)')\n",
    "grid_search_summary_SGDR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3150/2620337386.py:1: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_SGDR], ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "grid_search_summary = pd.concat([grid_search_summary, grid_search_summary_SGDR], ignore_index = True)\n",
    "data = dict(grid_search_pipelines); data.update(grid_search_pipelines_SGDR)\n",
    "grid_search_pipelines = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best **Model**, **Parameters** and **Pipeline** from Extensive Grid Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.344381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.817438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.08554</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-1.136743</td>\n",
       "      <td>0.572583</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.854663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>-1.140001</td>\n",
       "      <td>0.571999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>-1.148366</td>\n",
       "      <td>0.570326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-1.170942</td>\n",
       "      <td>0.55541</td>\n",
       "      <td>0.998017</td>\n",
       "      <td>0.863293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator min_score mean_score (R²) max_score stdDev_score\n",
       "6               XGBRegressor  0.139039        0.827801  0.999996     0.344381\n",
       "0           LinearRegression  0.087188        0.817438       1.0     0.365125\n",
       "7               SGDRegressor   0.08554        0.817108       1.0     0.365784\n",
       "5  GradientBoostingRegressor -1.136743        0.572583  0.999952     0.854663\n",
       "3        ExtraTreesRegressor -1.140001           0.572       1.0        0.856\n",
       "1      DecisionTreeRegressor -1.140001        0.571999       1.0        0.856\n",
       "2      RandomForestRegressor -1.148366        0.570326       1.0     0.859346\n",
       "4          AdaBoostRegressor -1.170942         0.55541  0.998017     0.863293"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_quick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "      <th>model__base_score</th>\n",
       "      <th>model__booster</th>\n",
       "      <th>model__eval_metric</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        estimator min_score mean_score (R²) max_score stdDev_score  \\\n",
       "0    XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "1    XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "2    XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "3    XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "4    XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "..            ...       ...             ...       ...          ...   \n",
       "497  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "498  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "499  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "500  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "501  SGDRegressor       NaN             NaN       NaN          NaN   \n",
       "\n",
       "    model__base_score model__booster model__eval_metric model__learning_rate  \\\n",
       "0                 0.5       gblinear               rmse                  0.3   \n",
       "1                 0.5       gblinear               rmse                  0.3   \n",
       "2                 0.5       gblinear               rmse                  0.3   \n",
       "3                 0.5       gblinear               rmse                  0.3   \n",
       "4                 0.5       gblinear               rmse                  0.3   \n",
       "..                ...            ...                ...                  ...   \n",
       "497               NaN            NaN                NaN                0.001   \n",
       "498               NaN            NaN                NaN                0.001   \n",
       "499               NaN            NaN                NaN                0.001   \n",
       "500               NaN            NaN                NaN                0.001   \n",
       "501               NaN            NaN                NaN                0.001   \n",
       "\n",
       "    model__max_depth  \n",
       "0                  4  \n",
       "1                  4  \n",
       "2                  6  \n",
       "3                  6  \n",
       "4                  4  \n",
       "..               ...  \n",
       "497              NaN  \n",
       "498              NaN  \n",
       "499              NaN  \n",
       "500              NaN  \n",
       "501              NaN  \n",
       "\n",
       "[502 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary.iloc[:, 0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The current **best model** performance is:\n",
    "* **XGBRegressor** with \n",
    "    <!-- * R² Score at **0.827807** and -->\n",
    "    * R² Score at **0.83843** and\n",
    "    <!-- * Standard Deviation at **0.344384** -->\n",
    "    * Standard Deviation at **0.323141**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator                   XGBRegressor\n",
       "min_score                       0.192148\n",
       "mean_score (R²)                  0.83843\n",
       "max_score                            1.0\n",
       "stdDev_score                    0.323141\n",
       "model__base_score                    0.5\n",
       "model__booster                  gblinear\n",
       "model__eval_metric                  rmse\n",
       "model__learning_rate                 0.3\n",
       "model__max_depth                       4\n",
       "model__n_estimators                   50\n",
       "model__objective        reg:squarederror\n",
       "model__verbosity                       0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "grid_search_summary.iloc[0].dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The **parameter configuration** of this model is:\n",
    "* XGBRegressor with\n",
    "    * max_depth = **6**\n",
    "    * n_estimators = **50**\n",
    "    * Note: \n",
    "        * This can be replaced with all **n_estimators = 20931**, (seen at row index 4) with no discernable change in the performance of the R² or standard deviation Scores.\n",
    "        * A sensitivity analysis was performed by including the total data from the df_train data bin:\n",
    "            * The performance decreased to R² Score at _0.500771_ and Standard Deviation at _0.611555_\n",
    "            * This confirms that we have successfully reduced some of the noise of the data by engineering a more even distribution among **dust** type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best **Regressor Pipeline** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
       "                         threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                       callbacks=None, colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None,\n",
       "                                       early_stopping_rounds=None,\n",
       "                                       enable_categorical=False,\n",
       "                                       eval_metric=None, feature_types=None,\n",
       "                                       gamma=None, gpu_id=None,\n",
       "                                       grow_policy=None, importance_type=None,\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=None, max_bin=None,\n",
       "                                       max_cat_threshold=None,\n",
       "                                       max_cat_to_onehot=None,\n",
       "                                       max_delta_step=None, max_depth=None,\n",
       "                                       max_leaves=None, min_child_weight=None,\n",
       "                                       missing=nan, monotone_constraints=None,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       num_parallel_tree=None, predictor=None,\n",
       "                                       random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=-1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('SmartCorrelatedSelection',\n",
       "                 SmartCorrelatedSelection(method='spearman',\n",
       "                                          selection_method='variance',\n",
       "                                          threshold=0.6)),\n",
       "                ('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Considerations\n",
    "Considering the value of using all data (n_estimators = 20931) to achieve the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator                   XGBRegressor\n",
       "min_score                       0.192148\n",
       "mean_score (R²)                  0.83843\n",
       "max_score                            1.0\n",
       "stdDev_score                    0.323141\n",
       "model__base_score                    0.5\n",
       "model__booster                  gblinear\n",
       "model__eval_metric                  rmse\n",
       "model__learning_rate                 0.3\n",
       "model__max_depth                       4\n",
       "model__n_estimators                20931\n",
       "model__objective        reg:squarederror\n",
       "model__verbosity                       0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_heuristic_model = grid_search_summary.iloc[4,:]\n",
    "best_heuristic_model.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The **test scores** and **best model parameters** for the remaining models are:\n",
    "\n",
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>0.817438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>0.818622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           estimator min_score mean_score (R²) max_score stdDev_score\n",
       "0       XGBRegressor  0.192148         0.83843       1.0     0.323141\n",
       "18  LinearRegression  0.087188        0.817438       1.0     0.365125\n",
       "22      SGDRegressor  0.093112        0.818622       1.0     0.362755"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_summary_short = grid_search_summary.iloc[:, 0:5]\n",
    "grid_search_summary_short[grid_search_summary_short.estimator != grid_search_summary_short.estimator.shift(1)].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores and Parameters of each pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      " estimator                   XGBRegressor\n",
      "min_score                       0.192148\n",
      "mean_score (R²)                  0.83843\n",
      "max_score                            1.0\n",
      "stdDev_score                    0.323141\n",
      "model__base_score                    0.5\n",
      "model__booster                  gblinear\n",
      "model__eval_metric                  rmse\n",
      "model__learning_rate                 0.3\n",
      "model__max_depth                       4\n",
      "model__n_estimators                   50\n",
      "model__objective        reg:squarederror\n",
      "model__verbosity                       0\n",
      "Name: 0, dtype: object\n",
      "========\n",
      " estimator               LinearRegression\n",
      "min_score                       0.087188\n",
      "mean_score (R²)                 0.817438\n",
      "max_score                            1.0\n",
      "stdDev_score                    0.365125\n",
      "model__copy_X                       True\n",
      "model__fit_intercept                True\n",
      "model__positive                    False\n",
      "Name: 18, dtype: object\n",
      "========\n",
      " estimator                               SGDRegressor\n",
      "min_score                                   0.093112\n",
      "mean_score (R²)                             0.818622\n",
      "max_score                                        1.0\n",
      "stdDev_score                                0.362755\n",
      "model__learning_rate                        adaptive\n",
      "model__fit_intercept                            True\n",
      "model__alpha                                  0.0001\n",
      "model__average                                  True\n",
      "model__early_stopping                           True\n",
      "model__loss              squared_epsilon_insensitive\n",
      "Name: 22, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = grid_search_summary_short[grid_search_summary_short.estimator != grid_search_summary_short.estimator.shift(1)].head()\n",
    "[print(f'========\\n', grid_search_summary.iloc[n,:].dropna()) for n in pipe.index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Feature Performance\n",
    "To find the most important features in this pipeline. \n",
    "\n",
    "If the best model is tree based, we can access these features using **.features_importances**.......???\n",
    "\n",
    "<!-- * The \"best features\" information is found in the pipeline's \"feature selection\" step as a boolean list.\n",
    "* We can use this list to subset the train set columns.\n",
    "* We create a DataFrame that contains these features' importance and plot it as a bar plot. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the best model from the GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBRegressor'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_score': 0.5,\n",
       " 'model__booster': 'gblinear',\n",
       " 'model__eval_metric': 'rmse',\n",
       " 'model__learning_rate': 0.3,\n",
       " 'model__max_depth': 2,\n",
       " 'model__n_estimators': 50,\n",
       " 'model__objective': 'reg:squarederror',\n",
       " 'model__verbosity': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;SmartCorrelatedSelection&#x27;,\n",
       "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
       "                                          selection_method=&#x27;variance&#x27;,\n",
       "                                          threshold=0.6)),\n",
       "                (&#x27;feat_scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;feat_selection&#x27;,\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
       "                         threshold=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                       callbacks=None, colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None,\n",
       "                                       early_stopping_rounds=None,\n",
       "                                       enable_categorical=False,\n",
       "                                       eval_metric=None, feature_types=None,\n",
       "                                       gamma=None, gpu_id=None,\n",
       "                                       grow_policy=None, importance_type=None,\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=None, max_bin=None,\n",
       "                                       max_cat_threshold=None,\n",
       "                                       max_cat_to_onehot=None,\n",
       "                                       max_delta_step=None, max_depth=None,\n",
       "                                       max_leaves=None, min_child_weight=None,\n",
       "                                       missing=nan, monotone_constraints=None,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       num_parallel_tree=None, predictor=None,\n",
       "                                       random_state=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=-1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('SmartCorrelatedSelection',\n",
       "                 SmartCorrelatedSelection(method='spearman',\n",
       "                                          selection_method='variance',\n",
       "                                          threshold=0.6)),\n",
       "                ('feat_scaling', StandardScaler()),\n",
       "                ('feat_selection',\n",
       "                 SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                        booster=None,\n",
       "                                                        callbacks=None,\n",
       "                                                        colsample_bylevel=None,\n",
       "                                                        colsample_bynode=None,\n",
       "                                                        colsample_bytree=None,\n",
       "                                                        early_stopping_ro...\n",
       "                              feature_types=None, gamma=None, gpu_id=-1,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.3,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=2, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=50,\n",
       "                              n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=0, ...))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBRegressor': {'model__base_score': 0.5,\n",
       "  'model__booster': 'gblinear',\n",
       "  'model__eval_metric': 'rmse',\n",
       "  'model__learning_rate': 0.3,\n",
       "  'model__max_depth': 2,\n",
       "  'model__n_estimators': 50,\n",
       "  'model__objective': 'reg:squarederror',\n",
       "  'model__verbosity': 0}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_summary = {f'{best_model}': best_parameters}\n",
    "params_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include best hyperparameter values into the Hyperparameter Optimization Search function \n",
    "* The **best_parameters** dictionary is not in the correct format, so has been entered manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation to help on hyperparameter list: \n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "model = {\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'XGBRegressor':{\n",
    "        'model__base_score': [0.5],\n",
    "        'model__booster': ['gblinear'],\n",
    "        'model__eval_metric': ['rmse'],\n",
    "        'model__learning_rate': [0.3],\n",
    "        'model__max_depth': [2],\n",
    "        'model__n_estimators': [50],\n",
    "        'model__objective': ['reg:squarederror'],\n",
    "        'model__verbosity': [0],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PipelineOptimization(model):\n",
    "#     pipeline_base = Pipeline([\n",
    "#         # (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "#         #                                              variables=['Differential_pressure', 'Flow_rate',\n",
    "#         #                                                         # 'log_EWM', 'Time', 'mass_g', 'Tt', 'filter_balance',\n",
    "#         #                                                         'Dust_feed', 'Dust', 'cumulative_mass_g'])),\n",
    "#         ('SmartCorrelatedSelection', SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
    "#         ('feat_scaling', StandardScaler()),\n",
    "#         ('feat_selection',  SelectFromModel(model)),\n",
    "#         ('model', model),\n",
    "#         # ('model',\n",
    "#         #     XGBRegressor(\n",
    "#         #         base_score=0.5,\n",
    "#         #         booster='gblinear',\n",
    "#         #         eval_metric='rmse',\n",
    "#         #         max_depth=2,\n",
    "#         #         n_estimators=50,\n",
    "#         #         objective='reg:squarederror',\n",
    "#         #         verbosity = 0,)),\n",
    "#     ])\n",
    "#     return pipeline_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearchCV for XGBRegressor \n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "optimal_model = HyperparameterOptimizationSearch(models=model, params=params)\n",
    "optimal_model.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <th>max_score</th>\n",
       "      <th>stdDev_score</th>\n",
       "      <th>model__base_score</th>\n",
       "      <th>model__booster</th>\n",
       "      <th>model__eval_metric</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__objective</th>\n",
       "      <th>model__verbosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.83843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      estimator min_score mean_score (R²) max_score stdDev_score  \\\n",
       "0  XGBRegressor  0.192148         0.83843       1.0     0.323141   \n",
       "\n",
       "  model__base_score model__booster model__eval_metric model__learning_rate  \\\n",
       "0               0.5       gblinear               rmse                  0.3   \n",
       "\n",
       "  model__max_depth model__n_estimators  model__objective model__verbosity  \n",
       "0                2                  50  reg:squarederror                0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model_summary, optimal_model_pipeline = optimal_model.score_summary(sort_by='mean_score (R²)')\n",
    "optimal_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBRegressor': GridSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('SmartCorrelatedSelection',\n",
       "                                         SmartCorrelatedSelection(method='spearman',\n",
       "                                                                  selection_method='variance',\n",
       "                                                                  threshold=0.6)),\n",
       "                                        ('feat_scaling', StandardScaler()),\n",
       "                                        ('feat_selection',\n",
       "                                         SelectFromModel(estimator=XGBRegressor(base_score=None,\n",
       "                                                                                booster=None,\n",
       "                                                                                callbacks=None,\n",
       "                                                                                colsample_bylevel=None,\n",
       "                                                                                colsample_bynode=None,\n",
       "                                                                                colsample_b...\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__base_score': [0.5],\n",
       "                          'model__booster': ['gblinear'],\n",
       "                          'model__eval_metric': ['rmse'],\n",
       "                          'model__learning_rate': [0.3], 'model__max_depth': [2],\n",
       "                          'model__n_estimators': [50],\n",
       "                          'model__objective': ['reg:squarederror'],\n",
       "                          'model__verbosity': [0]},\n",
       "              scoring='r2', verbose=1)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xbg_reg = xgb.XGBRegressor(\n",
    "#     base_score=0.5,\n",
    "#     booster='gblinear',\n",
    "#     eval_metric='rmse',\n",
    "#     max_depth=2,\n",
    "#     n_estimators=50,\n",
    "#     objective='reg:squarederror',\n",
    "#     verbosity = 0,\n",
    "#     ).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>79.771690</td>\n",
       "      <td>0.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.319179</td>\n",
       "      <td>179.4</td>\n",
       "      <td>99.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>80.820436</td>\n",
       "      <td>0.7</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.372376</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>80.605533</td>\n",
       "      <td>0.8</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.425572</td>\n",
       "      <td>179.4</td>\n",
       "      <td>98.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>80.639911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.478769</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>80.786058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.531965</td>\n",
       "      <td>179.4</td>\n",
       "      <td>97.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20926</th>\n",
       "      <td>50</td>\n",
       "      <td>58.721877</td>\n",
       "      <td>59.4</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.394913</td>\n",
       "      <td>59.8</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20927</th>\n",
       "      <td>50</td>\n",
       "      <td>58.699919</td>\n",
       "      <td>59.5</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.607699</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>50</td>\n",
       "      <td>58.743820</td>\n",
       "      <td>59.6</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>126.820485</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>50</td>\n",
       "      <td>58.601152</td>\n",
       "      <td>59.7</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.033271</td>\n",
       "      <td>59.8</td>\n",
       "      <td>39.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20930</th>\n",
       "      <td>50</td>\n",
       "      <td>58.612131</td>\n",
       "      <td>59.8</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>127.246057</td>\n",
       "      <td>59.8</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Flow_rate  Time   Dust_feed  Dust    mass_g  \\\n",
       "0            8  79.771690   0.6   59.107236   0.9  0.053197   \n",
       "1            8  80.820436   0.7   59.107236   0.9  0.053197   \n",
       "2            8  80.605533   0.8   59.107236   0.9  0.053197   \n",
       "3            8  80.639911   0.9   59.107236   0.9  0.053197   \n",
       "4            8  80.786058   1.0   59.107236   0.9  0.053197   \n",
       "...        ...        ...   ...         ...   ...       ...   \n",
       "20926       50  58.721877  59.4  177.321707   1.2  0.212786   \n",
       "20927       50  58.699919  59.5  177.321707   1.2  0.212786   \n",
       "20928       50  58.743820  59.6  177.321707   1.2  0.212786   \n",
       "20929       50  58.601152  59.7  177.321707   1.2  0.212786   \n",
       "20930       50  58.612131  59.8  177.321707   1.2  0.212786   \n",
       "\n",
       "       cumulative_mass_g     Tt  filter_balance  \n",
       "0               0.319179  179.4           99.31  \n",
       "1               0.372376  179.4           98.88  \n",
       "2               0.425572  179.4           98.36  \n",
       "3               0.478769  179.4           97.88  \n",
       "4               0.531965  179.4           97.54  \n",
       "...                  ...    ...             ...  \n",
       "20926         126.394913   59.8           40.00  \n",
       "20927         126.607699   59.8           39.87  \n",
       "20928         126.820485   59.8           39.75  \n",
       "20929         127.033271   59.8           39.66  \n",
       "20930         127.246057   59.8           38.92  \n",
       "\n",
       "[20931 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_No</th>\n",
       "      <th>Flow_rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Dust_feed</th>\n",
       "      <th>Dust</th>\n",
       "      <th>RUL</th>\n",
       "      <th>mass_g</th>\n",
       "      <th>cumulative_mass_g</th>\n",
       "      <th>Tt</th>\n",
       "      <th>filter_balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>56</td>\n",
       "      <td>57.383039</td>\n",
       "      <td>10.6</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>95.8</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>17.220214</td>\n",
       "      <td>71.3</td>\n",
       "      <td>99.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>77</td>\n",
       "      <td>57.690319</td>\n",
       "      <td>37.6</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>1.025</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>91.624533</td>\n",
       "      <td>60.2</td>\n",
       "      <td>89.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32959</th>\n",
       "      <td>94</td>\n",
       "      <td>60.006667</td>\n",
       "      <td>15.5</td>\n",
       "      <td>316.985065</td>\n",
       "      <td>0.900</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.285287</td>\n",
       "      <td>43.934130</td>\n",
       "      <td>24.1</td>\n",
       "      <td>97.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>79</td>\n",
       "      <td>81.686305</td>\n",
       "      <td>213.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>122.2</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>151.078095</td>\n",
       "      <td>258.1</td>\n",
       "      <td>65.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34580</th>\n",
       "      <td>99</td>\n",
       "      <td>80.313263</td>\n",
       "      <td>113.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>168.4</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>80.574984</td>\n",
       "      <td>248.2</td>\n",
       "      <td>93.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>78</td>\n",
       "      <td>83.445949</td>\n",
       "      <td>32.0</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>261.7</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>22.697179</td>\n",
       "      <td>243.8</td>\n",
       "      <td>98.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>91</td>\n",
       "      <td>80.846225</td>\n",
       "      <td>13.2</td>\n",
       "      <td>237.738799</td>\n",
       "      <td>0.900</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0.213965</td>\n",
       "      <td>28.243369</td>\n",
       "      <td>49.9</td>\n",
       "      <td>98.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>85</td>\n",
       "      <td>80.485188</td>\n",
       "      <td>34.0</td>\n",
       "      <td>177.321707</td>\n",
       "      <td>1.200</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.212786</td>\n",
       "      <td>72.347257</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>78</td>\n",
       "      <td>82.624780</td>\n",
       "      <td>80.6</td>\n",
       "      <td>59.107236</td>\n",
       "      <td>1.200</td>\n",
       "      <td>213.1</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>57.168518</td>\n",
       "      <td>243.8</td>\n",
       "      <td>94.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>56</td>\n",
       "      <td>58.228042</td>\n",
       "      <td>67.0</td>\n",
       "      <td>158.492533</td>\n",
       "      <td>1.025</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>108.844747</td>\n",
       "      <td>71.3</td>\n",
       "      <td>76.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25453 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_No  Flow_rate   Time   Dust_feed   Dust    RUL    mass_g  \\\n",
       "2168        56  57.383039   10.6  158.492533  1.025   95.8  0.162455   \n",
       "20305       77  57.690319   37.6  237.738799  1.025   40.6  0.243682   \n",
       "32959       94  60.006667   15.5  316.985065  0.900   22.7  0.285287   \n",
       "24724       79  81.686305  213.0   59.107236  1.200  122.2  0.070929   \n",
       "34580       99  80.313263  113.6   59.107236  1.200  168.4  0.070929   \n",
       "...        ...        ...    ...         ...    ...    ...       ...   \n",
       "20757       78  83.445949   32.0   59.107236  1.200  261.7  0.070929   \n",
       "32103       91  80.846225   13.2  237.738799  0.900   38.8  0.213965   \n",
       "30403       85  80.485188   34.0  177.321707  1.200   48.5  0.212786   \n",
       "21243       78  82.624780   80.6   59.107236  1.200  213.1  0.070929   \n",
       "2732        56  58.228042   67.0  158.492533  1.025   39.4  0.162455   \n",
       "\n",
       "       cumulative_mass_g     Tt  filter_balance  \n",
       "2168           17.220214   71.3           99.25  \n",
       "20305          91.624533   60.2           89.63  \n",
       "32959          43.934130   24.1           97.23  \n",
       "24724         151.078095  258.1           65.13  \n",
       "34580          80.574984  248.2           93.02  \n",
       "...                  ...    ...             ...  \n",
       "20757          22.697179  243.8           98.73  \n",
       "32103          28.243369   49.9           98.52  \n",
       "30403          72.347257   66.0           88.40  \n",
       "21243          57.168518  243.8           94.80  \n",
       "2732          108.844747   71.3           76.84  \n",
       "\n",
       "[25453 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20931, 9)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X, y = datasets.load_diabetes(return_X_y=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_test_drop = X_test.drop('RUL', axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test_drop)\n",
    "\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the regressor with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_reg = xgb.XGBRegressor().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xbg_reg.get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_heading = X_train.transpose().reset_index().rename(columns={'index':'Variable'})\n",
    "# v_heading = c_heading['Variable'].to_list()\n",
    "# v_heading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_df_copy = importance_df.copy()\n",
    "# importance_df_copy['Variable'] = v_heading\n",
    "# test = importance_df_copy.set_index('Variable', drop=True).rename_axis(None)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rename Axis\n",
    "f_importance = xbg_reg.get_booster().get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame.from_dict(data=f_importance, orient='index')\n",
    "c_heading = X_train.transpose().reset_index().rename(columns={'index':'Variable'})\n",
    "v_heading = c_heading['Variable'].to_list()\n",
    "importance_df['Variable'] = v_heading\n",
    "\n",
    "# Plot Most Important Feature\n",
    "plot_importance = importance_df.set_index('Variable', drop=True).rename_axis(None)\n",
    "plot_importance.plot.bar()\n",
    "\n",
    "# plt.legend()\n",
    "plt.xticks(fontsize=8)\n",
    "plt.title('Features by Importance Score\\n')\n",
    "plt.ylabel('Importance Score\\n(gain in accuracy)\\n')\n",
    "# training_score = xbg_reg.score(X_train, y_train)\n",
    "# plt.xlabel('\\nFeature\\nModel Training Score: %.4f' % training_score)\n",
    "plt.xlabel('\\nFeature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance = plot_importance.drop(['filter_balance'], axis=0)\n",
    "# plot_importance = plot_importance.drop(['Differential_pressure'], axis=0)\n",
    "plot_importance.plot.bar()\n",
    "\n",
    "# plt.legend()\n",
    "plt.xticks(fontsize=8)\n",
    "plt.title('Features by Importance Score\\n')\n",
    "plt.ylabel('Importance Score\\n(gain in accuracy)\\n')\n",
    "plt.xlabel('\\nFeature')\n",
    "# plt.xlabel('\\nFeature\\nModel Training Score: %.4f' % training_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20931, 8)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X, y = datasets.load_diabetes(return_X_y=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_test_drop = X_test.drop(['RUL', 'filter_balance'], axis=1)\n",
    "# X_test_drop = X_test.drop(['RUL', 'Differential_pressure'], axis=1)\n",
    "X_train_drop = X_train.drop('filter_balance', axis=1)\n",
    "# X_train_drop = X_train.drop('Differential_pressure', axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_drop)\n",
    "X_test_scaled = scaler.transform(X_test_drop)\n",
    "\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=-1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=-1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=None, gpu_id=-1, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=50, n_jobs=0, num_parallel_tree=None, predictor=None,\n",
       "             random_state=0, ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    base_score=0.5,\n",
    "    booster='gblinear',\n",
    "    eval_metric='rmse',\n",
    "    max_depth=2,\n",
    "    n_estimators=50,\n",
    "    objective='reg:squarederror',\n",
    "    verbosity = 0,\n",
    "    )\n",
    "\n",
    "xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create comparison dataframe and Visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test_drop = X_test.drop('RUL', axis=1)\n",
    "y_pred = xgbr.predict(X_test_drop)\n",
    "\n",
    "# Create Dataframe\n",
    "y_test_df = pd.DataFrame(columns=['y_test'])\n",
    "y_test_df['y_test'] = y_test\n",
    "df_pred = pd.DataFrame(y_pred, columns=['y_pred'])\n",
    "df_comp = y_test_df.reset_index(drop=True)\n",
    "df_comp['y_pred'] = df_pred.y_pred.reset_index(drop=True)\n",
    "df_comp['variance'] = ((df_comp.y_pred - df_comp.y_test)/sum(y_test,y_pred))*100\n",
    "\n",
    "# Visualize it\n",
    "sample = df_comp.sort_values(by='y_test')\n",
    "my_range = range(1,len(sample.index)+1)\n",
    "plt.scatter(sample['y_pred'], my_range, color='navy', alpha=1, label='y_pred')\n",
    "plt.scatter(sample['y_test'], my_range, color='gold', alpha=0.8 , label='y_test')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.title('Snapshot of the dataset tail showing variation between Actual\\nand Predicted measures in Differential Pressure\\n')\n",
    "plt.ylabel('Index No.\\n')\n",
    "plt.xlabel('\\nPredicted Differential Pressure vs Actual\\nAverage Variation (Pa): %.4f' % df_comp.variance.mean())\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Regressor, Train and Test Set Performance\n",
    "Compute a performance metric on the data held out for testing, **df_test**\n",
    "* [R² score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) (also called Coefficient of Determination)\n",
    "* [Mean Absolute Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (MAE)\n",
    "* [Median Absolute Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html) (MdAE)\n",
    "* [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) (MSE)\n",
    "* Root Mean Squared Error (RMSE).\n",
    "\n",
    "We could also consider:\n",
    "* Almost Correct Predictions Error Rate (ACPER)\n",
    "* Mean Absolute Percentage Error (MAPE) and \n",
    "* Adjusted R² Score \n",
    "    * _((1 - R²) * (sample_size - 1)) * -1 / (sample_size - no_independent_features - 1))_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>estimator</th>\n",
       "      <td>XGBRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_score</th>\n",
       "      <td>0.192148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score (R²)</th>\n",
       "      <td>0.83843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_score</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdDev_score</th>\n",
       "      <td>0.323141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__base_score</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__booster</th>\n",
       "      <td>gblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__eval_metric</th>\n",
       "      <td>rmse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__learning_rate</th>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__max_depth</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__n_estimators</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__objective</th>\n",
       "      <td>reg:squarederror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__verbosity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "estimator                 XGBRegressor\n",
       "min_score                     0.192148\n",
       "mean_score (R²)                0.83843\n",
       "max_score                          1.0\n",
       "stdDev_score                  0.323141\n",
       "model__base_score                  0.5\n",
       "model__booster                gblinear\n",
       "model__eval_metric                rmse\n",
       "model__learning_rate               0.3\n",
       "model__max_depth                     2\n",
       "model__n_estimators                 50\n",
       "model__objective      reg:squarederror\n",
       "model__verbosity                     0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model_summary.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R2 Score: -0.107\n",
    "* Mean Absolute Error: 97.403\n",
    "* Median Absolute Error: 85.597\n",
    "* Mean Squared Error: 16560.575\n",
    "* Root Mean Squared Error: 128.688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    # sample_size = len(X)\n",
    "    # no_indep_features = y.shape[1]\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    # print('Adjusted R2 Score:', -(1 - R2)*(sample_size - 1)/(sample_size - no_indep_features - 1))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Median Absolute Error:', median_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation \n",
      "\n",
      "* Train Set\n",
      "R2 Score: 0.127\n",
      "Mean Absolute Error: 89.901\n",
      "Median Absolute Error: 72.95\n",
      "Mean Squared Error: 14308.034\n",
      "Root Mean Squared Error: 119.616\n",
      "\n",
      "\n",
      "* Test Set\n",
      "R2 Score: -0.107\n",
      "Mean Absolute Error: 97.403\n",
      "Median Absolute Error: 85.597\n",
      "Mean Squared Error: 16560.575\n",
      "Root Mean Squared Error: 128.688\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_performance(X_train, y_train, X_test_drop, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_stop\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_stop' is not defined"
     ]
    }
   ],
   "source": [
    "df_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    # sample_size = len(X)\n",
    "    # no_indep_features = y.shape[1]\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    # print('Adjusted R2 Score:', -(1 - R2)*(sample_size - 1)/(sample_size - no_indep_features - 1))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Median Absolute Error:', median_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def regression_variation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    \n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # # Visualize it\n",
    "    # sample = df_comp.sort_values(by='y_test').tail(40)\n",
    "    # my_range = range(1,len(sample.index)+1)\n",
    "\n",
    "    # plt.hlines(y=my_range, xmin=sample['y_pred'], xmax=sample['y_test'], color='grey')\n",
    "    # plt.scatter(sample['y_pred'], my_range, color='navy', alpha=1, label='y_pred')\n",
    "    # plt.scatter(sample['y_test'], my_range, color='gold', alpha=0.8 , label='y_test')\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.xticks(fontsize=8)\n",
    "    # plt.yticks(my_range, sample.index, fontsize=5)\n",
    "    # plt.title('Snapshot of the dataset tail showing variation between Actual\\nand Predicted measures in Differential Pressure\\n')\n",
    "    # plt.ylabel('Index No.\\n')\n",
    "    # plt.xlabel('\\nPredicted Differential Pressure vs Actual\\nAverage Variation in Pascals: %.8f' % df_comp.variance.mean())\n",
    "    # # plt.figure(figsize=(15,15))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_less_RUL = X_test.drop(labels=['RUL'], axis=1)\n",
    "regression_performance(X_train, y_train, X_test_less_RUL, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test_less_RUL, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The **R2 score** (pipeline performance) is perfect 1.0 on the **df_train** and **df_test** sets respectively\n",
    "* As the business requirement requests an R2 score of 0.7 or above, this is an exceptional result.\n",
    "\n",
    "We also note that\n",
    "* The predictions follow the actual values extremely well, (the blue dots follow along the red diagonal almost perfectly).\n",
    "● We could have added more hyperparameters in the extensive search or considered more algorithms.\n",
    "● The reason we selected fewer hyperparameter combinations in the notebook was to train all possible\n",
    "models more quickly.\n",
    "In your project you may want to consider more hyperparameters.\n",
    "● If your hyperparameter combination almost reaches your performance criteria,\n",
    "○ then you may want to add a few more hyperparameters with the expectation that it would reach the performance we stated in the business case.\n",
    "● However, in this example, as our performance is very low, we'll explore other strategies. ○ We fitted a regressor pipeline using all available data.\n",
    " \n",
    "■ However, it didn't meet our performance requirements\n",
    "● What should we do?\n",
    "● Does this mean the data doesn't have patterns to predict tenure properly for a prospect that will likely\n",
    "churn?\n",
    "● Is there any other strategy we could take, like before delivering this pipeline as our solution?\n",
    "One strategy is to replace the feature selection step for a PCA (Principal Component Analysis) step. Next to refit our ML Pipeline with a PCA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Multiple regression and classification models under consideration \n",
    "\n",
    "* sklearn.linear_model.**LinearRegression**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "* sklearn.linear_model.**LogisticRegression**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "    * *.predict_proba(X)*\n",
    "* sklearn.linear_model.**SGDRegressor**(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
    "    * *.SGDClassifier()*\n",
    "\n",
    "List full of available and under consideration can be seen at scikitlearn [linear models](https://scikit-learn.org/stable/modules/linear_model.html#)\n",
    "\n",
    "* No one optimal model. the most appropriate seems .LogisticRegression()\n",
    "<!-- \n",
    "**.LinearRegression()** - Ordinary Least Squares\n",
    "**.SGDClassifier()** and **.SGDRegressor()** - Stochastic Gradient Descent - SGD\n",
    ".Ridge() \n",
    ".Lasso()\n",
    ".MultiTaskLasso()\n",
    ".ElasticNet()\n",
    ".MultiTaskElasticNet()\n",
    ".Lars() - Least Angle Regression\n",
    ".LassoLars()\n",
    ".OrthogonalMatchingPursuit() and orthogonal_mp()\n",
    ".BayesianRidge() - Bayesian Regression\n",
    ".ARDRegression() - Automatic Relevance Determination\n",
    "Generalized Linear Models\n",
    "**.LogisticRegression()** + **.predict_proba(X)**\n",
    ".TweedieRegressor()\n",
    ".Perceptron()\n",
    ".PassiveAggressiveClassifier() and .PassiveAggressiveRegressor()\n",
    "Robustness regression: outliers and modeling errors\n",
    ".RANSACRegressor()\n",
    ".TheilSenRegressor() and \n",
    ".HuberRegressor()\n",
    ".QuantileRegressor()\n",
    "Polynomial regression: extending linear models with basis functions\n",
    ".PolynomialFeatures() transformer -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models with **R² score** = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "print('Intercept :', linreg.intercept_)\n",
    "print('Coefficients :\\n', linreg.coef_)\n",
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "SGDreg = SGDRegressor()\n",
    "SGDreg.fit(X_train,y_train)\n",
    "print('Intercept :', SGDreg.intercept_)\n",
    "print('Coefficients :\\n', SGDreg.coef_)\n",
    "SGDreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "XTRreg = ExtraTreesRegressor()\n",
    "XTRreg.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFreg = RandomForestRegressor()\n",
    "RFreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DTreg = DecisionTreeRegressor()\n",
    "DTreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGBreg = XGBRegressor()\n",
    "XGBreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBreg = GradientBoostingRegressor()\n",
    "GBreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ABreg = AdaBoostRegressor()\n",
    "ABreg.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Model Evaluation\n",
    "* A good metric for this is the **coefficient of determination** also called **r2-score**.\n",
    "* A good metric for this is the **median_absolute_error**.\n",
    "* Consider Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "prediction_linear = linreg.predict(X_test)\n",
    "prediction_SGDreg = SGDreg.predict(X_test)\n",
    "prediction_XTRreg = XTRreg.predict(X_test)\n",
    "prediction_RFreg = RFreg.predict(X_test)\n",
    "prediction_DTreg = DTreg.predict(X_test)\n",
    "prediction_XGBreg = XGBreg.predict(X_test)\n",
    "prediction_GBreg = GBreg.predict(X_test)\n",
    "prediction_ABreg = ABreg.predict(X_test)\n",
    "\n",
    "print('prediction_linreg :', r2_score(y_test,prediction_linear))\n",
    "print('prediction_SGDreg :', round(r2_score(y_test,prediction_SGDreg)))\n",
    "print('prediction_XTRreg :', r2_score(y_test,prediction_XTRreg))\n",
    "print('prediction_RFreg :', r2_score(y_test,prediction_RFreg))\n",
    "print('prediction_DTreg :', r2_score(y_test,prediction_DTreg))\n",
    "print('prediction_XGBreg :', r2_score(y_test,prediction_XGBreg))\n",
    "print('prediction_GBreg :', r2_score(y_test,prediction_GBreg))\n",
    "print('prediction_ABreg :', r2_score(y_test,prediction_ABreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# prediction = linreg.predict(X_test)\n",
    "# print(classification_report(y_test,prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets \n",
    "Save the files to **/models** folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/models/RULRegressor')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "grid_search_summary.to_csv(f'outputs/datasets/models/RULRegressor/GS_summary.csv',index=False)\n",
    "grid_search_pipelines.to_csv(f'outputs/datasets/models/RULRegressor/GS_pipelines.csv',index=False)\n",
    "# linreg.to_csv(f'outputs/datasets/models/RULRegressor/RUL_linreg.csv',index=False)\n",
    "# ABreg.to_csv(f'outputs/datasets/models/RULRegressor/RUL_ABreg.csv',index=False)\n",
    "\n",
    "df_total.to_csv(f'outputs/datasets/models/df_total.csv',index=False)\n",
    "df_total_model.to_csv(f'outputs/datasets/models/df_total_model.csv',index=False)\n",
    "df_train.to_csv(f'outputs/datasets/models/df_train.csv',index=False)\n",
    "df_train_even_dist.to_csv(f'outputs/datasets/models/df_train_even_dist.csv',index=False)\n",
    "df_test.to_csv(f'outputs/datasets/models/df_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Dec  2 2022, 16:09:02) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
